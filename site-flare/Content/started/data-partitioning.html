<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
		<div class="product-bar">
			<p><a>Smart Cache</a>
			</p>
		</div>
		<div class="product-bar">
			<p><a>Smart DIH</a>
			</p>
		</div>
        <h1>Data Partitioning</h1>
        <p>&#160;</p>
        <p>Data Partitioning (load balancing) is essential for any truly scalable architecture, as it enables scaling beyond the physical resources of a single-server machine.</p>
        <p>It is optimal to spread large amounts of data across multiple JVMs (Java Virtual Machines) which can reside in several physical machines. We refer to several partitions related to the same schema as a <a href="../overview/terminology.html">Space</a>.</p>
        <p>This partitioning both allows <b>scaling</b> - the ability to grow when there is more data and simply enlarge your cluster by having more JVMs, and increased <b>performance</b> as a job can be run in several partitions simultaneously using resources and data of multiple processes.</p>
        <p>Performing operations related to this Space (composed of multiple JVMs) is achieved via the GigaSpaces logical proxy which knows how to perform partitioning and data distribution. The proxy knows how to write every object to the correct partition and read from the correct location as well as perform any required action on the data. Due to this proxy, it is not necessary to know how the cluster itself is partitioned or how the data is distributed, in order to access it.</p>
        <p MadCap:conditions="Default.DoNotShow">Load balancing (data partitioning) is essential in any truly scalable architecture, as it enables scaling beyond the physical resources of a single-server machine. In <MadCap:variable name="General.ProductNameXAP"></MadCap:variable>, load balancing is the mechanism used by the clustered proxy to distribute space operations among the different cluster members. Each cluster member can run on a different physical or virtual machine.</p>
        <p>A clustered proxy for a partitioned data grid holds logical references to all Space members in the cluster. The references are "logical", in the sense that no active connection to a space member is opened until it is needed. This is illustrated in the following diagram:</p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/load_balancing_basic.gif" alt="load_balancing_basic.gif" class="tc-picture50" />
            </p>
        </div>
        <p>The space can have a single instance that runs on a single JVM, or multiple instances that run on multiple JVMs. When there are multiple instances, the spaces can be set up in one of several topologies. This architecture determines how the data is distributed across the JVMs.</p>
        <p>Available topologies:</p>
        <ul>
            <li>
                <p MadCap:conditions="Version.15-0-died">Replicated - data is copied to all of the JVMs in the cluster.</p>
            </li>
            <li>
                <p>Partitioned - data is distributed across all of the JVMs, each containing a different data subset. A partition is a subset of data that is distributed by a routing key.</p>
            </li>
            <li>
                <p>Partitioned with backup - data resides in a partition, and also in one  backup space instances for this partition.</p>
            </li>
        </ul>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/toplogies=replicatedOnly.jpg" MadCap:conditions="Version.15-0-died" />
            </p>
            <p>
                <img src="../Resources/Static/attachment_files/Topologies_minusReplicated.jpg" />
            </p>
        </div>
        <p>With a partitioned topology, data or operations on data are <a href="../dev-java/routing-in-partitioned-spaces.html">routed</a> to one of several space instances (partitions). Each space instance holds a subset of the data, with no overlap. Business logic can be <a href="/sbp/data-collocation-deployment-topology.html">collocated</a> within the partition to allow for fast parallel processing.</p>
        <div class="tc-admon-note">
            <p>To learn more about applying data partitioning and load balancing, refer to the <a href="../admin/data-partitioning-practical.html">Data Partitioning </a> page in the Developer Guide. </p>
        </div>
        <div class="tc-admon-note">
            <p>For relatively small tables which require colocated logic, you can avoid distribution of the data over partition and add replicated data using <a href="../dev-java/broadcast-objects.html">Broadcast Objects</a>. </p>
        </div>
    </body>
</html>