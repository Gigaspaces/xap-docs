<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
        <h1 class="tc-pagetitle">Integrating Kafka with <MadCap:variable name="General.CompanyName" /></h1>
        <table>
            <thead>
                <tr>
                    <th>Author</th>
                    <th>Release</th>
                    <th>Last Updated</th>
                    <th>Reference</th>
                    <th>Download</th>
                </tr>
            </thead>
            <tbody>
                <tr MadCap:conditions="">
                    <td>Aharon Moll</td>
                    <td>14.2</td>
                    <td>March 2019</td>
                    <td><a href="https://kafka.apache.org/" target="_blank">Apache Kafka</a>
                    </td>
                    <td><a href="https://github.com/Gigaspaces-sbp/xap-kafka" target="_blank">Github link </a>
                    </td>
                </tr>
            </tbody>
        </table>
        <h1>Introduction</h1>
        <p><a href="http://kafka.apache.org">Apache Kafka</a> is a distributed publish-subscribe messaging system, which supports sending messages between applications, processes, and servers. A message is any kind of information that is sent from a producer (application that sends the messages) to a consumer (application that receives the messages).</p>
        <p>Producers write their messages, or data, to Kafka topics. These topics are divided into partitions that function like logs. Each message is written to a partition and has a unique offset, or identifier. Consumers can specify a particular offset point where they can begin to read messages. </p>
        <p>A Kafka server is called a broker, and a Kafka cluster contains one or more brokers. Topic partitions can reside on different brokers in the clusters, so that data in a specific topic can be split among multiple brokers. Consumers can be associated with consumer groups (each group reads from a specific topic). This enables high throughput because messages can be written and read in parallel to and from the different brokers in the cluster.</p>
        <p>Kafka is designed to support persistent messaging with a O(1) disk structure that provides constant time performance, even with multiple terabytes of stored messages.
Kafka provides high throughput even with very modest hardware, supporting hundreds of thousands of messages per second. Messages can be split among Kafka brokers, distributing consumption over a cluster of consumer machines while maintaining per-partition ordering semantics. For example, Kafka is often used to perform parallel data loading to Hadoop.</p>
        <p>This page describes how to integrate <MadCap:variable name="General.CompanyName" /> products with Apache Kafka, using our write-behind data grid operations to Kafka to make data available for subscribers. Hadoop or any other data warehousing system can using the data for reporting and processing.</p>
        <h1>The Space as a Producer</h1>
        <p>The <MadCap:variable name="General.CompanyName" />-Kafka integration is done via the <code>SpaceSynchronizationEndpoint</code> interface deployed as a Kafka producer service. The service consumes a batch of data grid operations, converts them into custom Kafka messages, and sends these to the Kafka broker using the Kafka Producer API.</p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/solution-hub/gs-kafka-producer.png" alt="xap-kafka.jpg" class="tc-picture50" />
            </p>
        </div>
        <p>The <MadCap:variable name="General.CompanyName" />-Kafka protocol is simple and represents the data and data grid operations. A message consists of the data grid operation type (Write, Update , Remove, etc.) and the actual data object. The data object itself may be represented either as a single object or as a <code>SpaceDocument</code> with key/value pairs.
Kafka messages are sent via the network, so must be somehow serialized into bytes.
The default encoder utilizes the Java serialization mechanism, which implies Space classes (domain model) to be <code>Serializable</code>.</p>
        <p>By default, Kafka messages are uniformly distributed across Kafka partitions. As such, even though data grid operations appear ordered in <code>SpaceSynchronizationEndpoint</code>, this doesn't imply the correct data processing ordering  in Kafka consumers. </p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/solution-hub/gs-kafka-data-order.png" alt="xap-kafka-ordering.jpg" class="tc-picture50" />
            </p>
        </div>
        <h1>The Space as a Consumer</h1>
        <p>The Kafka persistence library provides a wrapper around the native Kafka Consumer API for the <MadCap:variable name="General.CompanyName" />-Kafka protocol serialization. For an example of how to use this wrapper, see <code>com.epam.openspaces.persistency.kafka.consumer.KafkaConsumer</code> in the <code>&lt;<MadCap:variable name="General.Home-directory" />&gt;/example module</code> folder.</p>
        <p>The Space sits behind the Kafka consumer service, and the data objects are passed to the Space instances using routing keys.</p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/solution-hub/gs-kafka-consumer.png" class="tc-picture50" />
            </p>
        </div>
        <h1>Getting started</h1>
        <h2>Download the Kafka Example</h2>
        <p>You can download the example code from <a href="/download_files/sbp/kafka-integration.tar">here</a>.
Unzip into an empty folder.</p>
        <p>The example located under <code>&lt;project_root&gt;/example</code>. It demonstrates how to configure Kafka persistence and implements a simple Kafka consumer pulling data from Kafka and store in HsqlDB.</p>
        <h2>Running the Example</h2>
        <p>In order to run an example, please follow the instruction below:</p>
        <p>Step 1: Install Kafka<br /></p>
        <p>Step 2: Start Zookeeper and Kafka server<br />bin/zookeeper-server-start.sh config/zookeeper.properties<br />bin/kafka-server-start.sh config/server.properties</p>
        <p>Step 3: Build project<br /></p><pre><code class="language-java">cd &lt;project_root&gt;
mvn clean install
</code></pre>
        <p>Step 4: Deploy example to GigaSpaces<br /></p><pre><code class="language-java">cd example
mvn os:deploy
</code></pre>
        <p>Step 5: Check GigaSpaces log files, there should be messages from the Feeder and Consumer.</p>
        <h1>Configuration</h1>
        <h2>Library Dependency</h2>
        <p>The following maven dependency needs to be included in your project in order to use Kafka persistence. This artifact is built from <code>&lt;project_rood&gt;/kafka-persistence</code> source directory.</p><pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.epam&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-persistence&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
        <h2>Processing Unit</h2>
        <p>Here is an example of the Kafka Processing Unit configuration:</p><pre MadCap:conditions="Version.14-5-died"><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:os-core="http://www.openspaces.org/schema/core"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd"&gt;

    &lt;!--
        Spring property configurer which allows us to use system properties (such as user.name).
    --&gt;
    &lt;bean id="propertiesConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"/&gt;

    &lt;!--
        Enables the usage of @GigaSpaceContext annotation based injection.
    --&gt;
    &lt;os-core:giga-space-context/&gt;

    &lt;!--
        A bean representing a space (an IJSpace implementation).
    --&gt;
    &lt;os-core:space id="space" url="/./space" schema="default" mirror="true"&gt;
        &lt;os-core:space-type type-name="Product"&gt;
            &lt;os-core:id property="CatalogNumber"/&gt;
            &lt;os-core:basic-index path="Name"/&gt;
            &lt;os-core:extended-index path="Price"/&gt;
        &lt;/os-core:space-type&gt;
    &lt;/os-core:space&gt;

    &lt;!--
        OpenSpaces simplified space API built on top of IJSpace/JavaSpace.
    --&gt;
    &lt;os-core:giga-space id="gigaSpace" space="space" /&gt;
&lt;/beans&gt;
</code></pre><pre MadCap:conditions="Version.14-5-born"><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:os-core="http://www.openspaces.org/schema/core"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd"&gt;

    &lt;!--
        Spring property configurer which allows us to use system properties (such as user.name).
    --&gt;
    &lt;bean id="propertiesConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"/&gt;

    &lt;!--
        Enables the usage of @GigaSpaceContext annotation based injection.
    --&gt;
    &lt;os-core:giga-space-context/&gt;

    &lt;!--
        A bean representing a space (an IJSpace implementation).
    --&gt;
    &lt;os-core:space id="space" url="/./space" schema="default" mirror="true"&gt;
        &lt;os-core:space-type type-name="Product"&gt;
            &lt;os-core:id property="CatalogNumber"/&gt;
            &lt;os-core:basic-index path="Name"/&gt;
            &lt;os-core:extended-index path="Price"/&gt;
        &lt;/os-core:space-type&gt;
    &lt;/os-core:space&gt;

    &lt;!--
        OpenSpaces simplified space API built on top of IJSpace/JavaSpace.
    --&gt;
    &lt;os-core:giga-space id="gigaSpace" space="space" /&gt;
&lt;/beans&gt;
</code></pre>
        <h2>Mirror service</h2>
        <p>Here is an example of the Kafka Space Synchronization Endpoint configuration:</p><pre MadCap:conditions="Version.14-5-died"><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:os-core="http://www.openspaces.org/schema/core"
       xmlns:os-events="http://www.openspaces.org/schema/events"
       xmlns:os-remoting="http://www.openspaces.org/schema/remoting"
       xmlns:os-sla="http://www.openspaces.org/schema/sla"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd
       http://www.openspaces.org/schema/events http://www.openspaces.org/schema/9.1/events/openspaces-events.xsd
       http://www.openspaces.org/schema/remoting http://www.openspaces.org/schema/9.1/remoting/openspaces-remoting.xsd
       http://www.openspaces.org/schema/sla http://www.openspaces.org/schema/sla/9.1/openspaces-sla.xsd"&gt;

    &lt;bean id="propertiesConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
        &lt;property name="locations"&gt;
            &lt;list&gt;
                &lt;value&gt;classpath:kafka.properties&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean id="kafkaSpaceSynchronizationEndpoint" class="com.epam.openspaces.persistency.kafka.KafkaSpaceSynchronizationEndpointFactoryBean"&gt;
        &lt;property name="producerProperties"&gt;
            &lt;props&gt;
                &lt;!-- Kafka producer properties. Consult Kafka documentation for a list of available properties --&gt;
                &lt;prop key="metadata.broker.list"&gt;${metadata.broker.list}&lt;/prop&gt;
                &lt;prop key="request.required.acks"&gt;${request.required.acks}&lt;/prop&gt;
            &lt;/props&gt;
        &lt;/property&gt;
    &lt;/bean&gt;

    &lt;!--
        The mirror space. Uses the Kafka external data source. Persists changes done on the Space that
        connects to this mirror space into the Kafka.
    --&gt;
    &lt;os-core:mirror id="mirror" url="/./mirror-service" space-sync-endpoint="kafkaSpaceSynchronizationEndpoint" operation-grouping="group-by-replication-bulk"&gt;
        &lt;os-core:source-space name="space" partitions="2" backups="1"/&gt;
    &lt;/os-core:mirror&gt;

&lt;/beans&gt;
</code></pre><pre MadCap:conditions="Version.14-5-born"><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:os-core="http://www.openspaces.org/schema/core"
       xmlns:os-events="http://www.openspaces.org/schema/events"
       xmlns:os-remoting="http://www.openspaces.org/schema/remoting"
       xmlns:os-sla="http://www.openspaces.org/schema/sla"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd
       http://www.openspaces.org/schema/events http://www.openspaces.org/schema/9.1/events/openspaces-events.xsd
       http://www.openspaces.org/schema/remoting http://www.openspaces.org/schema/9.1/remoting/openspaces-remoting.xsd
       http://www.openspaces.org/schema/sla http://www.openspaces.org/schema/sla/9.1/openspaces-sla.xsd"&gt;

    &lt;bean id="propertiesConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
        &lt;property name="locations"&gt;
            &lt;list&gt;
                &lt;value&gt;classpath:kafka.properties&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
    &lt;/bean&gt;

    &lt;bean id="kafkaSpaceSynchronizationEndpoint" class="com.epam.openspaces.persistency.kafka.KafkaSpaceSynchronizationEndpointFactoryBean"&gt;
        &lt;property name="producerProperties"&gt;
            &lt;props&gt;
                &lt;!-- Kafka producer properties. Consult Kafka documentation for a list of available properties --&gt;
                &lt;prop key="metadata.broker.list"&gt;${metadata.broker.list}&lt;/prop&gt;
                &lt;prop key="request.required.acks"&gt;${request.required.acks}&lt;/prop&gt;
            &lt;/props&gt;
        &lt;/property&gt;
    &lt;/bean&gt;

    &lt;!--
        The mirror space. Uses the Kafka external data source. Persists changes done on the Space that
        connects to this mirror space into the Kafka.
    --&gt;
    &lt;os-core:mirror id="mirror" url="/./mirror-service" space-sync-endpoint="kafkaSpaceSynchronizationEndpoint" operation-grouping="group-by-replication-bulk"&gt;
        &lt;os-core:source-space name="space" partitions="2" backups="1"/&gt;
    &lt;/os-core:mirror&gt;

&lt;/beans&gt;
</code></pre>
        <div class="tc-admon-refer">
            <p>For more information on the Mirror service see <a href="https://docs.gigaspaces.com/latest/dev-java/asynchronous-persistency-with-the-mirror.html">asynchronous persistence</a></p>
        </div>
        <h1>Producer Properties</h1>
        <p>Please consult Kafka documentation for the full list of available producer properties.
The default properties applied to Kafka producer are the following:</p>
        <table>
            <thead>
                <tr>
                    <th align="left">Property</th>
                    <th align="left">Default value</th>
                    <th align="left">Description</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td align="left">key.serializer.class</td>
                    <td align="left">com.epam.openspaces.persistency.kafka.<br />protocol.impl.serializer.KafkaMessageKeyEncoder</td>
                    <td align="left">Message key serializer of default Gigaspace-Kafka protocol</td>
                </tr>
                <tr>
                    <td align="left">serializer.class</td>
                    <td align="left">com.epam.openspaces.persistency.kafka.<br />protocol.impl.serializer.KafkaMessageEncoder</td>
                    <td align="left">Message serializer of default Gigaspace-Kafka protocol</td>
                </tr>
            </tbody>
        </table>
        <p>You can override the default properties if there is a need to customize GigaSpace-Kafka protocol. See Customization section below for details.</p>
        <h2>Space class</h2>
        <p>In order to associate a Kafka topic with the domain model class, the class needs to be annotated with the <code>@KafkaTopic</code> annotation and declared as <code>Serializable</code>. Here is an example</p><pre><code class="language-java">@KafkaTopic("user_activity")
@SpaceClass
public class UserActivity implements Serializable {
    ...
}
</code></pre>
        <h2><a name="space-documents">&#160;</a>Space Documents</h2>
        <p>To configure a Kafka topic for a SpaceDocuments or Extended SpaceDocument, the property <code>KafkaPersistenceConstants.SPACE_DOCUMENT_KAFKA_TOPIC_PROPERTY_NAME</code> should be added to document. Here is an example</p><pre><code class="language-java">public class Product extends SpaceDocument {

public Product() {
    super("Product");
    super.setProperty(SPACE_DOCUMENT_KAFKA_TOPIC_PROPERTY_NAME, "product");
}
</code></pre>
        <p>It's also possible to configure the name of the property which defines the Kafka topic for SpaceDocuments. Set <code>spaceDocumentKafkaTopicName</code> to the desired value as shown below.</p><pre><code class="language-xml">&lt;bean id="kafkaSpaceSynchronizationEndpoint" class="com.epam.openspaces.persistency.kafka.KafkaSpaceSynchrspaceDocumentKafkaTopicNameonizationEndpointFactoryBean"&gt;
    ...
    &lt;property name="spaceDocumentKafkaTopicName" value="topic_name" /&gt;
&lt;/bean&gt;
</code></pre>
        <h2>Customization</h2>
        <ul>
            <li>Kafka persistence was designed to be extensible and customizable.</li>
            <li>If you need to create a custom protocol between GigaSpace and Kafka, provide an implementation of <code>AbstractKafkaMessage</code>, <code>AbstractKafkaMessageKey</code>, <code>AbstractKafkaMessageFactory</code>.</li>
            <li>If you would like to customize how data grid operations are sent to Kafka or how the Kafka topic is chosen for a given entity, provide an implementation of "AbstractKafkaSpaceSynchronizationEndpoint'.</li>
            <li>If you want to create a custom serializer, look at <code>KafkaMessageDecoder</code> and <code>KafkaMessageKeyDecoder</code>.</li>
            <li>Kafka Producer client (which is used under the hood) can be configured with a number of settings, see Kafka documentation.</li>
        </ul>
    </body>
</html>