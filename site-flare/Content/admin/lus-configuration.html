<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
		<div class="product-bar">
			<p><a>Smart Cache</a>
			</p>
		</div>
        <h1>Global vs. Local LUS</h1>
        <div class="tc-admon-note">
            <p>This page is irrelevant for <MadCap:variable name="General.ProductNameXAP" /> Manager; it explains how to setup multiple LUSs manually to achieve high availability. This technique is still supported, but outdated, and will be phased out in the future. It's highly recommended to use <a href="xap-manager.html">the Manager</a> instead, which is both easier to use and provides superior <a href="xap-manager.html#high-availability">high availability</a>.</p>
        </div><a name="global-lus"></a>
        <h1><a name="global-lus"></a>Global LUS</h1>
        <p>When you would like to have a fully dynamic elastic environment where the lookup service (LUS) may be running on <span class="tc-bold">any machine</span> on the network to serve multiple LUS machine failure (for existing machines or to be started in the future) you should consider using the <span class="tc-bold">global</span> LUS setup.</p>
        <p>With the global LUS setup you should rely on multicast lookup discovery mechanism to locate running lookup services. This discovery process executed by the service grid components (GSC , GSM) - configured via the <code><MadCap:variable name="General.EnvVariablePrefix" />_LOOKUP_GROUPS</code> environment variable) or client applications when constructing their data grid proxy - configured via the <code>groups</code> URL String (i.e. <code>jini://*/*/DataGridName?groups=myGroup</code>) or <code>lookup-groups</code> spring property as part of the <code>pu.xml</code>.
Another alternative is to use unicast based lookup discovery and specify with the <code><MadCap:variable name="General.EnvVariablePrefix" />_LOOKUP_LOCATORS</code> environment variable all existing and future machines that are running/may be running the LUS. Same with the space Url on the client side (i.e. <code>jini://LUS_HOST1,LUS_HOST2/*/DataGridName</code>). In most cases its much simpler to use the multicast lookup discovery mechanism.</p>
        <p>With the global LUS setup you should have two LUSs running across your service grid - these are running in <span class="tc-bold">active-active</span> configuration. This means all agents are equal with their setup. They will be communicating with each other to preserve the exact amount of specified LUSs. Once a running LUS failed (as a result of machine termination, or LUS process failure) , a different agent that is not currently running a LUS will be starting a LUS to enforce the SLA specified at the agent startup. The <code>timeout</code> space URL property (i.e. <code>jini://*/*/DataGridName?timeout=10000</code>) or <code>lookup-timeout</code> Spring property with the <code>pu.xml</code> allows you to specify the LUS multicast discovery timeout.</p>
        <h1><a name="global-setup-example"></a>Global Setup Example</h1>
        <p>With the following example we have <code>Machine A</code>, <code>Machine B</code>, <code>Machine C</code> and <code>Machine D</code> running the service grid.</p>
        <div class="tc-align-center">
            <img src="../Resources/Static/attachment_files/global-localLUS2.jpg" alt="global-localLUS2.jpg" class="tc-picture80" />
        </div>
        <p>All agents are started with the same command instructing them to maintain two global LUSs across the entire service grid:</p><pre><code class="language-bash">gs-agent --global.lus=2
</code></pre>
        <p>Upon startup the agents will decide which ones will run a LUS and which won't.
To enable this dynamic setup you should have multicast enabled between all service grid machines and also between client applications machines and service grid machines. To differentiate between different service grids running on the same network you should specify a unique <code><MadCap:variable name="General.EnvVariablePrefix" />_LOOKUP_GROUPS</code> environment variable value for the service grid machines before starting the agent. The client application should specify the right group via the URL (i.e. <code>jini://*/*/DataGridName?groups=myGroup</code>) or via the <code>lookup-groups</code> spring property as part of the pu.xml.</p><a name="local-lus"></a>
        <h1><a name="local-lus"></a>Local LUS</h1>
        <p>With the local lookup service setup you should specify a list of known machines to run the LUS. This list (two recommended) should be configured on the service grid via the <code><MadCap:variable name="General.EnvVariablePrefix" />_LOOKUP_LOCATORS</code> environment variable (comma delimited) and also with the client application space URL (i.e. <code>jini://LUS_HOST1, LUS_HOST2/*/DataGridName</code>) or via the <code>lookup-locators</code> Spring property .</p>
        <h1><a name="local-setup-example"></a>Local Setup Example</h1>
        <p>With the following example we have <code>Machine A</code>, <code>Machine B</code>, <code>Machine C</code> and <code>Machine D</code> running the service grid.  We would like to start two LUSs across these machines. We have decided that <code>Machine A</code> and <code>Machine D</code> will be running a LUS.</p>
        <div class="tc-align-center">
            <img src="../Resources/Static/attachment_files/global-localLUS1.jpg" alt="global-localLUS1.jpg" class="tc-picture80" />
        </div>
        <p>The agent on these machines will be started using the following:</p><pre><code class="language-bash">gs-agent --lus=1
</code></pre>
        <p><code>Machine B</code> and <code>Machine C</code> will not run the lookup service. The agent on the machines will be started using the following:</p><pre><code class="language-bash">gs-agent 
</code></pre>
        <p>Upon startup the only <code>Machine A</code> and <code>Machine D</code> agent's that are configured to start a local LUS will have it running.  In case of <code>Machine A</code> or <code>Machine D</code> failure the system will have a single LUS. Service Grid components (GSC , GSM) and client applications will keep looking for this missing LUS internally (configured via the <code>com.gigaspaces.unicast.interval</code>  system property).</p>
        <p>Once the missing LUS machine will be restarted they will reconnect. With a network running a DNS - you may start a new machine with the same Host name to support total machine failure while keeping number of running LUSs intact.</p>
    </body>
</html>