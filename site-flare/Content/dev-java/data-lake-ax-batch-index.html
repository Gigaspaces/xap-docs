<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
        <h1 class="tc-pagetitle">Intelligent Tiering</h1>
        <p MadCap:conditions="Default.DoNotShow"><MadCap:variable name="General.ProductNameIE" /> only</p>
        <p>Indexing is an effective way to improve performance in file systems with regular databases. However, organizations can store up to terabytes and petabytes of data in data lakes. Indexing all of the data in the data lake is impractical because the index itself would be very large; while indexing might improve performance, it isn't cost effective because of the memory storage required to support such a large index. </p>
        <p>AnalyticsXtreme provides intelligent data tiering with its batch indexing feature, which enables differentiating between older (cold) data  that is still frequently accessed, and data that can be archived because it is only relevant for historical purposes. This keeps the size of the index small while still providing high performance.</p>
        <p>Using batch indexing, you can create a full data life cycle policy that automatically tiers your aging data into cold and archive storage in your data lake, to complement AnalyticsXtreme's handling of hot and warm data that is ingested in automatic data tiering mode. This end-to-end approach optimizes your data storage, so you can maintain the right balance between performance and cost as data moves between the frequent access and infrequent access tiers.</p>
        <div class="tc-admon-note">
            <p>Hive with Hadoop is currently the only supported data storage solution.</p>
        </div>
        <h1>Data Life Cycle</h1>
        <p>The basic AnalyticsXtreme data life cycle from speed (hot) to batch (cold)  is detailed in the <MadCap:xref href="data-lake-acceleration.html">Data Lake Acceleration</MadCap:xref> topic. Batch indexing, which also leverages <MadCap:variable name="General.CompanyName" />'s MemoryXtend module, extends the life cycle from speed (hot) to batch (warm) to index (cold) to out (archive). </p>
        <p>As data moves from the speed layer to the batch layer, it is added to the batch index as it moves through the speed layer eviction time window (buffer). As the data moves into the batch layer, it is directed to the relevant partitions and buckets. At this point, the data is still available for frequent access.</p>
        <p> As the batch layer time window expires, the data moves into the batch index eviction time window and when this expires, the data is expunged from the index and is available only as archive data.</p>
        <p>&#160;</p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/lambda/AX-batch-index.png" class="tc-picture80" />
            </p>
        </div>
        <h1>Index Entry Structure</h1>
        <p>AnalyticsXtreme batch indexing leverages the functionality of Apache Hive, which is an SQL&#160;engine over Hadoop. Hive uses partitions and buckets to categorize data in the Hadoop file system, so you can designate a specific location for each type of data.</p>
        <p>For example, you might partition your data according to city, but then want to query by customer name. In order to successfully query this in Hive, you need to map the names to the cities.</p>
        <div class="tc-admon-note">
            <p> Spark doesn't currently support querying buckets, only partitions.</p>
        </div>
        <p>As batch indexing is a time-based feature, the data is segmented in time slices.</p>
        <h2>Accuracy vs. Size</h2>
        <p>The <span class="tc-italic">batch index period </span>is the entire amount of cold data in the batch layer that is indexed. For example, want to index one month out of a full year of data - one month is the index period. The month needs to be segmented into time slices called buckets (this is the index granularity). The more granular you get, the larger the index which is a tradeoff for greater accuracy. The longer the time slice the less granular, so the less accurate but you get better performance/ smaller footprint in memory. Index is deployed in MX space over SSD.</p>
        <p>&#160;</p>
        <p>Speed space is the AX speed layer. Batch index space is MX over SSD&#160;space where the index is stored. <MadCap:variable name="General.ProductNameIE" /> JDBC&#160;driver is used to communicate from the AX&#160;client side. When index is deployed, need to do an initial indexing of the required index period. This index will only be available to optimize search time until it is completely initialized. You can run your query, but you don't get the benefit of the faster search because you weren't able to use the index.</p>
        <p>data is regularly moved from the speed layer to the batch later (only the data that matches the partition/bucket definitions and has a time value). </p>
        <p>Note:&#160;Null is not a legitimate value.</p>
        <p>As part of this process, the data is indexed before it's cached in the speed buffer. If a query is executed in the AX&#160;client, first step is to check whether index is available. Then verifies that all the required data is within the defined index period (if the time definition exceeds the index period, the index isn't used in the query because there won't be data consistency). If yes, query is run using the index. The relevant partitions are returned - meaning those that contain data that match the query. Then the original query from the client is updated with the partition condition.</p>
        <p>example query would be to look for Niv and he is a match for three city partitions (Jerusalem, Tel Aviv, and Haifa). then the query would be name=Niv and partition=Jerusalem, Tel Aviv, Haifa. So the query only searches those three partitions instead of searching all the partitions, which speeds up the query considerably.</p>
        <p>&#160;</p>
        <p>&#160;</p>
        <h1>Zeppelin Examples</h1>
        <h2>XetraStockMarketTrade</h2>
        <p>running the example without the batch index takes over 4 minutes (full scan of maybe 30MB of data, which isn't a lot) in Hive.</p>
        <p>When the query is run with the batch index, it takes about 3 seconds. the securityType (ETN) that was the target of the query was present in about 100 of the 1900 partitions in Hive, so using the batch index meant that 99% of the available partitions didn't actually have to be scanned.</p>
        <h2>Efficiency Query</h2>
        <p>Zeppelin also has a Batch Index Efficiency query to assess how effective it is to use the batch index to improve performance.</p>
        <h2>Adding Custom Queries and Data</h2>
        <p>There are also statistics that are saved in the same object and so can used for demo purposes. This is for when you add your own data and apply your own queries, so you can see how effective batch indexing is on your own data.</p>
    </body>
</html>