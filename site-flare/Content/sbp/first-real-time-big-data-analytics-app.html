<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
<head></head>
<body>
<h1>Real Time Big Data Analytics</h1>
  

<table class="tc-borderless"><tr><td style="width:80%;"><p><br/>
We live almost every aspect of our lives in a real-time world. Think about our social communications; we update our friends online via social networks and micro-blogging, we text from our cell phones, or message from our laptops. But it's not just our social lives; we shop online whenever we want, we search the web for immediate answers to our questions, we trade stocks online, we pay our bills, and do our banking. All online and all in real time.</p>
</td>
<td style="width:20%;"><p><MadCap:snippetBlock src="Resources/Snippets/YouTube.flsnp" MadCap:snippetVariables="Links.YouTube:https://www.youtube.com/watch?v=ioHwEsARPWI," /></p>
</td>
</tr></table>

<p>Real time doesn't just affect our personal lives. Enterprises and government agencies need real-time insights to be successful, whether they are investment firms that need fast access to market views and risk analysis, or retailers that need to adjust their online campaigns and recommendations to their customers. Even homeland security has come to increasingly rely on real-time monitoring.
The amount of data that flows in these systems is huge. Twitter, for example, 500 million Tweets per day, which is nearly 3,000 Tweets per second, on average.  At various peak moments through 2011, Twitter did as high as 8,000+ TPS, with at least one instance of over 25,000 tps. Facebook gets 100 billion hits per day with 3.2B Likes &amp; Comments/day. Google get 2 billion searches a day. These numbers are growing as more and more users join the service.</p>

<p>This tutorial explains the challenges of a Real-time (RT) Analytics system using Twitter as an example, and show in details how these challenges can be met by using GigaSpaces XAP.</p>

<h1><a name="the-challenge">&#160;</a>The Challenge</h1>

<p>Twitter users aren't just interested in reading tweets of the people they follow; they are also interested in finding new people and topics to follow based on popularity. This poses several challenges to the Twitter architecture due to the vast volume of tweets. In this example, we focus on the challenges relating to calculating the <span class="tc-bold">word count</span> use case. The challenge here is straightforward:</p>

<ol>
<li>Tens of thousands of tweets need to be stored and parsed every second.</li>
<li>Word counters need to be aggregated continuously. Since tweets are limited to 140 characters, we are dealing with hundreds of thousands of words per second.</li>
<li>Finally, the system needs to scale linearly so the stream can grow as the business grows.</li>
</ol>

<p>These challenges are not simple to deal with as there are knock-on effects from the volume and analysis of the data, as follows:</p>

<ul>
<li>Tens of thousands of tweets to tokenize every second, meaning hundreds of thousands of words to filter -&gt; <span class="tc-bold">CPU bottleneck</span></li>
<li>Tens/hundreds of thousands of counters to update -&gt; <span class="tc-bold">Counters contention</span></li>
<li>Tens/hundreds of thousands of counters to persist -&gt; <span class="tc-bold">Database bottleneck</span></li>
<li>Tens of thousands of tweets to store in the database every second -&gt; <span class="tc-bold">Database bottleneck</span></li>
</ul>

<h1><a name="solution-architecture">&#160;</a>Solution Architecture</h1>

<table class="tc-borderless"><tr><td style="width:90%;"><p>In designing a solution, we need to consider the various challenges we must address.</p>

<p>The first challenge is providing <span class="tc-bold">unlimited scalability</span> - therefore, we are talking about dynamically increasing resources to meet demand, and hence implementing a distributed solution using parallelized processing approach.</p>

<p>The second challenge is providing <span class="tc-bold">low latency</span> - we can't afford to use a distributed file system such as Hadoop HDFS, a relational database or a distributed disk-based structured data store such as NoSQL database. All of these use physical I/O that becomes a bottleneck when dealing with massive writes. Furthermore, we want the business logic collocated with the data on a single platform for faster processing, with minimal network hops and integration issues.</p>
</td>
<td style="width:10%;"><p><img src="/attachment_files/map_reduce.png" class="tc-thumbnail" /></p>
</td>
</tr></table>

<p>To overcome the latency challenge, we use an in-memory system of record. GigaSpaces XAP is built just for that. Its core component is <a href="/product_overview/the-in-memory-data-grid.html">in-memory data grid</a> (IMDG, a.k.a. the Space) that partitions the data based on a specified attribute within the data object. The data grid uses a share nothing policy, and each primary node has consistent backup. In addition the grid keeps its SLA by self-healing crashed nodes, so it's completely consistent and highly-available.</p>

<p>The third challenge is the <span class="tc-bold">efficient processing</span> of the data in a distributed system. To achieve this, we use the <span class="tc-bold">Map</span> / <span class="tc-bold">Reduce</span> algorithm for distributed computing on large data sets on clusters of computers. In the <span class="tc-bold">Map</span> step, we normalize the data so we can create local counters. In the <span class="tc-bold">Reduce</span> step, we aggregate the entire set of interim results into a single set of results.</p>

<table class="tc-borderless"><tr><td style="width:80%;"><p>In our Twitter example, we need to build a flow that provides the <span class="tc-bold">Map</span> / <span class="tc-bold">Reduce</span> flow in real time. For this we use XAP's Processing and Messaging features collocated with its corresponding data.</p>
</td>
<td style="width:10%;"><p><img src="/attachment_files/map_reduce_tweets.png" class="tc-thumbnail" /></p>
</td>
</tr></table>

<p>Our solution uses two main modules:</p>

<h2><a name="feeder">&#160;</a>Feeder</h2>

<p>The <span class="tc-bold">feeder</span> write raw tweets into the Space (IMDG)â€“ The tweets are routed to their relevant partition using their ID (assumed to be globally unique). This makes the solution scalable.</p>

<h2><a name="processor">&#160;</a>Processor</h2>

<p>The <span class="tc-bold">processor</span> module implements the <span class="tc-bold">Map/Reduce</span> algorithm that processes tweets in the Space, resulting in real-time word counts. The tweets are then moved from the Space to the historical data store. The processor performs the following steps:</p>

<ol>
<li>Tokenizes tweets into maps of tokens and writes them to the Space (triggered by the writing of raw tweets to the Space).</li>
<li>Filters unwanted words from the maps of tokens and writes the filtered maps to the Space (triggered by the writing of maps of tokens to the Space).</li>
<li>Generates a token counter per word, distributing the counters across the grid partitions for scalability and performance (triggered by the writing of filtered maps of tokens to the Space).</li>
</ol>

<p>The processor's <span class="tc-bold">Reduce</span> phase aggregates the local results into global word counters.</p>

<h1><a name="implementing-the-solution">&#160;</a>Implementing the Solution</h1>

<table class="tc-borderless"><tr><td style="width:90%;"><p>We use a local file to store the historical data. XAP will process and persist the data in real-time using the following modules:</p>
</td>
<td style="width:10%;"><p><img src="/attachment_files/twitter_topo.png" class="tc-thumbnail" /></p>
</td>
</tr></table>

<ul>
<li><p>The <span class="tc-bold">processor</span> module is a XAP <a href="/xap/14.0/dev-java/the-processing-unit-structure-and-configuration.html">processing unit</a> that contains the Space and performs the real-time workflow of processing the incoming tweets. The processing of data objects is performed using event containers.</p></li>

<li><p>The <span class="tc-bold">feeder</span> module is implemented as well as a processing unit. It is simulating tweets , converting them to Space Documents objects and writes them to the Space. This in turn invokes the relevant event processors on the processor module.</p></li>

<li><p>The <span class="tc-bold">common</span> module including items that are shared between the feeder and the processor modules (e.g. common interfaces, shared data model, etc.).</p></li>
</ul>

<h1><a name="building-the-application">&#160;</a>Building the Application</h1>

<p>The following are step-by-step instructions building the application:</p>

<ol>
<li><p>Install XAP
Follow these <a href="/xap/14.0/started/installation.html">instructions</a> to download and install the latest version of XAP.</p></li>

<li><p>Get the demo application code from github
Get the <a href="https://github.com/gigaspaces/rt-analytics-streaming-bigdata">demo application</a> and place the files under an empty folder.</p></li>

<li><p>Install Maven and the GigaSpaces Maven plug-in
The application uses <a href="http://maven.apache.org/">Apache Maven</a>. If you don't have Apache Maven installed, please <a href="http://maven.apache.org/download.html#Installation">download</a> and install it. Once installed:</p></li>
</ol>

<ul>
<li>Set the <code>MVN_HOME</code> environment variable</li>
<li>Add <code>$MVN_HOME/bin</code> to your path.</li>
<li>Run the GigaSpaces Maven plug-in installer by calling the <code>&lt;XapInstallationRoot&gt;/tools/maven/installmavenrep.bat/sh</code> script.</li>
</ul>

<ol>
<li>Building the Application
Move to the application root folder. Edit the <code>pom.xml</code> file and make sure the <code>&lt;gsVersion&gt;</code> include the correct XAP release you have installed. For example if you have XAP [%=Versions.xap-version%] installed you should have the following:</li>
</ol>

<pre><code class="language-bash">&lt;properties&gt;
    &lt;gsVersion&gt;[%=Versions.maven-version%]&lt;/gsVersion&gt;
&lt;/properties&gt;
</code></pre>

<p>To Build the project type the following at your command (Windows) or shell (*nix):</p>

<pre><code class="language-bash">mvn package
</code></pre>

<p>The Maven build will download the required dependencies, compile the source files, run the unit tests, and build the required jar files. In our example, the following processing unit jar files are built:</p>

<ul>
<li><code>&lt;project root&gt;/feeder/target/rt-feeder-rt-analytics1.0.jar</code></li>
<li><code>&lt;project root&gt;/processor/target/rt-processor-rt-analytics1.0.jar</code></li>
</ul>

<p>Once the build is complete, a summary message similar to the following is displayed:</p>

<pre><code class="language-bash">[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO]
[INFO] rt-analytics ...................................... SUCCESS [0.001s]
[INFO] rt-common ......................................... SUCCESS [2.196s]
[INFO] rt-processor ...................................... SUCCESS [11.301s]
[INFO] rt-feeder ......................................... SUCCESS [3.102s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 16.768s
[INFO] Finished at: Sun May 13 13:38:06 IDT 2012
[INFO] Final Memory: 14M/81M
[INFO] ------------------------------------------------------------------------
</code></pre>

<h1><a name="running-and-debugging-the-application-within-an-ide">&#160;</a>Running and Debugging the Application within an IDE</h1>

<p>Since the application is a Maven project, you can load it using your Java IDE and thus automatically configure all module and classpath configurations.</p>

<ul>
<li>With <a href="http://www.eclipse.org">Eclipse</a>, install the <a href="http://eclipse.org/m2e/m2e-downloads.html">M2Eclipse plugin</a> and click "File -&gt; Import" , "Maven -&gt; Existing Maven Projects" , select the <code>streaming-bigdata</code> folder and click the <code>Finish</code> button.</li>
</ul>

<table class="tc-borderless"><tr><td style="width:30%;"><p><img src="/attachment_files/rt-ide1.jpg" class="tc-thumbnail" /></p>
</td>

<td style="width:30%;"><p><img src="/attachment_files/rt-ide2.jpg" class="tc-thumbnail" /></p>
</td>

<td style="width:30%;"><p><img src="/attachment_files/rt-ide3.jpg" class="tc-thumbnail" /></p>
</td>
</tr></table>

<p>Once the project is loaded in your IDE, you can run the application, as follows:</p>

<p>In <span class="tc-bold">Eclipse</span>, create two run configurations. One for the <span class="tc-bold">feeder</span> and one for the <span class="tc-bold">processor</span>. For both, the main class must be [IntegratedProcessingUnitContainer][%=Links.ApiJavaDoc%]/org/openspaces/pu/container/integrated/IntegratedProcessingUnitContainer.html).</p>

<p>rt-processor project run configuration:</p>

<table class="tc-borderless"><tr><td style="width:30%;"><p><img src="/attachment_files/rt-processor1.png" class="tc-thumbnail" /></p>
</td>

<td style="width:30%;"><p><img src="/attachment_files/rt-processor2.png" class="tc-thumbnail" /></p>
</td>
</tr></table>

<p>rt-feeder project run configuration:</p>

<table class="tc-borderless"><tr><td style="width:30%;"><p><img src="/attachment_files/rt-feeder1.png" class="tc-thumbnail" /></p>
</td>

<td style="width:30%;"><p><img src="/attachment_files/rt-feeder2.png" class="tc-thumbnail" /></p>
</td>
</tr></table>

<p>For more information about the <code>IntegratedProcessingUnitContainer</code> class (runs the processing units within your IDE), see <a href="/xap/14.0/started/xap-ide.html">Running and Debugging Within Your IDE</a>.</p>

<div class="tc-admon-tip">
  
  <p>Make sure you have updated <span class="tc-bold">gslicense.xml</span> located under the GigaSpaces XAP root folder with the license key provided as part of the email sent to you after downloading GigaSpaces XAP.</p>
</div>

<p>To run the application, run the <span class="tc-bold">processor</span> configuration, and then the <span class="tc-bold">feeder</span> configuration. An output similar to the following is displayed:</p>

<pre><code class="language-bash">2013-02-22 13:09:38,524  INFO [org.openspaces.bigdata.processor.TokenFilter] - filtering tweet 305016632265297920
2013-02-22 13:09:38,526  INFO [org.openspaces.bigdata.processor.FileArchiveOperationHandler] - Writing 1 object(s) to File
2013-02-22 13:09:38,534  INFO [org.openspaces.bigdata.processor.TweetArchiveFilter] - Archived tweet 305016632265297920
2013-02-22 13:09:38,535  INFO [org.openspaces.bigdata.processor.LocalTokenCounter] - local counting of a bulk of 1 tweets
2013-02-22 13:09:38,537  INFO [org.openspaces.bigdata.processor.LocalTokenCounter] - writing 12 TokenCounters across the cluster
2013-02-22 13:09:38,558  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token arrive by 1
2013-02-22 13:09:38,606  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token Reine by 1
2013-02-22 13:09:38,622  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token pute by 1
2013-02-22 13:09:38,624  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token lyc?e by 2
2013-02-22 13:09:41,432  INFO [org.openspaces.bigdata.processor.TweetParser] - parsing tweet SpaceDocument .....
2013-02-22 13:09:41,440  INFO [org.openspaces.bigdata.processor.TokenFilter] - filtering tweet 305016630734381057
2013-02-22 13:09:41,441  INFO [org.openspaces.bigdata.processor.FileArchiveOperationHandler] - Writing 1 object(s) to File
2013-02-22 13:09:41,447  INFO [org.openspaces.bigdata.processor.LocalTokenCounter] - local counting of a bulk of 1 tweets
2013-02-22 13:09:41,448  INFO [org.openspaces.bigdata.processor.LocalTokenCounter] - writing 11 TokenCounters across the cluster
2013-02-22 13:09:41,454  INFO [org.openspaces.bigdata.processor.TweetArchiveFilter] - Archived tweet 305016630734381057
2013-02-22 13:09:41,463  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token Accounts by 1
2013-02-22 13:09:41,485  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token job by 1
2013-02-22 13:09:41,487  INFO [org.openspaces.bigdata.processor.GlobalTokenCounter] - Increment  local token time by 1
</code></pre>

<h1><a name="running-the-application-with-xap-runtime-environment">&#160;</a>Running the Application with XAP Runtime Environment</h1>

<p>The following are step-by-step instructions for running the application in XAP:</p>

<ul>
<li><a href="http://www.gigaspaces.com/LatestProductVersion">Download</a> and <a href="/xap/14.0/started/installation.html">install</a> XAP.</li>
<li>Edit <code>&lt;XapInstallationRoot&gt;/gslicense.xml&gt;</code> and place the license key file provided with the email sent to you after downloading GigaSpaces XAP as the <code>&lt;licensekey&gt;</code> value.</li>
<li>Make sure you have the <code>feeer</code> and <code>processor</code> PUs built.</li>
<li>Start a <a href="/product_overview/service-grid.html#gsa">Grid Service Agent</a> by running the <code>gs-agent.sh/bat</code> script.</li>
</ul>

<div class="easyui-tabs" plain="true" data-options=""><div title="  Unix " style="padding:10px"><pre><code class="language-bash">nohup ./gs-agent.sh &gt;/dev/null 2&gt;&amp;1
</code></pre>
</div>
<div title="  Windows " style="padding:10px"><pre><code class="language-bash">start /min gs-agent.bat
</code></pre>
</div>
</div>

<ul>
<li>Deploy the processor</li>
</ul>

<div class="easyui-tabs" plain="true" data-options=""><div title="  Unix " style="padding:10px"><pre><code class="language-bash">./gs.sh deploy ../processor/target/rt-processor-rt-analytics1.0.jar
</code></pre>
</div>
<div title="  Windows " style="padding:10px"><pre><code class="language-bash">gs deploy ..\processor\target\rt-processor-rt-analytics1.0.jar
</code></pre>
</div>
</div>

<p>You should see the following output:</p>

<pre><code class="language-bash">Deploying [rt-processor-rt-analytics1.0.jar] with name [rt-processor-rt-analytics1.0] under groups [[%=Versions.default-lookup-group%]] and locators []
Uploading [rt-processor-rt-analytics1.0] to [http://127.0.0.1:61765/]
Waiting indefinitely for [4] processing unit instances to be deployed...
[rt-processor-rt-analytics1.0] [1] deployed successfully on [127.0.0.1]
[rt-processor-rt-analytics1.0] [1] deployed successfully on [127.0.0.1]
[rt-processor-rt-analytics1.0] [2] deployed successfully on [127.0.0.1]
[rt-processor-rt-analytics1.0] [2] deployed successfully on [127.0.0.1]
Finished deploying [4] processing unit instances
</code></pre>

<ul>
<li>Deploy the feeder:</li>
</ul>

<div class="easyui-tabs" plain="true" data-options=""><div title="  Unix " style="padding:10px"><pre><code class="language-bash">./gs.sh deploy ../feeder/taret/rt-feeder-rt-analytics1.0
</code></pre>
</div>
<div title="  Windows " style="padding:10px"><pre><code class="language-bash">gs deploy ..\feeder\target\rt-feeder-rt-analytics1.0
</code></pre>
</div>
</div>

<div class="tc-admon-important">
  
  <p>You will need XAP PREMIUM edition license key to deploy the processor in a clustered configuration</p>
</div>

<p>You should see the following output:</p>

<pre><code class="language-java">Deploying [rt-feeder-rt-analytics1.0.jar] with name [rt-feeder-rt-analytics1.0] under groups [[%=Versions.default-lookup-group%]] and locators []
Uploading [rt-feeder-rt-analytics1.0] to [http://127.0.0.1:61765/]
SLA Not Found in PU.  Using Default SLA.
Waiting indefinitely for [1] processing unit instances to be deployed...
[rt-feeder-rt-analytics1.0] [1] deployed successfully on [127.0.0.1]
Finished deploying [1] processing unit instances
</code></pre>

<p>Once the application is running, you can use the XAP UI tools to view your application , access the data and the counters and manage the application:</p>

<ul>
<li>For the Web Based UI run gs-webui.bat/sh and point your browser to <code>localhost:8099</code></li>
<li>For the Rich Based UI run gs-ui.bat/sh</li>
</ul>


<div class='bs-callout bs-callout-info'>
    <b style="">More Deployment Options </b><br/>
    <p>To learn about additional options for deploying your XAP processing units, please see <a href="/xap/14.0/dev-java/deploying-onto-the-service-grid.html">Deploying onto the Service Grid</a></p>
</div>





<h1><a name="viewing-most-popular-words">&#160;</a>Viewing Most Popular Words</h1>

<p>To view the most popular words , start the GS-UI using the gs-ui.bat/sh , click the Query icon as demonstrated below and execute the following SQL Query by clicking the <img src="/attachment_files/rt-tw6.jpg" alt="rt-tw6.jpg" /> button:</p>

<pre><code class="language-bash">select uid,* from org.openspaces.bigdata.common.counters.GlobalCounter order by counter DESC
</code></pre>

<p>You should see the top most popular words on twitter ordered by their popularity:</p>

<img src="/attachment_files/rt-tw4new.jpg" class="tc-thumbnail" />

<p>You can re-execute the query just by clicking the <img src="/attachment_files/rt-tw5.jpg" alt="rt-tw5.jpg" /> button again. This will give you real-time view on the most popular words on Twitter.</p>

</body>
</html>