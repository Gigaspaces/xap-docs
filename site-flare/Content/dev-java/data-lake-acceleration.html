<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head>
    </head>
    <body>
        <h1>Data Lake Acceleration</h1>
        <p MadCap:conditions="Default.DoNotShow"><MadCap:variable name="General.ProductNameIE" /> only</p>
        <h1>Overview</h1>
        <p>Big data adoption in enterprises is increasing all the time, with no sign of stopping. The Apache Spark MLlib&#160;and&#160;Tensorflow&#160;are among the most-adopted big data analytics platforms, while Cloudera,&#160;Amazon EMR,&#160;Hortonworks, and&#160;MapR&#160;are popular big data distributions. Patching all these technologies together into the classic Lambda architecture presents a number of customer challenges. </p>
        <ul>
            <li>Increasing system complexity - traditional Lambda architectures simply keep adding components as new technologies come into play, which slows down queries and is difficult to maintain.</li>
            <li>Data freshness - New data may only be accessible to users once every X hours, which is too slow to make real-time decisions.</li>
            <li>One-way, immutable data flow - If data contains a lot of update operations, and big data platforms such as HDFS and Parquet don't support data updates, all ingestion jobs needed to create new snapshots.</li>
        </ul>
        <p>AnalyticsXtreme is a data lake accelerator that  operationalizes your data lake for real-time analytics, which can run simultaneously on both real-time, mutable streaming data and on historical data that is stored on data lakes based on Hadoop, Amazon S3 or Azure Blob Storage, as well as data warehouses such as Snowflake, without requiring a separate data load procedure or data duplication.  Moving from on-premise to the cloud, or changing technology stacks for example from Cloudera to Amazon S3, is seamless to machine learning applications; increasing flexibility while reducing development and maintenance. </p>
        <p>With AnalyticsXtreme, your data is available for immediate searching, queries, and running analytics; there is a single logical view for hot, warm and cold data. The hot data resides on <MadCap:variable name="General.ProductNameIE" />'s in-memory data grid, while cold (historical) data can be stored on any big-data platform such as HDFS or Amazon S3. Additionally, the hot data is mutable, supporting real-time updates. The data becomes immutable when it is stored on the external big data platform.</p>
        <p>This approach enables fast access to frequently used historical data, and applications can access any data - hot, warm, or cold - via a unified layer using Spark SQL or JDBC. You can easily integrate BI&#160;tools such as <a href="tableau.html">Tableau</a>, Looker, and PowerBI.</p>
        <p> AnalyticsXtreme provides automatic life cycle management, handling the underlying data movement, optimization and deletion using an internal data life cycle policy.</p>
        <h1>Implementation</h1>
        <p MadCap:conditions="Default.DoNotShow">AnalyticXtreme (get from Niv)</p>
        <div class="tc-align-center">
            <p>
                <img src="../Resources/Static/attachment_files/lambda/AnalyticsXtreme.png" class="tc-picture50" />
            </p>
        </div>
        <h1>Configuring the Data Life Cycle Policy</h1>
        <h2>Global Properties</h2>
        <p>The global configuration contains a list of DataLifecyclePolicy properties, as well as the following parameters that are set for the entire application:</p>
        <table style="width: 100%;" class="tc-standard">
            <col />
            <col />
            <col />
            <col />
            <col />
            <thead>
                <tr>
                    <th>Parameter</th>
                    <th>Description</th>
                    <th>Unit</th>
                    <th>Default Value</th>
                    <th>Required/Optional</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>verbose </td>
                    <td>Increases the log levels for both the client and the server to provide verbose information (useful for troubleshooting).</td>
                    <td>True/False</td>
                    <td>False</td>
                    <td>Optional</td>
                </tr>
                <tr>
                    <td>evictionPollingInterval </td>
                    <td>Polling interval for querying and evicting each policy.</td>
                    <td>Minutes (m)</td>
                    <td>1 m</td>
                    <td>Optional</td>
                </tr>
            </tbody>
        </table>
        <h2>Table (Object) Properties</h2>
        <p>The DataLifecyclePolicy table contains the following parameters.</p>
        <table style="width: 100%;" class="tc-standard">
            <col />
            <col />
            <col />
            <col />
            <col />
            <thead>
                <tr>
                    <th>Parameter</th>
                    <th>Description</th>
                    <th>Unit</th>
                    <th>Default Value</th>
                    <th>Required/Optional</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>tableName *</td>
                    <td>Name of the table/type/class to which this policy applies.</td>
                    <td>&#160;</td>
                    <td>&#160;</td>
                    <td>Required</td>
                </tr>
                <tr>
                    <td>timeColumn** </td>
                    <td>Name of column/property/field that contains the time data used to manage this policy.</td>
                    <td>&#160;</td>
                    <td>&#160;</td>
                    <td>Required</td>
                </tr>
                <tr>
                    <td>timeFormat </td>
                    <td>Time format for the data in the timeColumn parameter.</td>
                    <td>&#160;</td>
                    <td>by java</td>
                    <td>Optional</td>
                </tr>
                <tr>
                    <td>speedPeriod </td>
                    <td>Time period or fixed timestamp.</td>
                    <td>&#160;</td>
                    <td>&#160;</td>
                    <td>Required</td>
                </tr>
                <tr>
                    <td>batchDataSource </td>
                    <td>endpoint for querying the batch layer</td>
                    <td>&#160;</td>
                    <td>&#160;</td>
                    <td>Required</td>
                </tr>
                <tr>
                    <td>batchDataTarget </td>
                    <td>endpoint for feeding data to the batch layer</td>
                    <td>&#160;</td>
                    <td>&#160;</td>
                    <td>Required</td>
                </tr>
                <tr>
                    <td>mutabilityPeriod </td>
                    <td>Period of time during which data can be updated.</td>
                    <td> Duration in minutes (m) or % of speedPeriod.</td>
                    <td>80%</td>
                    <td>Optional</td>
                </tr>
                <tr>
                    <td>batchFeedInterval </td>
                    <td>Data is fed from the Space (speed layer) to the batch layer in these time-based intervals at the end of the speedPeriod, after the mutabilityPeriod has expired.</td>
                    <td>Minutes (m)</td>
                    <td>1 m</td>
                    <td>Optional</td>
                </tr>
                <tr>
                    <td>batchFeedSize </td>
                    <td>Maximum data entries per batch feed interval.</td>
                    <td>&#160;</td>
                    <td>
                        <p>1000 </p>
                    </td>
                    <td>Optional</td>
                </tr>
                <tr>
                    <td>evictionBuffer </td>
                    <td>Additional waiting period before evicting data from the Space (speed layer)&#160;after it was fed to the batch layer, so that long queries and clock differences won't cause errors or generate exceptions. </td>
                    <td>Duration in minutes (m) or % of speedPeriod.</td>
                    <td>10 m</td>
                    <td>Optional</td>
                </tr>
            </tbody>
        </table>
        <p>* This correlates to an object or JSON in the object store.</p>
        <p>** This correlates to a property or entity in an object or JSON.</p>
        <p MadCap:conditions="Default.DoNotShow">You can configure the following properties for the data life cycle policy:</p>
        <ul>
            <li MadCap:conditions="Default.DoNotShow">Storage/FS:  HDFS/S3 (for batch layer)</li>
            <li MadCap:conditions="Default.DoNotShow">Date &amp; Time: last N h</li>
            <li MadCap:conditions="Default.DoNotShow">Partition: by hour</li>
            <li MadCap:conditions="Default.DoNotShow">Primary: by ID (key)</li>
            <li MadCap:conditions="Default.DoNotShow">Size: up to NNN GB</li>
            <li MadCap:conditions="Default.DoNotShow">Deletion: Every N hours</li>
        </ul>
        <h2>Supported Data Formats</h2>
        <p>AnalyticsXtreme supports all the data formats that are supported by Apache Spark, such as Apache Parquet and Apache Avro.</p>
        <h1>Using the <MadCap:variable name="General.ProductNameIE" /> JDBC&#160;Driver</h1>
        <p MadCap:conditions="Default.DoNotShow">(Get from Niv)</p>
        <p>TBD</p>
        <h2>Supported Query Languages</h2>
        <ul>
            <li>Spark</li>
            <li>SQL</li>
            <li>JDBC</li>
        </ul>
        <h1>Limitations</h1>
        <p MadCap:conditions="Default.DoNotShow">Gaps: Join (Ayelet)</p>
        <p>TBD</p>
    </body>
</html>