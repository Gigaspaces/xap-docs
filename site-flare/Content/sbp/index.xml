<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sbp-rsses on XAP Documentation</title>
    <link>http://docs.gigaspaces.com/sbp.xml</link>
    <description>Recent content in Sbp-rsses on XAP Documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://docs.gigaspaces.com/sbp.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Solutions, Patterns &amp; Best Practices</title>
      <link>http://docs.gigaspaces.com/sbp.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp.html</guid>
      <description>&lt;p&gt;The content provided here is a collection of known patterns, solutions and best practices for GigaSpaces products, most of which are based on real-life use cases. Each topic is listed with its author/origin, and the product version that it was tested with. The content is divided into the following sections.&lt;/p&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;The topics are presented as is. While most of them are used in real-life use cases and production environments, they should not be considered as fully productized artifacts, and you should test them in your own environment before using them.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;./examples.html&#34;&gt;Examples&lt;/a&gt; - This section provides tutorials and examples of simple applications that can be developed and deployed with the data grid, covering several types of architectures and business needs.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./data-access-patterns.html&#34;&gt;Data Access Patterns&lt;/a&gt; - This section contains topics that address integrations with a wide variety of third-party applications and platforms, which may be helpful in the development process over GigaSpaces products.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./processing.html&#34;&gt;Parallel Processing and Message Patterns&lt;/a&gt; - This section contains a number of topics that describe a number of different processing and messaging patterns in detail.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./production.html&#34;&gt;Setup Production Environment&lt;/a&gt; - This section provides informaton and implementation examples that may be useful in the later stages of development, when production environment considerations become more important.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./wan-based-deployment.html&#34;&gt;WAN-Based Deployment&lt;/a&gt; - This section describes several use cases for implementing a WAN gateway for multi-region and disaster recovery scenarios.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./solutions.html&#34;&gt;Solutions&lt;/a&gt; - This section presents solutions to issues that may be encountered in the field.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./insightedge.html&#34;&gt;InsightEdge&lt;/a&gt; - This section describes integrations with analytics tools and libraries, along with integrations in Kubernetes environments.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Modeling your Data in a Distributed Environment</title>
      <link>http://docs.gigaspaces.com/sbp/modeling-your-data.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/modeling-your-data.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Shay Hassidim&lt;/td&gt;
&lt;td&gt;9.7&lt;/td&gt;
&lt;td&gt;March 2015&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://docs.gigaspaces.com/download_files//sbp/Space-Data-Model-Example.zip&#34;&gt;Space data model examples&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;moving-from-a-centralized-to-a-distributed-data-model&#34;&gt;Moving from a Centralized to a Distributed Data Model&lt;/h1&gt;

&lt;p&gt;When moving from a centralized into a distributed data store, your data must be partitioned across multiple nodes (or partitions). Implementing the partitioning mechanism isn&amp;rsquo;t a technically difficult task; however, planning the distribution of your data for scalability and performanc, requires some forethought.&lt;/p&gt;

&lt;p&gt;There are several questions that should be answered when planning your data partitioning:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What information I should store in memory?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The answer to this question is not technical, and should not be confused with the structure of the data. This is in essence a business question; how much the data will it grow over time, and for how long should it be kept?&lt;/p&gt;

&lt;p&gt;You can use the following table to estimate the answer:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Data Item&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Estimated Quantity&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Expected Growth&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Estimated Object Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Data Type A&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100K&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2K&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Data Type B&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;200K&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;20%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4K&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;After you have identified the size and expected growth of your data, you can start thinking about partitioning it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What are my application&amp;rsquo;s use cases?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A common approach is to model data according to the logical relationship of the data items. However, for distributed data a different approach is needed. The rule of thumb is to avoid cross-cluster relationships as much as possible, because they can lead to cross-cluster queries and updates that are usually much less scalable and slower than their local counterparts.&lt;/p&gt;

&lt;p&gt;It is deceptive to think in terms of traditional relationships (&amp;ldquo;one to one&amp;rdquo;, &amp;ldquo;one to many&amp;rdquo; and &amp;ldquo;many to many&amp;rdquo;) with distributed data. The first issue to consider is how many different associations each entity has. If an entity is associated with several containers (parent entities), that entity can&amp;rsquo;t be embedded within the containing entity. It might be also impossible to store the entity with all of its containers on the same partition.&lt;/p&gt;

&lt;p&gt;To answer this question effectively, you need to understand the implications of embedded relationships regarding your application. This concept is explained in further detail below.&lt;/p&gt;

&lt;h1 id=&#34;the-space-data-store&#34;&gt;The Space Data Store&lt;/h1&gt;

&lt;p&gt;A Space can store many type of entities. The Space can be compared to a database that can contain many tables, in the same way that a Space can contain many space classes. Practically speaking, there is no limit to the number of entities (Space classes or data types) you can store within a given Space cluster. Each Space class can contain an unlimited number of instances (Space objects or entries).&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/in-line-cache.jpg&#34; alt=&#34;in-line-cache.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Unlike legacy caching products that promote a Map-per-Entity storage model, with the Space data modeling approach you can treat all your application objects naturally, having one global in-memory data source regardless of their data type.&lt;/p&gt;

&lt;h1 id=&#34;embedded-vs-non-embedded-relationships&#34;&gt;Embedded vs. Non-Embedded Relationships&lt;/h1&gt;

&lt;h2 id=&#34;embedded-relationships&#34;&gt;Embedded Relationships&lt;/h2&gt;

&lt;p&gt;With Embedded Relationships, a parent object physically contains the associated object(s) and there is a &lt;strong&gt;strong&lt;/strong&gt; lifecycle dependency between them; when you delete the parent object, you also delete all of its contained objects. With this type of object association, all transactions are local because the entire object graph is stored in the same entry within the Space.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/model_embed.jpg&#34; alt=&#34;model_embed.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h3 id=&#34;embedded-relationship-data-retrieval-flow&#34;&gt;Embedded Relationship Data Retrieval Flow&lt;/h3&gt;

&lt;p&gt;When using the Embedded Relationship model, fetching objects from the Space is done using a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-sql.html&#34;&gt;SQLQuery&lt;/a&gt; with the &lt;code&gt;readMultiple&lt;/code&gt; call, or the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-paging-support.html&#34;&gt;IteratorBuilder&lt;/a&gt; when you have large sets of objects where the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-sql.html&#34;&gt;SQLQuery&lt;/a&gt; predicate uses root level or embedded object properties. With a single &lt;code&gt;SQLQuery&lt;/code&gt;, you can specify a query that spans objects from different data types related to each other or contained in each other. The embedded objects can be elements within an array, any type of collection (List, Map), or just a simple referenced object.&lt;/p&gt;

&lt;h3 id=&#34;updating-embedded-objects&#34;&gt;Updating Embedded Objects&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/change-api.html&#34;&gt;Change API&lt;/a&gt; allows you to modify a specific property(s) within the root space object (or any embedded object) without reading the entire object graph in an atomic manner. This optimizes the amount of data transferred between the client and the primary Space, and also between the primary and backup instances when replicating updates.&lt;/p&gt;

&lt;p&gt;With the embedded model, updating (as well adding or removing) a nested collection with large number of elements &lt;strong&gt;must use the Change API&lt;/strong&gt;, because the default behavior is to replicate the entire Space object and its nested collection elements from the primary instance to the backup (or other replica primary copies when using the sync-replicate or the async-replicated cluster schema). The Change API reduces CPU utilization on the primary side, the serialization overhead, and the garbage collection activity on both the primary and backup instances, which significantly improves overall system stability.&lt;/p&gt;

&lt;h2 id=&#34;non-embedded-relationships&#34;&gt;Non-Embedded Relationships&lt;/h2&gt;

&lt;p&gt;With Non-Embedded Relationships a parent object is associated with a number of other objects, so you can navigate from one object to others. However, there is no life cycle dependency between them, so if you delete the referencing object (parent), you don&amp;rsquo;t automatically delete the referenced (child) object(s). The association is therefore manifested in storing the child IDs in the parent rather than storing the actual associated object itself. This type of relationship means that you may want to access the child object separately without accessing their parent objects. This approach avoids the need to duplicate child objects if there are references from multiple parent objects. This approach may force you to perform multiple Space operations when accessing the entire parent-child graph across multiple Space cluster partitions.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/model_non_embed.jpg&#34; alt=&#34;model_non_embed.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h3 id=&#34;non-embedded-relationship-data-retrieval-flow&#34;&gt;Non-Embedded Relationship Data Retrieval Flow&lt;/h3&gt;

&lt;p&gt;The following topics describe the different data modeling options available with Non-Embedded Relationships.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/space-data-modeling-options.jpg&#34; alt=&#34;space-data-modeling-options.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h4 id=&#34;parent-first-data-retrieval-flow&#34;&gt;Parent-First Data Retrieval Flow&lt;/h4&gt;

&lt;p&gt;With this approach you first retrieve an initial set of &amp;ldquo;root space objects&amp;rdquo;, usually using a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-sql.html&#34;&gt;SQLQuery&lt;/a&gt; or a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-template-matching.html&#34;&gt;template&lt;/a&gt; with the &lt;code&gt;readMultiple&lt;/code&gt; call or the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-paging-support.html&#34;&gt;IteratorBuilder&lt;/a&gt; if you have a large set of objects. After that, you use metadata stored within these root space objects, such as the ID or IDs of related objects, and their routing field values (if they are distributed across remote multiple partitions) to fetch the related (child) objects using the &lt;code&gt;readById&lt;/code&gt; or &lt;code&gt;readByIds&lt;/code&gt; calls. Both &lt;code&gt;readById&lt;/code&gt; and &lt;code&gt;readByIds&lt;/code&gt; allow you to provide the routing field value, so there is no need to search the entire cluster for matching objects. You can also use the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/change-api.html&#34;&gt;Change API&lt;/a&gt; call to modify specific child objects without reading them first.&lt;/p&gt;

&lt;h4 id=&#34;child-first-data-retrieval-flow&#34;&gt;Child-First Data Retrieval Flow&lt;/h4&gt;

&lt;p&gt;With this approach the child object stores the parent object ID (and routing field value). You can access the referenced (child) objects directly, and from them you can access their parent object. You can query the Space for child objects via specific properties using a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-sql.html&#34;&gt;SQLQuery&lt;/a&gt; or a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-template-matching.html&#34;&gt;template&lt;/a&gt; with the &lt;code&gt;readMultiple&lt;/code&gt; call, iterate over the child object result set to collect the parent IDs, and read all relevant parent objects via the &lt;code&gt;readByIds&lt;/code&gt; call .&lt;/p&gt;

&lt;div class=&#34;tc-admon-tip&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;The data grid supports projections where you can read specific properties (delta read) instead of reading the entire Space object content. This may optimize the data retrieval flow.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h4 id=&#34;parent-child-bi-directional-data-retrieval-flow&#34;&gt;Parent-Child Bi-Directional Data Retrieval Flow&lt;/h4&gt;

&lt;p&gt;This is a hybrid approach of the Parent-First and Child-First flows, in which the parent stores the ID of the child objects and the child objects store the ID of the parent object. This enables you to choose the appropriate data retrieval flow based on the business logic requirements, which provides greater flexibility. The bi-directional model allows navigating from a child object to its sibling child via the common parent via two simple Space calls. The downside of this approach is redundant metadata maintained in memory, and extra updates required when data is deleted and a transaction which space more objects. This also affects the system concurrency level.&lt;/p&gt;

&lt;h1 id=&#34;moving-from-a-database-centric-to-a-space-model&#34;&gt;Moving from a Database-Centric to a Space Model&lt;/h1&gt;

&lt;p&gt;If you have an existing application that evolved with a database as its sole system of record, you may be using Hibernate (or some other mapping layer) to bridge between the object model your application uses and the relational model the database  uses. In other cases, you may be using a JDBC API to access the database.&lt;/p&gt;

&lt;p&gt;To leverage the Space data modeling approach, you must adapt your existing application entities to use the appropriate data access routines. The entity class should be modified to leverage the Space data model and API. If your application uses Hibernate for example, the changes can be done in a way that is relatively transparent to the application itself. The &lt;a href=&#34;http://docs.gigaspaces.com/sbp/moving-from-hibernate-to-space.html&#34;&gt;Moving from Hibernate to Space&lt;/a&gt; topic explains how to perform these changes in the Data Access Objects (DAO). You may also be able to automate this process via auto-code generation or byte code manipulation.&lt;/p&gt;

&lt;h1 id=&#34;author-and-book-example&#34;&gt;Author and Book Example&lt;/h1&gt;

&lt;p&gt;In the following example, we have &lt;strong&gt;Author&lt;/strong&gt; and &lt;strong&gt;Book&lt;/strong&gt; entities. This is how the original &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; Entities look:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Author&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Book&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;id:Integer&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;id:Integer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;lastName:String&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;title:String&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;example-code&#34;&gt;Example Code&lt;/h2&gt;

&lt;p&gt;You can &lt;a href=&#34;http://docs.gigaspaces.com/download_files//sbp/Space-Data-Model-Example.zip&#34;&gt;download&lt;/a&gt; the code used with the examples below. See &lt;code&gt;MainEmbeddedOne2Many&lt;/code&gt;, &lt;code&gt;MainEmbeddedOne2One&lt;/code&gt;, &lt;code&gt;MainNonEmbeddedOne2Many&lt;/code&gt;, &lt;code&gt;MainNonEmbeddedOne2One&lt;/code&gt;, and &lt;code&gt;MainJDBC&lt;/code&gt; that demonstrate each scenario described below.&lt;/p&gt;

&lt;h2 id=&#34;remote-vs-co-located-client&#34;&gt;Remote vs. Co-located Client&lt;/h2&gt;

&lt;p&gt;The examples below can be used with a client accessing a remote space or a co-located client running within the Space, such as a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/task-execution-over-the-space.html&#34;&gt;DistributedTask&lt;/a&gt; implementation or a &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/executor-based-remoting.html&#34;&gt;service&lt;/a&gt; method invoked in a broadcast mode. The co-located client reduces the serialization and network overhead. When using the co-located client approach with the non-embedded model, you should use the same &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/routing-in-partitioned-spaces.html&#34;&gt;routing field&lt;/a&gt; value for associated objects (parent-child).&lt;/p&gt;

&lt;h2 id=&#34;one-to-one-relationship&#34;&gt;One-to-One Relationship&lt;/h2&gt;

&lt;p&gt;With this example, there is a one-to-one relationship between the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; entity; An author may have one (1) book.&lt;/p&gt;

&lt;p&gt;Users can search for:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All &lt;strong&gt;Book&lt;/strong&gt; titles written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name (there may be multiple matching authors).&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When using JDBC to query for all the &lt;strong&gt;Books&lt;/strong&gt; related to an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the SQL query will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;select Book.id , Author.id,Author.lastName from Book, Author WHERE Author.lastName=&#39;AuthorX&#39; AND Book.authorId = Author.id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main problem with this approach is the execution time. The more &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt; you have, the greater the time required to execute the query. Using the Space API with the embedded and non-embedded model provides much better performance, which isn&amp;rsquo;t affected if there are many &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We can compare the JDBC approach to the embedded and non-embedded models.&lt;/p&gt;

&lt;h3 id=&#34;embedded-model&#34;&gt;Embedded Model&lt;/h3&gt;

&lt;p&gt;In the embedded model, the root Space object is the &lt;strong&gt;Author&lt;/strong&gt;, and has a &lt;strong&gt;Book&lt;/strong&gt; object embedded. The representation of these entities looks like this:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;The Author Entity&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;
    Book book;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    @SpaceIndex(path = &amp;quot;title&amp;quot;)
    public Book getBook() {
        return book;
    }

    public void setBook(Book book) {
        this.book = book;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Embedded Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Book implements Serializable{
    Integer id;
    String title;

    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID]
    public int Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }

    [SpaceIndex(Path = &amp;quot;Title&amp;quot;)]        
    [SpaceProperty(StorageType = StorageType.Document)]
    public Book Book { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Embedded Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[Serializable]
public class Book
{
    public int Id { get; set; }

    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&#34;tc-admon-tip&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;See the how the book &lt;strong&gt;Title&lt;/strong&gt; property is indexed within &lt;strong&gt;Author&lt;/strong&gt; class.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;To query for all the &lt;strong&gt;Books&lt;/strong&gt; written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the query code should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=?&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
Set&amp;lt;Book&amp;gt; booksFound = new HashSet&amp;lt;Book&amp;gt; ();
for (int j = 0; j &amp;lt; authorFounds.length; j++) {
    booksFound.add(authorFounds[j].getBook());
}
return booksFound;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var books = new HashSet&amp;lt;Book&amp;gt;();

var query = new SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=?&amp;quot;);
query.SetParameter(1, &amp;quot;AuthorX&amp;quot;);

var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(query);

foreach (var author in authors)
{
    books.Add(author.Book);
}

return books;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;To query for an &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt; title, the query should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=? and book.title=&amp;quot;?&amp;quot;);&amp;quot;%}}
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
query.setParameter(2, &amp;quot;BookX&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
return authorFounds ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;var query = new  SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=? and Book.Title=?&amp;quot;);
query.SetParameter(1, &amp;quot;AuthorX&amp;quot;);
query.SetParameter(2, &amp;quot;BookX&amp;quot;);

Author[] authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(query);
return authors;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;non-embedded-model&#34;&gt;Non-Embedded Model&lt;/h3&gt;

&lt;p&gt;With the non-embedded model, the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; entities look like this; the ID of the book is stored within the author, rather than in the book object itself. It is stored as a separate Space object:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;
    Integer bookId;

    @SpaceId(autoGenerate=false)
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    public Integer getBookId() {
        return bookId;
    }
    public void setBookId(Integer bookId) {
        this.bookId = bookId;
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Book {
    Integer id;
    Integer authorId;
    String title;

    @SpaceId (autoGenerate=false)
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public Integer getAuthorId() {
        return authorId;
    }
    public void setAuthorId(Integer authorId) {
        this.authorId = authorId;
    }

    @SpaceIndex
    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID(AutoGenerate = false)]
    public int Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }

    public int BookId { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Book
{
    [SpaceID(AutoGenerate = false)]
    public int Id { get; set; }

    [SpaceIndex]
    public int AuthorId { get; set; }

    [SpaceIndex]
    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To query for all the &lt;strong&gt;Books&lt;/strong&gt; written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the query code should look like this (see how the &lt;strong&gt;readById&lt;/strong&gt; call is used):&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=?&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authors [] = space.readMultiple(query);
ArrayList&amp;lt;Book&amp;gt; booksFound = new ArrayList&amp;lt;Book&amp;gt;() ;

// read the Author Book via its ID
for (int j=0;j&amp;lt;authors.length;j++)
{
    Book book = space.readById(Book.class , authors[j].getBookId());
    booksFound.add(book);
}
return booksFound;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var books = new HashSet&amp;lt;Book&amp;gt;();

var query = new SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=?&amp;quot;);
query.SetParameter(1, &amp;quot;AuthorX&amp;quot;);

Author[] authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(query);

foreach (Author author in authors)
{
   books.Add(spaceProxy.ReadById&amp;lt;Book&amp;gt;(author.BookId));
}

return books;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;See the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-by-id.html&#34;&gt;ID Queries&lt;/a&gt; topic for more information on how the &lt;code&gt;readById&lt;/code&gt; call can be used.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;To query for a specific &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt; title, the query code should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;String authoridsForTitle = &amp;quot;&amp;quot;;
SQLQuery&amp;lt;Book&amp;gt; bookQuery = new SQLQuery &amp;lt;Book&amp;gt;(Book.class , &amp;quot;title=&amp;quot;?&amp;quot;);
bookQuery.setParameter(1, &amp;quot;BookX&amp;quot;);
Book booksFounds [] = space.readMultiple(bookQuery);
for (int j = 0; j &amp;lt; booksFounds.length; j++) {
    Book book = booksFounds[j];
    authoridsForTitle = authoridsForTitle + book.getAuthorId().toString() ;
    if ((j +1)!= booksFounds.length)
        authoridsForTitle = authoridsForTitle + &amp;quot;,&amp;quot;;
}

SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=? AND id IN (&amp;quot;+ authoridsForTitle+&amp;quot;)&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
return authorFounds ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var authorIds = new StringBuilder();

var bookQuery = new SqlQuery&amp;lt;Book&amp;gt;(&amp;quot;Title=?&amp;quot;);
bookQuery.SetParameter(1, &amp;quot;BookX&amp;quot;);

var books = spaceProxy.ReadMultiple&amp;lt;Book&amp;gt;(bookQuery);

foreach (var book in books)
{
    authorIds.AppendFormat(&amp;quot;,{0}&amp;quot;, book.AuthorId);
}

var inCriteria = authorIds.ToString().TrimStart(&#39;,&#39;);
var authorQuery = new SqlQuery&amp;lt;Author&amp;gt;(string.Format(&amp;quot;LastName=? AND Id IN ({0})&amp;quot;, inCriteria));
authorQuery.SetParameter(1, &amp;quot;AuthorX&amp;quot;);

var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(authorQuery);
return authors;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;one-to-many-relationship&#34;&gt;One-to-Many Relationship&lt;/h2&gt;

&lt;p&gt;In this example, there is one-to-many relationship between the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; entities; an author may write many books.&lt;/p&gt;

&lt;p&gt;Users can search for:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All &lt;strong&gt;Book&lt;/strong&gt; titles written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name (there may be multiple matching authors).&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When using JDBC to query for all the &lt;strong&gt;Books&lt;/strong&gt; related to an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the query code should look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;select Book.id , Author.id,Author.lastName from Book, Author WHERE Author.lastName=&#39;AuthorX&#39; AND Book.authorId = Author.id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main problem with this approach is the execution time. The more &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt; you have, the greater the time required to execute the query. Using the Space API with the embedded and non-embedded model provides much better performance, which isn&amp;rsquo;t affected if there are many &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We can compare the JDBC approach with the embedded and non-embedded models.&lt;/p&gt;

&lt;h3 id=&#34;embedded-model-1&#34;&gt;Embedded Model&lt;/h3&gt;

&lt;p&gt;In the embedded model the root Space object is the &lt;strong&gt;Author&lt;/strong&gt;, and it has a &lt;strong&gt;Book&lt;/strong&gt; collection embedded. The representation of these entities looks like this:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;
    List&amp;lt;Book&amp;gt; books;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    @SpaceIndex(path = &amp;quot;[*].title&amp;quot;)
    public List&amp;lt;Book&amp;gt; getBooks() {
        return books;
    }

    public void setBooks(List&amp;lt;Book&amp;gt; books) {
        this.books = books;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  The Embedded Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Book implements Serializable{
    Integer id;
    String title;

    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID]
    public int Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }

    [SpaceIndex(Path=&amp;quot;[*].Title&amp;quot;)]
    [SpaceProperty(StorageType = StorageType.Document)]
    public IList&amp;lt;Book&amp;gt; Books { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  The Embedded Book Entity  &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[Serializable]
public class Book
{
    public int Id { get; set; }

    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&#34;tc-admon-tip&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;See the how the book &lt;strong&gt;Title&lt;/strong&gt; property is indexed within the &lt;strong&gt;Author&lt;/strong&gt; class.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;To query for all the &lt;strong&gt;Books&lt;/strong&gt; written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the query code should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Set&amp;lt;Book&amp;gt; booksFound = new HashSet&amp;lt;Book&amp;gt; ();
SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=?&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
for (int j = 0; j &amp;lt; authorFounds.length; j++) {
    booksFound.addAll(authorFounds[j].getBooks());
}
return booksFound;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var books = new List&amp;lt;Book&amp;gt;();

var authorQuery = new SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=?&amp;quot;);
authorQuery.SetParameter(1, &amp;quot;AuthorX&amp;quot;);
var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(authorQuery);

foreach (var author in authors)
{
    books.AddRange(author.Books);
}

return books;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;To query for an &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt; title, the query should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=? and books[*].title=&amp;quot;?&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
query.setParameter(2, &amp;quot;BookY&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
return authorFounds;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var authorQuery = new SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=? AND Books[*].Title=?&amp;quot;);
authorQuery.SetParameter(1, &amp;quot;AuthorX&amp;quot;);
authorQuery.SetParameter(2, &amp;quot;BookY&amp;quot;);
var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(authorQuery);

return authors;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;non-embedded-model-1&#34;&gt;Non-Embedded Model&lt;/h3&gt;

&lt;p&gt;In the non-embedded model, the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; look like this; the IDs of the books are stored within the author object rather than in the books themselves. These are stored as separate Space objects:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;
    List&amp;lt;Integer&amp;gt; bookIds;

    @SpaceId(autoGenerate=false)
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    public List&amp;lt;Integer&amp;gt; getBookIds() {
        return bookIds;
    }
    public void setBookIds(List&amp;lt;Integer&amp;gt; bookIds) {
        this.bookIds = bookIds;
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Book {
    Integer id;
    Integer authorId;
    String title;

    @SpaceId (autoGenerate=false)
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public Integer getAuthorId() {
        return authorId;
    }
    public void setAuthorId(Integer authorId) {
        this.authorId = authorId;
    }

    @SpaceIndex
    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID(AutoGenerate = false)]
    public int Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }

    public IList&amp;lt;int&amp;gt; BookIds { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Book
{
    [SpaceID(AutoGenerate = false)]
    public int Id { get; set; }

    [SpaceIndex]
    public int AuthorId { get; set; }

    [SpaceIndex]
    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To query for all the &lt;strong&gt;Books&lt;/strong&gt; written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the query code should look like this (see how the &lt;strong&gt;readByIds&lt;/strong&gt; call is used):&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=?&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authors [] = space.readMultiple(query);
ArrayList&amp;lt;Book&amp;gt; booksFound = new ArrayList&amp;lt;Book&amp;gt;() ;

// read all the Author Books via their IDs
for (int j=0;j&amp;lt;authors.length;j++)
{
    Integer ids [] = new Integer[authors[j].getBookIds().size()];
    ids  = authors[j].getBookIds().toArray(ids);
    Iterator&amp;lt;Book&amp;gt; bookIter = space.readByIds(Book.class ,ids).iterator();
    while (bookIter.hasNext()) {
        booksFound.add((Book) bookIter.next());
    }
}
return booksFound;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;var authorQuery = new SqlQuery&amp;lt;Author&amp;gt;(&amp;quot;LastName=?&amp;quot;);
authorQuery.SetParameter(1, &amp;quot;AuthorX&amp;quot;);
var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(authorQuery);

var books = new List&amp;lt;Book&amp;gt;();

foreach (var author in authors)
{
    books.AddRange(spaceProxy.ReadByIds&amp;lt;Book&amp;gt;(author.BookIds.Cast&amp;lt;object&amp;gt;().ToArray()));
}


return books;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;See the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-by-id.html&#34;&gt;ID Queries&lt;/a&gt; topic for more information about how the &lt;code&gt;readByIds&lt;/code&gt; call can be used.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;To query for a specific &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt; title, the query should look like this:&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Java &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SQLQuery&amp;lt;Book&amp;gt; bookQuery = new SQLQuery &amp;lt;Book&amp;gt;(Book.class , title=&amp;quot;?&amp;quot;);
bookQuery.setParameter(1, &amp;quot;BookX&amp;quot;);
Book booksFounds [] = space.readMultiple(bookQuery);
String authoridsForTitle=&amp;quot;&amp;quot;;
for (int j = 0; j &amp;lt; booksFounds.length; j++) {
    Book book = booksFounds[j];
    authoridsForTitle = authoridsForTitle + book.getAuthorId().toString() ;
    if ((j +1)!= booksFounds.length)
        authoridsForTitle = authoridsForTitle + &amp;quot;,&amp;quot;;
}

SQLQuery&amp;lt;Author&amp;gt; query = new SQLQuery &amp;lt;Author&amp;gt;(Author.class , &amp;quot;lastName=? AND id IN (&amp;quot;+ authoridsForTitle+&amp;quot;)&amp;quot;);
query.setParameter(1, &amp;quot;AuthorX&amp;quot;);
Author authorFounds [] = space.readMultiple(query);
return authorFounds ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  C# &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;var bookQuery = new SqlQuery&amp;lt;Book&amp;gt;(&amp;quot;Title=?&amp;quot;);
bookQuery.SetParameter(1, &amp;quot;BookX&amp;quot;);
var books = spaceProxy.ReadMultiple&amp;lt;Book&amp;gt;(bookQuery);

var authorIds = new StringBuilder();

foreach (var book in books)
{
    authorIds.AppendFormat(&amp;quot;,{0}&amp;quot;, book.AuthorId);
}

var authorQueryCriteria = authorIds.ToString().TrimStart(&#39;,&#39;);
var authorQuery = new SqlQuery&amp;lt;Author&amp;gt;(string.Format(&amp;quot;LastName=? AND Id in ({0})&amp;quot;, authorQueryCriteria));
authorQuery.SetParameter(1, &amp;quot;AuthorX&amp;quot;);

var authors = spaceProxy.ReadMultiple&amp;lt;Author&amp;gt;(authorQuery);

return authors;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;many-to-many-relationship&#34;&gt;Many-to-Many Relationship&lt;/h2&gt;

&lt;p&gt;In this example, there is many-to-many relationship between the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; entity; an author may write many books, and a book may be written by multiple authors.&lt;/p&gt;

&lt;p&gt;Users can search for:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All &lt;strong&gt;Book&lt;/strong&gt; titles written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name (there may be multiple matching authors).&lt;/li&gt;
&lt;li&gt;An &lt;strong&gt;Author&lt;/strong&gt; with a specific &lt;strong&gt;Book&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To model this in SQL, you need an additional table that links an author with the related books (or in other words, a book and its authors). Each entry in this table contains a foreign key to the Author table, and a foreign key to the Book table. When using JDBC to query for all the &lt;strong&gt;Books&lt;/strong&gt; written by an &lt;strong&gt;Author&lt;/strong&gt; with a specific last name, the SQL query should look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;select Book.id, Author.id, Author.lastName from Book, Author, AuthorBookLink WHERE Author.lastName=&#39;AuthorX&#39; AND Author.id = AuthorBookLink.authorId AND AuthorBookLink.bookId = Book.id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main problem with this approach is the execution time. The more &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt; you have, the greater the time required to execute the query. Using the Space API with the non-embedded model provides much better performance, which isn&amp;rsquo;t affected if there are many &lt;strong&gt;Books&lt;/strong&gt; or &lt;strong&gt;Authors&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We can compare the JDBC approach to the embedded and non-embedded model.&lt;/p&gt;

&lt;h3 id=&#34;embedded-model-2&#34;&gt;Embedded Model&lt;/h3&gt;

&lt;p&gt;In the embedded model, the root Space object is the &lt;strong&gt;Author&lt;/strong&gt; and it has a &lt;strong&gt;Book&lt;/strong&gt; collection embedded. The representation of these entities looks like this:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;
    List&amp;lt;Book&amp;gt; books;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    @SpaceIndex(path = &amp;quot;[*].title&amp;quot;)
    public List&amp;lt;Book&amp;gt; getBooks() {
        return books;
    }

    public void setBooks(List&amp;lt;Book&amp;gt; books) {
        this.books = books;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  The Embedded Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Book implements Serializable {
    Integer id;
    String title;

    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID]
    public int Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }

    [SpaceIndex(Path=&amp;quot;[*].Title&amp;quot;)]
    [SpaceProperty(StorageType = StorageType.Document)]
    public IList&amp;lt;Book&amp;gt; Books { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  The Embedded Book Entity  &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-csahrp&#34;&gt;[Serializable]
public class Book
{
    public int Id { get; set; }

    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&#34;non-embedded-model-2&#34;&gt;Non-Embedded Model&lt;/h3&gt;

&lt;p&gt;In the non-embedded model, the &lt;strong&gt;Author&lt;/strong&gt; and the &lt;strong&gt;Book&lt;/strong&gt; look like this. Note that there additional entities expressing a relationship between &lt;strong&gt;Author&lt;/strong&gt; and &lt;strong&gt;Book&lt;/strong&gt;; &lt;strong&gt;AuthorBookLink&lt;/strong&gt;. In this model, &lt;strong&gt;Books&lt;/strong&gt; are stored as separate Space objects:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Java&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Author {
    Integer id;
    String lastName;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getLastName() {
        return lastName;
    }
    public void setLastName(String lastName) {
        this.lastName = lastName;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class Book {
    Integer id;
    String title;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public String getTitle() {
        return title;
    }
    public void setTitle(String title) {
        this.title = title;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The AuthorBookLink Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@SpaceClass
public class AuthorBookLink {
    Integer id;
    Integer authorId;
    Integer bookId;

    @SpaceId
    public Integer getId() {
        return id;
    }
    public void setId(Integer id) {
        this.id = id;
    }

    @SpaceIndex
    public Integer getAuthorId() {
        return authorId;
    }
    public void setAuthorId(Integer authorId) {
        this.authorId = authorId;
    }

    @SpaceIndex
    public Integer getBookId() {
        return bookId;
    }
    public void setBookId(Integer bookId) {
        this.bookId = bookId;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div title=&#34;C#&#34; style=&#34;padding:10px;&#34;&gt;&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  The Author Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Author
{
    [SpaceID]
    public int? Id { get; set; }

    [SpaceIndex]
    public string LastName { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;  The Book Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class Book
{
    [SpaceID]
    public int? Id { get; set; }

    [SpaceIndex]
    public string Title { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  The AuthorBookLink Entity &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-c#&#34;&gt;[SpaceClass]
public class AuthorBookLink
{
    [SpaceID]
    public int? Id { get; set; }

    [SpaceIndex]
    public int? AuthorId { get; set; }
    
    [SpaceIndex]
    public int? BookId { get; set; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;See the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-by-id.html&#34;&gt;ID Queries&lt;/a&gt; topic for more information on how the &lt;code&gt;readByIds&lt;/code&gt; call can be used.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&#34;tc-admon-tip&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;More examples are available in the &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/query-sql.html&#34;&gt;SQLQuery&lt;/a&gt; topic, which provides details about query and indexing embedded entities. Additionally, the &lt;a href=&#34;./parent-child-relationship.html&#34;&gt;Parent Child Relationship&lt;/a&gt; page contains an example of non-embedded relationships.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;real-world-example&#34;&gt;Real World Example&lt;/h2&gt;

&lt;p&gt;In the &lt;a href=&#34;http://www.openspaces.org/display/DAE/GigaSpaces+PetClinic&#34;&gt;Pet Clinic application&lt;/a&gt; that is based on the &lt;a href=&#34;https://github.com/spring-projects/spring-petclinic&#34;&gt;Spring pet clinic sample&lt;/a&gt;, a &lt;strong&gt;Pet&lt;/strong&gt; is only associated with an &lt;strong&gt;Owner&lt;/strong&gt;. We can therefore store each &lt;strong&gt;Pet&lt;/strong&gt; with its &lt;strong&gt;Owner&lt;/strong&gt; on the same partition. We can even embed the &lt;strong&gt;Pet&lt;/strong&gt; object within the physical &lt;strong&gt;Owner&lt;/strong&gt; entry.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/petclinic_class_model.gif&#34; alt=&#34;petclinic_class_model.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;However, if a &lt;strong&gt;Pet&lt;/strong&gt; is also associated with a &lt;strong&gt;Vet&lt;/strong&gt;, we can&amp;rsquo;t embed the &lt;strong&gt;Pet&lt;/strong&gt; in the &lt;strong&gt;Vet&lt;/strong&gt; physical entry (without duplicating each Pet entry), and can&amp;rsquo;t even store the &lt;strong&gt;Pet&lt;/strong&gt; and its &lt;strong&gt;Vet&lt;/strong&gt; in the same partition.&lt;/p&gt;

&lt;h1 id=&#34;guidelines-for-choosing-embedded-relationships&#34;&gt;Guidelines for Choosing Embedded Relationships&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Embed when an entity is meaningful only with the context of its containing object. For example, in the Pet Clinic application, the &lt;strong&gt;Pet&lt;/strong&gt; entity has a meaning only when it is associated with an &lt;strong&gt;Owner&lt;/strong&gt;. A &lt;strong&gt;Pet&lt;/strong&gt; by itself is meaningless without an &lt;strong&gt;Owner&lt;/strong&gt; in this specific application. There is no business scenario for transferring a &lt;strong&gt;Pet&lt;/strong&gt; from one&lt;strong&gt;Owner&lt;/strong&gt; to another &lt;strong&gt;Owner&lt;/strong&gt;, or for admitting a &lt;strong&gt;Pet&lt;/strong&gt; to a &lt;strong&gt;Vet&lt;/strong&gt; without an &lt;strong&gt;Owner&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Embedding may sometimes mean duplicating your data. For example, if you want to reference a certain &lt;strong&gt;Visit&lt;/strong&gt; from both the &lt;strong&gt;Pet&lt;/strong&gt; and &lt;strong&gt;Vet&lt;/strong&gt; classes, you&amp;rsquo;ll need duplicate &lt;strong&gt;Visit&lt;/strong&gt; entries.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Regarding duplication:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Duplication means preferring scalability over footprint. The reason for duplicating is to avoid cluster-wide transactions and in many cases, it is the only way to partition your object in a scalable manner.&lt;/li&gt;
&lt;li&gt;Duplication means higher memory consumption. While memory is considered a low-cost commodity today, duplication has a hidden cost because you may have two Sspace objects that contain the same data.&lt;/li&gt;
&lt;li&gt;Duplication means more lenient consistency. When you add a &lt;strong&gt;Visit&lt;/strong&gt; to a &lt;strong&gt;Pet&lt;/strong&gt; and a &lt;strong&gt;Vet&lt;/strong&gt;, for example, you must update them both. You can do this in one (potentially distributed) transaction, or in two separate transactions, which will scale better but be less consistent. This may be sufficient for many types of applications, such as on social networks where losing a post, although undesired, does not incur significant damage. In contrast, this is not feasible for financial applications where every operation must be accounted for.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Collections</title>
      <link>http://docs.gigaspaces.com/sbp/distributed-collections.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/distributed-collections.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Mike Raney&lt;/td&gt;
&lt;td&gt;10.2&lt;/td&gt;
&lt;td&gt;February 2016&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/GigaSpaces-ProfessionalServices/distributed-collections&#34;&gt;Github link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is a distributed java collections implementation on top of Gigaspaces XAP. It currently includes the implementation of &lt;code&gt;java.util.concurrent.BlockingQueue&lt;/code&gt; and &lt;code&gt;java.util.Set&lt;/code&gt; with a number of features on top of them, e.g. different collocation modes.&lt;/p&gt;

&lt;h2 id=&#34;building-project&#34;&gt;Building project&lt;/h2&gt;

&lt;p&gt;This project is based on Maven, to build it run following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# with unit tests
mvn clean package -Dcom.gs.home=&amp;lt;path to xap install&amp;gt;

# without unit tests
mvn clean package -DskipTests=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The project includes multi-partitioned space unit tests. Please use proper XAP licence key to run these. To pass the licence file to tests, the &lt;code&gt;com.gs.home&lt;/code&gt; JVM argument is used. A proper value is path to folder without slash at the end, e.g. &lt;code&gt;/home/ec2-user/gigaspaces-xap-premium-10.2.0-ga&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;using-collections&#34;&gt;Using collections&lt;/h2&gt;

&lt;p&gt;Each collection declaration requires passing &lt;code&gt;Gigaspace&lt;/code&gt; bean to the configurer or bean factory. Here is how you can create set and queue via Spring XML and Java configurations:&lt;/p&gt;

&lt;h3 id=&#34;java-declaration&#34;&gt;Java declaration&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;GigaSet&amp;lt;Person&amp;gt; set = new GigaSetConfigurer&amp;lt;Person&amp;gt;(gigaSpace).gigaSet();
GigaQueue&amp;lt;Person&amp;gt; queue = new GigaQueueConfigurer&amp;lt;Person&amp;gt;(gigaSpace, &amp;quot;myPersonQueue&amp;quot;, CollocationMode.DISTRIBUTED).gigaQueue();
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;xml-declaration&#34;&gt;XML declaration&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;!-- Space declaration is omitted --&amp;gt;

&amp;lt;os-core:giga-space id=&amp;quot;myGigaSpace&amp;quot; space=&amp;quot;space&amp;quot;/&amp;gt;

&amp;lt;bean id=&amp;quot;myGigaSet&amp;quot; class=&amp;quot;org.openspaces.collections.GigaSetFactoryBean&amp;quot;&amp;gt;
  &amp;lt;property name=&amp;quot;gigaSpace&amp;quot; ref=&amp;quot;myGigaSpace&amp;quot;/&amp;gt;
&amp;lt;/bean&amp;gt;

&amp;lt;bean id=&amp;quot;myGigaQueue&amp;quot; class=&amp;quot;org.openspaces.collections.GigaQueueFactoryBean&amp;quot;&amp;gt;
  &amp;lt;property name=&amp;quot;queueName&amp;quot; value=&amp;quot;myQueue&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;gigaSpace&amp;quot; ref=&amp;quot;myGigaSpace&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;collocationMode&amp;quot; value=&amp;quot;DISTRIBUTED&amp;quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Service
public class MyService {
    @Resource(name = &amp;quot;myGigaSet&amp;quot;)
    private GigaSet&amp;lt;SerializableType&amp;gt; set;

    @Resource(name = &amp;quot;myGigaQueue&amp;quot;)
    private GigaBlockingQueue&amp;lt;SerializableType&amp;gt; queue;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;Only &lt;code&gt;Serializable&lt;/code&gt; elements can be stored in &lt;code&gt;GigaSet&lt;/code&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;configuring-gigaset&#34;&gt;Configuring GigaSet&lt;/h2&gt;

&lt;p&gt;Current implementation of &lt;code&gt;GigaSet&lt;/code&gt; supports two modes: &lt;code&gt;clustered&lt;/code&gt; and &lt;code&gt;non-clustered&lt;/code&gt;. If a specific mode is not chosen, it will be set automatically based on given &lt;code&gt;GigaSpace&lt;/code&gt;. Clustered mode is set to &lt;code&gt;false&lt;/code&gt; if the space is an embedded one and the space is not a local cache proxy, &lt;code&gt;true&lt;/code&gt; otherwise. When declaring the mode, user can leave this flag unset or choose &lt;code&gt;false&lt;/code&gt; to work with single member of the grid or &lt;code&gt;true&lt;/code&gt; to work with the whole cluster. This allows to switch between client-side implementation of &lt;code&gt;GigaSet&lt;/code&gt; which interacts with remote space and server-side implementation that works with own embedded space.&lt;/p&gt;

&lt;p&gt;Here is an example of how to create a &lt;code&gt;GigaSet&lt;/code&gt; for a single grid member (embedded space):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;GigaSet&amp;lt;Person&amp;gt; set = new GigaSetConfigurer&amp;lt;Person&amp;gt;(gigaSpace)
                        .clustered(false)
                        .gigaSet();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, with XML configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;!-- Embedded space declaration is omitted --&amp;gt;

&amp;lt;os-core:giga-space id=&amp;quot;myGigaSpace&amp;quot; space=&amp;quot;space&amp;quot;/&amp;gt;

&amp;lt;bean id=&amp;quot;myGigaSet&amp;quot; class=&amp;quot;org.openspaces.collections.GigaSetFactoryBean&amp;quot;&amp;gt;
  &amp;lt;property name=&amp;quot;gigaSpace&amp;quot; ref=&amp;quot;myGigaSpace&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;clustered&amp;quot; value=&amp;quot;false&amp;quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;configuring-gigaqueue&#34;&gt;Configuring GigaQueue&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;GigaQueue&lt;/code&gt; supports three collocation modes, multi-client usage, non-serializable element types and capacity limits.&lt;/p&gt;

&lt;h4 id=&#34;distributed-collocation-mode&#34;&gt;Distributed collocation mode&lt;/h4&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/collections/distributed.png&#34; alt=&#34;Distributed collocation mode&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In this mode collection items are spread over the whole cluster. It is preferred mode for collections of huge sizes, since memory consumption is balanced across the grid. User items are wrapped into meta classes and stored in space one by one.&lt;/p&gt;

&lt;h4 id=&#34;local-collocation-mode&#34;&gt;Local collocation mode&lt;/h4&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/collections/local.png&#34; alt=&#34;Local collocation mode&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In &lt;code&gt;local&lt;/code&gt; collocation mode items are stored within the same partition as the metadata object. This mode should be chosen when application interacts with multiple small collections stored in the grid. It is scalable by collection count and not by the number of items in one collection. User items are wrapped into meta classes and stored in space one by one.&lt;/p&gt;

&lt;h4 id=&#34;embedded-collocation-mode&#34;&gt;Embedded collocation mode&lt;/h4&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/collections/embedded.png&#34; alt=&#34;Embedded collocation mode&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;This mode suggests that user items are stored inside single collection container object. Thus items do not have their own space identity and are stored together. This mode is similar to &lt;code&gt;local&lt;/code&gt; mode but groups up items for performance needs.&lt;/p&gt;

&lt;h4 id=&#34;multi-client-usage&#34;&gt;Multi-client usage&lt;/h4&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/collections/multi-client.png&#34; alt=&#34;Multi-client usage&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code&gt;GigaQueue&lt;/code&gt; can have multiple clients operating over one collection. Several processes may declare a queue with one name: this will create only one queue structure in space and will allow clients to offer and poll with a single source. For example, queue may be filled with tasks by the producer process and emptied by the consumers.&lt;/p&gt;

&lt;p&gt;It is strongly recommended to reuse one instance of queue within one java process due to client-side optimizations. Thus, it is recommended to declare a queue as a Spring context bean, and just inject it wherever it&amp;rsquo;s required without additional creation.&lt;/p&gt;

&lt;h4 id=&#34;serialization&#34;&gt;Serialization&lt;/h4&gt;

&lt;p&gt;By default all queue items will be serialized into byte arrays and stored in space. To tweak the serialization, you can provide an item class which will be used to determine if items must be stored in byte form or note. Next configuration will skip additional serialization, if &lt;code&gt;Person&lt;/code&gt; class implements &lt;code&gt;Serializable&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;GigaQueue&amp;lt;Person&amp;gt; queue = new GigaQueueConfigurer&amp;lt;Person&amp;gt;(gigaSpace, &amp;quot;myPersonQueue&amp;quot;, DISTRIBUTED)
                            .elementType(Person.class)
                            .gigaQueue();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, with XML configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;bean id=&amp;quot;myGigaQueue&amp;quot; class=&amp;quot;org.openspaces.collections.GigaQueueFactoryBean&amp;quot;&amp;gt;
  &amp;lt;property name=&amp;quot;queueName&amp;quot; value=&amp;quot;myQueue&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;gigaSpace&amp;quot; ref=&amp;quot;myGigaSpace&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;collocationMode&amp;quot; value=&amp;quot;DISTRIBUTED&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;elementType&amp;quot; value=&amp;quot;com.myproject.bean.Person&amp;quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also provide custom serializers and serializer providers using &lt;code&gt;GigaQueueFactoryBean&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;capacity-limits&#34;&gt;Capacity limits&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;GigaQueue&lt;/code&gt; can be limited on capacity. This will change queue behavior when items count reaches the maximum. More information about bounded queue behavior can be found in method docs. To create a bounded queue, next declaration may be used:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;GigaQueue&amp;lt;Person&amp;gt; queue = new GigaQueueConfigurer&amp;lt;Person&amp;gt;(gigaSpace, &amp;quot;myPersonQueue&amp;quot;, DISTRIBUTED)
                            .capacity(100)
                            .gigaQueue();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, with XML configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;bean id=&amp;quot;myGigaQueue&amp;quot; class=&amp;quot;org.openspaces.collections.GigaQueueFactoryBean&amp;quot;&amp;gt;
  &amp;lt;property name=&amp;quot;queueName&amp;quot; value=&amp;quot;myQueue&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;gigaSpace&amp;quot; ref=&amp;quot;myGigaSpace&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;collocationMode&amp;quot; value=&amp;quot;DISTRIBUTED&amp;quot;/&amp;gt;
  &amp;lt;property name=&amp;quot;capacity&amp;quot; value=&amp;quot;100&amp;quot;/&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Custom Aggregators</title>
      <link>http://docs.gigaspaces.com/sbp/aggregators-custom.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/aggregators-custom.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Shay Hassidim&lt;/td&gt;
&lt;td&gt;10.1&lt;/td&gt;
&lt;td&gt;July 2015&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Aggregators provided by the core XAP platform are extensible, allowing developers to modify existing functionality as well as add new features. This flexibility allows the framework to grow with changing requirements and new technologies.  Creating a new aggregator or extending an existing one is a small level of effort for the developer.  This document will describe different patterns to write custom aggregators and some common use cases.&lt;/p&gt;

&lt;h1 id=&#34;spaceentriesaggregator&#34;&gt;SpaceEntriesAggregator&lt;/h1&gt;

&lt;p&gt;The &lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html&#34;&gt;SpaceEntriesAggregator&lt;/a&gt; is an abstract class that serves as the base class for all aggregators, including the ones provided by the core platform.  Extending this class will provide several methods to allow the user to easily implement a custom aggregator.  The methods are as follows:&lt;/p&gt;

&lt;h3 id=&#34;aggregate-hahahugoshortcode-2hbhb-com-gigaspaces-query-aggregators-spaceentriesaggregator-html-aggregate-com-gigaspaces-query-aggregators-spaceentriesaggregatorcontext&#34;&gt;&lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html#aggregate-com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext-&#34;&gt;aggregate&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The aggregate method is executed for each space entity matching the SQLQuery in a space partition.  The function receives a SpaceEntriesAggregatorContext, which is a wrapper that allows the user to access members of the user entity. The members of each space entity can be accessed by the getPathValue method of SpaceEntriesAggregatorContext.&lt;/p&gt;

&lt;p&gt;Long departmentId = (Long) context.getPathValue(&amp;ldquo;departmentId&amp;rdquo;);&lt;/p&gt;

&lt;h3 id=&#34;getintermediateresult-hahahugoshortcode-3hbhb-com-gigaspaces-query-aggregators-spaceentriesaggregator-html-getintermediateresult&#34;&gt;&lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html#getIntermediateResult--&#34;&gt;getIntermediateResult&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Executed after all aggregate method calls have completed, this method represents the aggregation result of one partition. The returned value will be passed back to the client where it will trigger the aggregateIntermediateResult method.&lt;/p&gt;

&lt;h3 id=&#34;aggregateintermediateresult-hahahugoshortcode-4hbhb-com-gigaspaces-query-aggregators-spaceentriesaggregator-html-aggregateintermediateresult-t&#34;&gt;&lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html#aggregateIntermediateResult-T-&#34;&gt;aggregateIntermediateResult&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Assembles the responses from each partition on the client side to represent a response from the entire cluster.  The input to this method is the returned value of the getIntermediateResult method.&lt;/p&gt;

&lt;h3 id=&#34;getfinalresult-hahahugoshortcode-5hbhb-com-gigaspaces-query-aggregators-spaceentriesaggregator-html-getfinalresult-optional&#34;&gt;&lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html#getFinalResult--&#34;&gt;getFinalResult&lt;/a&gt; (optional)&lt;/h3&gt;

&lt;p&gt;Once all partitions have returned their results, the proxy invokes the getFinalResult method to retrieve the final aggregation result. Its default implementation will invoke the getIntermediateResult method, which yields the correct value in most aggregation implementations. Implement getFinalResult when there needs to be additional logic performed on the entire aggregatedResult.&lt;/p&gt;

&lt;h3 id=&#34;getdefaultalias-hahahugoshortcode-6hbhb-com-gigaspaces-query-aggregators-spaceentriesaggregator-html-getdefaultalias&#34;&gt;&lt;a href=&#34;[%=Links.ApiJavaDoc%]/com/gigaspaces/query/aggregators/SpaceEntriesAggregator.html#getDefaultAlias--&#34;&gt;getDefaultAlias&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;An aggregation result can contain the results from multiple aggregations. An alias provides a way to distinguish one aggregation result from another.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/aggregators-custom.png&#34; alt=&#34;aggregators.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;simple-aggregator&#34;&gt;Simple Aggregator&lt;/h1&gt;

&lt;p&gt;In the following example we will implement a custom aggregator to retrieve a result set of employee-id and salary. In the aggregate method, we place the employee-id and salary-id in a key value map.  On the client side, each partition result is assembled in the aggregateIntermediateResult method. After the results are assembled the getFinalResult method is called. In this case we implemented getFinalResult to be explicit, but by default getFinalResult behavior will invoke getIntermediateResult.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34; Aggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.gigaspaces.se.aggregator.example.salaryaggregator;

import java.util.HashMap;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class SalaryAggregator extends SpaceEntriesAggregator&amp;lt;HashMap&amp;lt;String, Integer&amp;gt;&amp;gt;{

    private static final long serialVersionUID = -7641865740945835568L;
    
    private transient HashMap&amp;lt;String, Integer&amp;gt; map;

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {

        String employeeId = (String)context.getPathValue(&amp;quot;id&amp;quot;);
        Integer salary = (Integer)context.getPathValue(&amp;quot;salary&amp;quot;);

        if(map == null)
            map = new HashMap&amp;lt;String, Integer&amp;gt;();

        map.put(employeeId, salary);
    }

    @Override
    public HashMap&amp;lt;String, Integer&amp;gt; getIntermediateResult() {
        return map;
    }

    @Override
    public void aggregateIntermediateResult(
        HashMap&amp;lt;String, Integer&amp;gt; partitionResult) {

        if(partitionResult != null){
            if(map == null){
                   map = partitionResult;
            }else{
                map.putAll(partitionResult);
            }
        }
    }
    
    @Override
    public String getDefaultAlias() {
        return &amp;quot;salaryAggrgetor()&amp;quot;;
    }
    @Override
    public Object getFinalResult() {
        return getIntermediateResult();
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; Program&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    SalaryAggregator salaryAggregator = new SalaryAggregator();
    AggregationSet aggregationSet = new AggregationSet();
    aggregationSet.add(salaryAggregator);
        
    SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 50000&amp;quot;);
    AggregationResult aggregationResult = gigaSpace.aggregate(query, aggregationSet);
    Map&amp;lt;String, Integer&amp;gt; employeeSalaryMap = (Map&amp;lt;String, Integer&amp;gt;)aggregationResult.get(&amp;quot;salaryAggrgetor()&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&#34;extending-an-existing-aggregator&#34;&gt;Extending an Existing Aggregator&lt;/h1&gt;

&lt;p&gt;In the following example we extend the GroupByAggregator to add custom filtering based on a Mathematical operation. For each value found, we compare the absolute value of expenses  to the value of  limit provided in the constructor. If expenses fall between -100 and 100 the aggregator will include the space entry in the aggregation.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34; Aggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.gigaspaces.se.aggregator.example.salaryaggregator;

import java.io.IOException;
import java.io.ObjectInput;
import java.io.ObjectOutput;

import com.gigaspaces.query.aggregators.GroupByAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class GroupByAggregatorWithFilter extends GroupByAggregator{

    private Double limit;

    public GroupByAggregatorWithFilter(){
        super();
    }

    public GroupByAggregatorWithFilter(Double limit){
        super();
        this.limit = limit;
    }

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {
        Double expenses = (Double) context.getPathValue(&amp;quot;expenses&amp;quot;);

        if(Math.abs(expenses) &amp;lt; this.limit) {
            super.aggregate(context);
        }
    }
    
     /***
     * Override Parent Serialization methods
     * and serialize and new members
     */
    @Override
    public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
        super.readExternal(in);
        limit = (Double)in.readObject();
    }
    
    @Override
    public void writeExternal(ObjectOutput out) throws IOException {
        super.writeExternal(out);
        out.writeObject(limit);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; Program&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 50000&amp;quot;);

    GroupByAggregator groupByAggregator = new GroupByAggregatorWithFilter(100.0)
    .selectAverage(&amp;quot;salary&amp;quot;)
    .groupBy(&amp;quot;departmentId&amp;quot;);

    AggregationSet aggregationSet = new AggregationSet();
    aggregationSet.add(groupByAggregator);

    AggregationResult result = gigaSpace.aggregate(query, aggregationSet);

    GroupByResult groupByResult = (GroupByResult)result.get(0);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; SQL&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT AVG(salary)
FROM employee
WHERE ABS(expenses) &amp;lt; 100 AND salary &amp;gt; 50000
GROUP BY  departmentId
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&#34;chaining-aggregators&#34;&gt;Chaining Aggregators&lt;/h1&gt;

&lt;p&gt;Chaining aggregators allows users to reuse the same filtering logic for different aggregators. Just as in our example where we extend the GroupByAggregator, we check the absolute value of a field before aggregating the value. This time we accept any type of aggregator.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34; Aggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.gigaspaces.se.aggregator.example.salaryaggregator;

import java.io.Serializable;

import com.gigaspaces.query.aggregators.SpaceEntriesAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class ChainedAggregatorWithFilter&amp;lt;T extends Serializable&amp;gt; extends SpaceEntriesAggregator&amp;lt;T&amp;gt;{

    private static final long serialVersionUID = 3892805657010192758L;

    private SpaceEntriesAggregator&amp;lt;T&amp;gt; aggregator;

    private Double limit;

    public ChainedAggregatorWithFilter(SpaceEntriesAggregator&amp;lt;T&amp;gt; aggregator, Double limit){
        super();
        this.aggregator = aggregator;
        this.limit = limit;
    }

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {
        Double expenses = (Double) context.getPathValue(&amp;quot;expenses&amp;quot;);

        if(Math.abs(expenses) &amp;lt; limit){
            aggregator.aggregate(context);
        }
    }

    @Override
    public void aggregateIntermediateResult(T partitionResult) {
        aggregator.aggregateIntermediateResult(partitionResult);
    }

    @Override
    public String getDefaultAlias() {
        return &amp;quot;filterByExpenses&amp;quot;;
    }

    @Override
    public T getIntermediateResult() {
        return aggregator.getIntermediateResult();
    }

    @Override
    public Object getFinalResult() {
        return aggregator.getFinalResult();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; Program&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;        SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 50000&amp;quot;);

        GroupByAggregator groupByAggregator = new GroupByAggregator()
                .selectAverage(&amp;quot;salary&amp;quot;)
                .groupBy(&amp;quot;departmentId&amp;quot;);


        AggregationSet aggregationSet = new AggregationSet();
        aggregationSet.add(new ChainedAggregatorWithFilter&amp;lt;GroupByResult&amp;gt;(groupByAggregator, 100.0));

        AggregationResult result = gigaSpace.aggregate(query, aggregationSet);

        GroupByResult groupByResult = (GroupByResult)result.get(0);

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; SQL&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT AVG(salary)
FROM employee
WHERE ABS(expenses) &amp;lt; 100 AND salary &amp;gt; 50000
GROUP BY  departmentId
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&#34;common-use-cases&#34;&gt;Common Use Cases&lt;/h1&gt;

&lt;h2 id=&#34;comparing-two-properties-from-the-same-object&#34;&gt;Comparing Two Properties From the Same Object&lt;/h2&gt;

&lt;p&gt;Sometimes there is a need to compare two members of the same object. Currently (XAP 10.2) SQLQuery does not support this type of comparison. To achieve this a user may create a custom aggregator to perform the comparison before performing the aggregation. The following example will emulate a read multiple call. It has a special filter that compares two fields from the same object.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34; Aggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.gigaspaces.se.aggregator.example.salaryaggregator;

import java.util.HashMap;

import com.gigaspaces.query.aggregators.SpaceEntriesAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class SalaryAggregatorWithFilter extends SpaceEntriesAggregator&amp;lt;HashMap&amp;lt;String, Integer&amp;gt;&amp;gt;{

    
    private static final long serialVersionUID = -1639750562385907859L;
    
    private transient HashMap&amp;lt;String, Integer&amp;gt; map;

    public SalaryAggregatorWithFilter() {
        super();
    }

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {

        String employeeId = (String)context.getPathValue(&amp;quot;id&amp;quot;);
        String ssn = (String)context.getPathValue(&amp;quot;ssn&amp;quot;);
        Integer salary = (Integer)context.getPathValue(&amp;quot;salary&amp;quot;);

        if(employeeId.equals(ssn)){
            if(map == null)
                map = new HashMap&amp;lt;String, Integer&amp;gt;();

            map.put(employeeId, salary);
        }
    }

    @Override
    public HashMap&amp;lt;String, Integer&amp;gt; getIntermediateResult() {
        return map;
    }

    @Override
    public void aggregateIntermediateResult(
        HashMap&amp;lt;String, Integer&amp;gt; partitionResult) {

        if(partitionResult != null){
            if(map == null){
                map = partitionResult;
            }else{
                map.putAll(partitionResult);
            }
        }
    }

    @Override
    public String getDefaultAlias() {
        return &amp;quot;salaryAggrgetorWithFilter()&amp;quot;;
    }

    @Override
    public Object getFinalResult() {
        return getIntermediateResult();
    }

}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; Program&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    SalaryAggregatorWithFilter salaryAggregator = new SalaryAggregatorWithFilter();
    AggregationSet aggregationSet = new AggregationSet();
    aggregationSet.add(salaryAggregator);
        
    SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 50000&amp;quot;);
    AggregationResult aggregationResult = gigaSpace.aggregate(query, aggregationSet);
    Map&amp;lt;String, Integer&amp;gt; employeeSalaryMap = (Map&amp;lt;String, Integer&amp;gt;)aggregationResult.get(&amp;quot;salaryAggrgetorWithFilter()&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; SQL&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT employeeId, salary
FROM employee
WHERE employeeId = ssn AND salary &amp;gt; 50000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&#34;sql-in-query-vs-custom-aggregator-query&#34;&gt;SQL IN Query vs. Custom Aggregator Query&lt;/h1&gt;

&lt;h2 id=&#34;sql-in-queries-custom-aggregator-example&#34;&gt;SQL IN Queries  Custom Aggregator Example&lt;/h2&gt;

&lt;p&gt;This example has a Space with a million Employee objects.
The Employee objects are associated with 50,000 different Departments  in average 20 Employees per Department.
An Employee object has an id field, a salary field (extended indexed) and a departmentId field (indexed).&lt;/p&gt;

&lt;p&gt;Out of the million Employees within the space we had 750,000 with a salary = 6000 and 250,000 Employees with salary = 1000.&lt;/p&gt;

&lt;p&gt;The query executed using a classic &lt;code&gt;SQL IN&lt;/code&gt; statement:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select id from Employee where salary &amp;gt; 5000 AND departmentId IN (?)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where the dynamic parameter had a different size of IDs list each time. The normal way of implementing such a query is to use the &lt;code&gt;SQLQuery&lt;/code&gt; in the following manner:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Collection&amp;lt;Integer&amp;gt; departmentList = new HashSet&amp;lt;Integer&amp;gt;();
departmentList.add();
.
SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 5000 AND departmentId IN (?)&amp;quot;);
query.setProjections(&amp;quot;id&amp;quot;);
query.setParameter(1, departmentList);
Employee result[] = gigaSpace.readMultiple(query);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the &lt;strong&gt;departmentList&lt;/strong&gt; includes the list of IDs we want to match against.&lt;/p&gt;

&lt;p&gt;The other option is to use a &lt;code&gt;Custom Aggregator&lt;/code&gt; as described below.&lt;/p&gt;

&lt;p&gt;Here are the results comparing regular query using IN with the custom aggregator:&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/custom-agg-example.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;As we can see - the time it takes to execute the query using the regular approach grows exponentially as we increase the departmentList size, where with the custom aggregator we are getting a minor increase with the query execution time.&lt;/p&gt;

&lt;p&gt;The reason for this difference is the way the Custom Aggregator is implemented.  With the Custom Aggregator, the Space iterates the candidate set (in our case Employee objects that matches salary &amp;gt; 5000) and calls the CustomINAggregator.Aggregate()
for each where the given &lt;strong&gt;departmentList&lt;/strong&gt; matched against the Employee &lt;strong&gt;departmentID&lt;/strong&gt; field value. The ones that can be found within the departmentList are added to the result set that eventually is sent back to the client using getIntermediateResult and finally aggregated via the aggregateIntermediateResult that is called for each partition.
Iterating the candidate set is a very fast process that does not generates many new objects on the server.
Getting the final result (HashSet) back into the client size also have very minimal garbage creation footprint.&lt;/p&gt;

&lt;p&gt;The regular approach, where the &lt;code&gt;SQLQuery&lt;/code&gt; is getting the departmentList to match against , performs a separate query for each element within the departmentList collections. All results are eventually aggregated into a final one returned back to the client.
This is a time consuming process. In addition  the aEmployee objects are materialize on the client side, which may consume memory and invoke garbage collection activity.
With the Custom Aggregator approach, Employee objects are not created anywhere throughout the process (these are accessed by reference during the scan activity), so no garbage is created.
This generates a very stable system in case such a query is executed continuously by many threads.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;CustomINAggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.io.Externalizable;
import java.io.IOException;
import java.io.ObjectInput;
import java.io.ObjectOutput;
import java.util.Collection;
import java.util.HashSet;

import com.gigaspaces.query.aggregators.SpaceEntriesAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class CustomINAggregator extends SpaceEntriesAggregator&amp;lt;HashSet&amp;lt;String&amp;gt;&amp;gt; implements Externalizable {

    private Collection&amp;lt;Integer&amp;gt; collection;
    private HashSet&amp;lt;String&amp;gt; result = new HashSet&amp;lt;String&amp;gt;();

    public CustomINAggregator() {
        super();
    }

    public String getDefaultAlias() {
        return &amp;quot;IN&amp;quot;;
    }

    public HashSet&amp;lt;String&amp;gt; getIntermediateResult() {
        return result;
    }

    public CustomINAggregator(Collection&amp;lt;Integer&amp;gt; collection) {
        super();
        this.collection = collection;
    }

    public void aggregateIntermediateResult(HashSet&amp;lt;String&amp;gt; partitionResult) {
        result.addAll(partitionResult);
    }

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {
        Integer departmentId = (Integer) context.getPathValue(&amp;quot;departmentId&amp;quot;);

        if (collection.contains(departmentId)) {
            result.add((String) context.getPathValue(&amp;quot;id&amp;quot;));
        }
    }

    public void readExternal(ObjectInput in) {
        try {
            collection = (Collection&amp;lt;Integer&amp;gt;) in.readObject();
        } catch (ClassNotFoundException | IOException e) {
            e.printStackTrace();
        }
    }

    public void writeExternal(ObjectOutput out) {
        try {
            out.writeObject(collection);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;Employee&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.gigaspaces.annotation.pojo.SpaceId;
import com.gigaspaces.annotation.pojo.SpaceIndex;
import com.gigaspaces.metadata.index.SpaceIndexType;

public class Employee {
    String id;
    Integer salary;
    Integer departmentId;

    @SpaceId
    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    @SpaceIndex(type = SpaceIndexType.EXTENDED)
    public Integer getSalary() {
        return salary;
    }

    public void setSalary(Integer salary) {
        this.salary = salary;
    }

    @SpaceIndex
    public Integer getDepartmentId() {
        return departmentId;
    }

    public void setDepartmentId(Integer departmentId) {
        this.departmentId = departmentId;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34;Custom aggregator Query&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 5000&amp;quot;);
    CustomINAggregator customINAggregator = new CustomINAggregator(departmentList);
    AggregationSet aggregationSet = new AggregationSet();
    aggregationSet.add(customINAggregator);

    AggregationResult result = gigaSpace.aggregate(query, aggregationSet);
    HashSet&amp;lt;String&amp;gt; aggreResult = (HashSet&amp;lt;String&amp;gt;) result.get(0);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;replacing-large-collection-for-in-operator&#34;&gt;Replacing Large Collection for IN Operator&lt;/h2&gt;

&lt;p&gt;Consider replacing the IN/NOT IN operator in SQLQuery with a custom aggregator when using a large collection as a parameter. The SQLQuery supports the IN and NOT IN operator, but when the collection is extensive, it may be beneficial to pass the collection into a custom aggregator as shown below.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34; Aggregator&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.gigaspaces.se.aggregator.example.salaryaggregator;

import java.io.IOException;
import java.io.ObjectInput;
import java.io.ObjectOutput;
import java.util.Collection;

import com.gigaspaces.query.aggregators.GroupByAggregator;
import com.gigaspaces.query.aggregators.SpaceEntriesAggregatorContext;

public class GroupByAggregatorWithContainsFiler&amp;lt;T&amp;gt; extends GroupByAggregator{

    private Collection&amp;lt;T&amp;gt; collection;
    private String inFieldName;
   
    public GroupByAggregatorWithContainsFiler(String inFieldName, Collection&amp;lt;T&amp;gt; collection){
        super();
        this.inFieldName = inFieldName;
        this.collection = collection;
    }
    public GroupByAggregatorWithContainsFiler(){
        super();
    }

    @Override
    public void aggregate(SpaceEntriesAggregatorContext context) {
        T field = (T) context.getPathValue(inFieldName);

        if(collection.contains(field)) {
            super.aggregate(context);
        }
    }
    
    /***
     * Override Parent Serialization methods
     * and serialize and new members
     */
    @Override
    public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
        super.readExternal(in);
        
        collection = (Collection&amp;lt;T&amp;gt;)in.readObject();
        inFieldName = (String)in.readObject();
       
    }
    
    @Override
    public void writeExternal(ObjectOutput out) throws IOException {
        super.writeExternal(out);
        out.writeObject(collection);
        out.writeObject(inFieldName);
       
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; Program&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    List&amp;lt;Integer&amp;gt; departmentList = new ArrayList&amp;lt;Integer&amp;gt;();
    departmentList.add(1);
    departmentList.add(2);
    //Large List....
    
    SQLQuery&amp;lt;Employee&amp;gt; query = new SQLQuery&amp;lt;Employee&amp;gt;(Employee.class, &amp;quot;salary &amp;gt; 50000&amp;quot;);

    GroupByAggregator groupByAggregator = new GroupByAggregatorWithContainsFiler(&amp;quot;departmentId&amp;quot;, departmentList)
        .selectAverage(&amp;quot;salary&amp;quot;)
        .groupBy(&amp;quot;departmentId&amp;quot;);

    AggregationSet aggregationSet = new AggregationSet();
    aggregationSet.add(groupByAggregator);

    AggregationResult result = gigaSpace.aggregate(query, aggregationSet);

    GroupByResult groupByResult = (GroupByResult)result.get(0);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div title=&#34; SQL&#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT AVG(salary), departmentId FROM
Employee
WHERE salary &amp;gt; 50000 AND departmentId IN (1,25,33,. 10,000)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Grid with Large Backend Database Support</title>
      <link>http://docs.gigaspaces.com/sbp/imdg-with-large-backend-database-support.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/imdg-with-large-backend-database-support.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Shay Hassidim&lt;/td&gt;
&lt;td&gt;8.0&lt;/td&gt;
&lt;td&gt;Jan 2011&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;When having an application using a very large backend database leveraging the IMDG, caching a subset of the application data, while running on-going data eviction policy with read-through policy (i.e. LRU cache policy mode with an External-Data-Source used), the main requirement is to &lt;strong&gt;access the database in the most optimal manner&lt;/strong&gt; when performing queries against the IMDG.&lt;/p&gt;

&lt;p&gt;When using &lt;code&gt;readById&lt;/code&gt; or &lt;code&gt;readByIds&lt;/code&gt; operations looking for a single specific object(s), that cannot be found within the IMDG (a cache miss), the database access is very minimal. Only one raw is retrieved from the database per object lookup activity via the space External Data Source (EDS) implementation.&lt;/p&gt;

&lt;p&gt;But when performing queries, using &lt;code&gt;readMultiple&lt;/code&gt; with a template or SQLQuery filter, that return a result set that may involve relatively large amount of objects, with an IMDG running in LRU cache policy mode, the probability accessing the database retrieving large amount of data is very high:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When using &lt;code&gt;readMultiple&lt;/code&gt; having &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt; as the &lt;code&gt;max_objects&lt;/code&gt; parameter, every partition will access the database (parallel database access). This may overload the database.&lt;/li&gt;
&lt;li&gt;When using &lt;code&gt;readMultiple&lt;/code&gt; having &lt;code&gt;max_objects&lt;/code&gt; &amp;lt; &lt;code&gt;Integer.MAX_VALUE&lt;/code&gt; the database might be accessed even if there are enough objects matching the query criteria across all the space partitions.&lt;/li&gt;
&lt;li&gt;When loading data from database data eviction process may be triggered. This may impact the performance.&lt;/li&gt;
&lt;li&gt;Database access involves reading objects that will not be loaded into the space (non-matching routing value).&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;solution&#34;&gt;Solution&lt;/h1&gt;

&lt;p&gt;The main motivation with the solution proposed below, is to have better control when a space partition is accessing the database. The space is inspected prior retrieving the data leveraging the ability to count matching objects to a given query very fast (via the in-memory indexes the space maintains). If there is an adequate amount of matching objects, the client will access the relevant space partition(s) and retrieve the data from the space without accessing the database.&lt;/p&gt;

&lt;p&gt;Here is the full query execution strategy:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Check matching object count per partition for a given query.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If there are enough objects within the clustered space:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If one partition has sufficient amount of objects use it and retrieve objects only from this partition&lt;/li&gt;
&lt;li&gt;If there are multiple partitions with sufficient amount of objects:

&lt;ul&gt;
&lt;li&gt;Retrieve in parallel data from the partitions which have enough objects (from the ones with the highest amount of matching objects first).&lt;/li&gt;
&lt;li&gt;Max objects parameter used to query the partition will match the object count to avoid database access.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If there are no enough objects within the clustered space:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Load data in order - first into the partition with the highest amount of free memory.&lt;/li&gt;
&lt;li&gt;Optional - check with other partitions if they access the database to avoid concurrent database access.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/imdg_eviction_large_db.jpg&#34; alt=&#34;imdg_eviction_large_db.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;data-eviction-options&#34;&gt;Data Eviction Options&lt;/h2&gt;

&lt;p&gt;Evicting data from the space can be done using the following options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LRU Cache policy - The simplest way to evict data based on available memory. Built-in option.&lt;/li&gt;
&lt;li&gt;Lease - Space objects expire based on TTL specified once the object is written into the space.&lt;/li&gt;
&lt;li&gt;Custom eviction implementation:
&amp;ndash; Using a Polling Container query the data frequently.
&amp;ndash; Using the JVM Memory Notification API.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See the &lt;a href=&#34;./custom-eviction.html#Eviction Strategies&#34;&gt;Custom Eviction&lt;/a&gt; section for details.&lt;/p&gt;

&lt;h1 id=&#34;example&#34;&gt;Example&lt;/h1&gt;

&lt;p&gt;With the &lt;a href=&#34;http://docs.gigaspaces.com/attachment_files/sbp/LargeDBLRUSpace.zip&#34;&gt;attached example&lt;/a&gt; the clustered space has 600 objects in memory:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100 object loaded into partition 1.&lt;/li&gt;
&lt;li&gt;200 object loaded into partition 2.&lt;/li&gt;
&lt;li&gt;300 object loaded into partition 3.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The clustered space is using a dummy External Data Source. It does not leverage any database. It prints a message when the space needs to access the database to retrieve data.&lt;/p&gt;

&lt;p&gt;The client performs 3 types of queries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Query for 50 matching objects - This will return objects from a single partition only without accessing the database.&lt;/li&gt;
&lt;li&gt;Query for 500 matching objects - This will return objects from multiple partitions without accessing the database.&lt;/li&gt;
&lt;li&gt;Query for 700 matching objects - Load data from the database and return objects from all partitions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;running-the-example&#34;&gt;Running the Example&lt;/h2&gt;

&lt;p&gt;To run the example you should first run the IMDG and later run the client. The example below explains how to run these within the IDE, but you can also modify these to run as a PU and deploy these into the GigaSpaces runtime environment.&lt;/p&gt;

&lt;h3 id=&#34;running-the-imdg&#34;&gt;Running the IMDG&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;MyEDS&lt;/code&gt; class main method will start IMDG with 3 nodes. Once the IMDG will be started, each partition will load the dummy data.&lt;/p&gt;

&lt;h3 id=&#34;running-the-client&#34;&gt;Running the Client&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;Client&lt;/code&gt; class main method will start a client that will perform the above queries.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XAP Spring Data</title>
      <link>http://docs.gigaspaces.com/sbp/spring-data.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/spring-data.html</guid>
      <description>&lt;p&gt;XAP Spring Data implements the &lt;a href=&#34;http://projects.spring.io/spring-data&#34;&gt;Spring Data Framework&lt;/a&gt; that lets you use the concepts to the development of applications using XAP&amp;rsquo;s In-Memory Data Grid (IMDG) as the data store. XAP Spring Data supports high-level abstractions to simplify configuration and development.&lt;/p&gt;

&lt;p&gt;This section is the reference guide for Spring Data with XAP. It explains basic and advanced configuration and usage of XAP IMDG features assuming the reader is already familiar with the &lt;a href=&#34;http://docs.spring.io/spring-data/commons/docs/1.9.1.RELEASE/reference/html/&#34;&gt;Spring Framework&lt;/a&gt; and &lt;a href=&#34;http://docs.gigaspaces.com&#34;&gt;XAP application development&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XAP Integration with Storm</title>
      <link>http://docs.gigaspaces.com/sbp/storm-integration.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/storm-integration.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Oleksiy Dyagilev&lt;/td&gt;
&lt;td&gt;10.0&lt;/td&gt;
&lt;td&gt;August 2014&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://storm.incubator.apache.org&#34;&gt;Storm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/fe2s/xap-storm&#34;&gt;Github link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Real-time processing is becoming very popular, and Storm is a popular open source framework and runtime used by Twitter for processing real-time data streams.  Storm addresses the complexity of running real time streams through a compute cluster by providing an elegant set of abstractions that make it easier to reason about your problem domain by letting you focus on data flows rather than on implementation details.&lt;/p&gt;

&lt;p&gt;Storm has many use cases: realtime analytics, online machine learning, continuous computation, distributed RPC, ETL, and more. Storm is fast: a benchmark clocked it at over a million tuples processed per second per node. It is scalable, fault-tolerant, guarantees your data will be processed, and is easy to set up and operate.&lt;/p&gt;

&lt;table class=&#34;tc-borderless&#34;&gt;&lt;tr&gt;&lt;p&gt;&lt;td style=&#34;width:70%;&#34;&gt;&lt;p&gt;This pattern integrates XAP with Storm. XAP is used as stream data source and fast reliable persistent storage, whereas Storm is in charge of data processing. We support both pure Storm and Trident framework.&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;As part of this integration we provide classic &lt;strong&gt;Word Counter&lt;/strong&gt; and &lt;strong&gt;Twitter Reach&lt;/strong&gt; implementations on top of XAP and Trident.&lt;/p&gt;

&lt;p&gt;&lt;p&gt;Also, we demonstrate how to build highly available, scalable equivalent of &lt;strong&gt;Realtime Google Analytics&lt;/strong&gt; application with XAP and Storm. Application can be deployed to cloud with one click using Cloudify.&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&#34;width:30%;&#34;&gt;&lt;p&gt;&lt;MadCap:snippetBlock src=&#34;Resources/Snippets/YouTube.flsnp&#34; MadCap:snippetVariables=&#34;Links.YouTube:https://www.youtube.com/watch?v=c9L06fKbbW8,&#34; /&gt;&lt;/p&gt;
&lt;/td&gt;&lt;/p&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h1 id=&#34;storm-in-a-nutshell&#34;&gt;Storm in a Nutshell&lt;/h1&gt;

&lt;p&gt;Storm is a real time, open source data streaming framework that functions entirely in memory.  It constructs a processing graph that feeds data from an input source through processing nodes.  The processing graph is called a &amp;ldquo;topology&amp;rdquo;.  The input data sources are called &amp;ldquo;spouts&amp;rdquo;, and the processing nodes are called &amp;ldquo;bolts&amp;rdquo;.  The data model consists of tuples.  Tuples flow from Spouts to the bolts, which execute user code. Besides simply being locations where data is transformed or accumulated, bolts can also join streams and branch streams.&lt;/p&gt;

&lt;p&gt;Storm is designed to be run on several machines to provide parallelism.  Storm topologies are deployed in a manner somewhat similar to a webapp or a XAP processing unit; a jar file is presented to a deployer which distributes it around the cluster where it is loaded and executed.  A topology runs until it is terminated.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/storm-nutshell.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Beside Storm, there is a &lt;strong&gt;Trident&lt;/strong&gt; - a high-level abstraction for doing realtime computing on top of Storm. Trident adds primitives like groupBy, filter, merge, aggregation to simplify common computation routines. Trident has consistent, exactly-once semantics, so it is easy to reason about Trident topologies.&lt;/p&gt;

&lt;p&gt;Capability to guarantee exactly-once semantics comes with additional cost. To guarantee that, incremental processing should be done on top of persistence data source. Trident has to ensure that all updates are idempotent. Usually that leads to lower throughput and higher latency than similar topology with pure Storm.&lt;/p&gt;

&lt;h1 id=&#34;spouts&#34;&gt;Spouts&lt;/h1&gt;

&lt;p&gt;Basically, Spouts provide the source of tuples for Storm processing.  For spouts to be maximally performant and reliable, they need to provide tuples in batches, and be able to replay failed batches when necessary.  Of course, in order to have batches, you need storage, and to be able to replay batches, you need reliable storage.  XAP is about the highest performing, reliable source of data out there, so a spout that serves tuples from XAP is a natural combination.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/xap-general-spout.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Depending on domain model and level of guarantees you want to provide, you choose either pure Storm or Trident. We provide Spout implementations for both - &lt;code&gt;XAPSimpleSpout&lt;/code&gt; and &lt;code&gt;XAPTranscationalTridentSpout&lt;/code&gt; respectively.&lt;/p&gt;

&lt;h2 id=&#34;storm-spout&#34;&gt;Storm Spout&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;XAPSimpleSpout&lt;/code&gt; is a spout implementation for pure Storm that reads data in batches from XAP. On XAP side we introduce conception of stream. Please find &lt;code&gt;SimpleStream&lt;/code&gt; - a stream implementation that supports writing data in single and batch modes and reading in batch mode. &lt;code&gt;SimpleStream&lt;/code&gt; leverages XAP&amp;rsquo;s FIFO(First In, First Out) capabilities.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/simple-spout.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code&gt;SimpleStream&lt;/code&gt; works with arbitrary space class that has &lt;code&gt;FifoSupport.OPERATION&lt;/code&gt; annotation and implements &lt;code&gt;Serializable&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here is an example how one may write data to &lt;code&gt;SimpleStream&lt;/code&gt; and process it in Storm topology. Let&amp;rsquo;s consider we would like to build an application to analyze the stream of page views (user clicks) on website. At first, we create a data model that represents a page view&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; @SpaceClass(fifoSupport = FifoSupport.OPERATION)
 public class PageView implements Serializable {
     private String id;
     private String page;
    private String sessionId;
    [getters setters omitted for brevity]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we would like to create a reference to stream instance and write some data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; SimpleStream&amp;lt;PageView&amp;gt; stream = new SimpleStream&amp;lt;&amp;gt;(space, new PageView());
 stream.writeBatch(pageViews);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The second argument of &lt;code&gt;SimpleStream&lt;/code&gt; is a template used to match objects during reading.
If you want to have several streams with the same type, template objects should differentiate your streams.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s create a spout for &lt;code&gt;PageView&lt;/code&gt; stream.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; public class PageViewSpout extends XAPSimpleSpout&amp;lt;PageView&amp;gt; {
     public PageViewSpout() {
         super(new PageViewTupleConverter(), new PageView());
     }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create a spout, we have to specify how we want our space class be converted to Storm tuple. That is exactly what &lt;code&gt;TupleConverter&lt;/code&gt; knows about.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; class PageViewTupleConverter implements TupleConverter&amp;lt;PageView&amp;gt; {
     @Override
     public Fields tupleFields() {
         return new Fields(&amp;quot;page&amp;quot;, &amp;quot;session&amp;quot;);
     }

     @Override
     public List&amp;lt;Object&amp;gt; spaceObjectToTuple(PageView pageView) {
         return Arrays.&amp;lt;Object&amp;gt;asList(pageView.getPage(), pageView.getSessionId());
     }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point we have everything ready to build Storm topology with &lt;code&gt;PageViewSpout&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; Config conf = new Config();
 conf.put(ConfigConstants.XAP_SPACE_URL_KEY, &amp;quot;jini://*/*/space&amp;quot;);
 conf.put(ConfigConstants. XAP_STREAM_BATCH_SIZE, 300);
 TopologyBuilder builder = new TopologyBuilder();
 builder.setSpout(&amp;quot;pageViewSpout&amp;quot;, new PageViewSpout());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ConfigConstants.XAP_SPACE_URL_KEY&lt;/code&gt; is a space URL&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ConfigConstants. XAP_STREAM_BATCH_SIZE&lt;/code&gt; is a maximum number of items that spout reads from XAP with one hit.&lt;/p&gt;

&lt;h2 id=&#34;trident-spout&#34;&gt;Trident Spout&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;XAPTranscationalTridentSpout&lt;/code&gt; is a scalable, fault-tolerant, transactional spout for Trident, supports pipelining. Let&amp;rsquo;s discuss all its properties in details.&lt;/p&gt;

&lt;p&gt;For spout to be maximally performant, we want an ability to scale the number of instances to control the parallelism of reader threads.&lt;/p&gt;

&lt;p&gt;There are several spout APIs available that we could potentially use for our XAPTranscationalTridentSpout implementation:
- &lt;code&gt;IPartitionedTridentSpout&lt;/code&gt;: A transactional spout that reads from a partitioned data source. The problem with this API is that it doesn&amp;rsquo;t acknowledge when batch is successfully processed which is critical for in memory solutions since we want to remove items from the grid as soon as they have been processed. Another option would be to use XAP&amp;rsquo;s lease capability to remove items by time out. This might be unsafe, if we keep items too long, we might consume all available memory.
- &lt;code&gt;ITridentSpout&lt;/code&gt;: The most general API. Setting parallelism hint for this spout to N will create N spout instances, single coordinator and N emitters. When coordinator issues new transaction id, it passes this id to all emitters. Emitter reads its portion of transaction by given transaction id. Merged data from all emitters forms transaction.&lt;/p&gt;

&lt;p&gt;For our implementation we choose &lt;code&gt;ITridentSpout&lt;/code&gt; API.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/trident-spout.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There is one to one mapping between XAP partitions and emitters.&lt;/p&gt;

&lt;p&gt;Storm framework guarantees that topology is high available, if some component fails, it restarts it. That means our spout implementation should be stateless or able to recover its state after failure.&lt;/p&gt;

&lt;p&gt;When emitter is created, it calls remote service &lt;code&gt;ConsumerRegistryService&lt;/code&gt; to register itself. &lt;code&gt;ConsumerRegistryService&lt;/code&gt; knows the number of XAP partitions and keeps track of the last allocated partition.  This information is reliably stored in the space, see &lt;code&gt;ConsumerRegistry.java&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/consumer-registry.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Remember that parallelism hint for &lt;code&gt;XAPTranscationalTridentSpout&lt;/code&gt; should equal to the number of XAP partitions.&lt;/p&gt;

&lt;p&gt;The property of being transactional is defined in Trident as following:
- batches for a given txid are always the same. Replays of batches for a txid will exact same set of tuples as the first time that batch was emitted for that txid.
- there&amp;rsquo;s no overlap between batches of tuples (tuples are in one batch or another, never multiple).
- every tuple is in a batch (no tuples are skipped)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;XAPTranscationalTridentSpout&lt;/code&gt; works with &lt;code&gt;PartitionedStream&lt;/code&gt; that wraps stream elements into Item class and keeps items ordered by &amp;lsquo;offset&amp;rsquo; property. There is one &lt;code&gt;PartitionStream&lt;/code&gt; instance per XAP partition.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/storm/partitioned-stream.png&#34; alt=&#34;alt tag&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Stream&amp;rsquo;s &lt;code&gt;WriterHead&lt;/code&gt; holds the last offset in the stream.  Any time batch of elements (or single element) written to stream, &lt;code&gt;WriterHead&lt;/code&gt; incremented by the number of elements. Allocated numbers used to populate offset property of Items. &lt;code&gt;WriterHead&lt;/code&gt; object is kept in heap, there is no need to keep it in space. If primary partition fails, &lt;code&gt;WriterHead&lt;/code&gt; is reinitialized to be the max offset value for given stream.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ReaderHead&lt;/code&gt; points to the last read item. We have to keep this value in the space, otherwise if partition fails we won&amp;rsquo;t be able to infer this value.&lt;/p&gt;

&lt;p&gt;When spout request new batch, we take &lt;code&gt;ReaderHead&lt;/code&gt;, read data from that point and update &lt;code&gt;ReaderHead&lt;/code&gt;. New &lt;code&gt;BatchMetadata&lt;/code&gt; object is placed to the space, it keeps start offset and number of items in the batch. In case Storm requests transaction replaying, we are able to reread exactly the same items by given batchId. Finally, once Storm acknowledges that batch successfully processed, we delete &lt;code&gt;BatchMetadata&lt;/code&gt; and corresponding items from the spac&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Mirror</title>
      <link>http://docs.gigaspaces.com/sbp/distributed-mirror.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/distributed-mirror.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Shay Hassidim&lt;/td&gt;
&lt;td&gt;12.0&lt;/td&gt;
&lt;td&gt;March 2017&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/asynchronous-persistency-with-the-mirror.html&#34;&gt;Asynchronous Persistence&lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/distributed-mirror.zip&#34;&gt;Example&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;By default a single mirror instance used to perform write-behind activity, persisting data from the space to the enterprise backend database. For most systems this will provide sufficient throughput to address the activity a single clustered space generating. There are cases with large space clusters or with systems that produce large volume of activity where the amount of activity performed by a clustered space would require a distributed (multi-instance) mirror setup. The solution described here allows each partition (primary and backup instances) to perform write-behind activity via a dedicated mirror. This forms an architecture where each partition using a separate mirror instance that may run on a different machine, utilizing its full CPU and network bandwidth. This approach reducing the potential for redolog accumulation generating a lag between the space data state and the persistency backend state as a result of a single mirror.&lt;/p&gt;

&lt;h1 id=&#34;architecture&#34;&gt;Architecture&lt;/h1&gt;

&lt;p&gt;With the example below we will run a partitioned space (2 partitions) and 2 mirror instances, both writing into a single database.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-1.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;the-example&#34;&gt;The Example&lt;/h1&gt;

&lt;p&gt;Download the &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/distributed-mirror.zip&#34;&gt;example&lt;/a&gt; and extract its contents into an empty folder. You will find 3 zip files:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;multi-mirror.zip  A Mirror PU configured to support multiple mirror instances&lt;/li&gt;
&lt;li&gt;space.zip - A Space PU configured to support multiple mirror instances&lt;/li&gt;
&lt;li&gt;feeder.zip  A PU writing objects into the space&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;start-the-database-and-its-ui&#34;&gt;Start the Database and its UI&lt;/h2&gt;

&lt;p&gt;Run SQLDB:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java -cp hsqldb-2.3.2.jar org.hsqldb.Server -database.0 file:testDB -dbname.0 testDB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run SQLDB Manager:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java -cp hsqldb-2.3.2.jar org.hsqldb.util.DatabaseManager
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;connect-to-the-database&#34;&gt;Connect to the database:&lt;/h2&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-2.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;You can find the hsqldb-2.3.2.jar within the multi-mirror.zip lib folder.&lt;/p&gt;

&lt;h2 id=&#34;start-agent&#34;&gt;Start Agent&lt;/h2&gt;

&lt;p&gt;Start an agent with 7 GSCs. This will allow the GSM to deploy each instance into a dedicated GSC. It will allow you to track the activity easily by monitoring the GSC log file each PU instance using.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gs-agent gsa.gsc 7
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploying-multiple-mirror-instances&#34;&gt;Deploying Multiple Mirror Instances&lt;/h2&gt;

&lt;p&gt;To scale the mirror activity deploy multiple mirror instances , one per partition. You should deploy each separately. Each can use the same PU library with different mirror-service_id value  see below example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gs deploy -properties embed://mirror-service_id=1 -override-name mirror1 multi-mirror.zip

gs deploy -properties embed://mirror-service_id=2 -override-name mirror2 multi-mirror.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can create a script that will loop and deploy multiple mirror instances each with its own unique ID.&lt;/p&gt;

&lt;h2 id=&#34;deploying-the-space&#34;&gt;Deploying the Space&lt;/h2&gt;

&lt;p&gt;To deploy the space:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gs deploy -cluster schema=partitioned total_members=2,1 -override-name space space.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deploying-the-feeder&#34;&gt;Deploying the Feeder&lt;/h2&gt;

&lt;p&gt;Deploy the feeder via the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gs deploy feeder.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will write objects into the space. The mirrors will persist these into the database.&lt;/p&gt;

&lt;h2 id=&#34;view-the-space-and-the-mirrors-status&#34;&gt;View the Space and the Mirrors Status&lt;/h2&gt;

&lt;p&gt;Start the GS-Web UI. You should see the space and the different mirror instances:&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-3.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Or you can start the Management console and view the space and the different mirror instances:&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-4.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-5.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;You may access the database and check the amount of rows inserted  this should match the amount of objects within the space:&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/mirror/distributed-mirror-6.jpg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;space-pu-xml-configuration&#34;&gt;Space pu.xml configuration&lt;/h2&gt;

&lt;p&gt;The cluster-config.mirror-service.url should include the ${clusterInfo.instanceId} as demonstrated below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;os-core:space id=&amp;quot;space&amp;quot; url=&amp;quot;/./space&amp;quot; mirror=&amp;quot;true&amp;quot; &amp;gt;
        &amp;lt;os-core:properties&amp;gt;
            &amp;lt;props&amp;gt;
                &amp;lt;prop key=&amp;quot;cluster-config.mirror-service.url&amp;quot;&amp;gt;jini://*/mirror-service${clusterInfo.instanceId}_container/mirror-service${clusterInfo.instanceId}&amp;lt;/prop&amp;gt;
            &amp;lt;/props&amp;gt;
        &amp;lt;/os-core:properties&amp;gt;
    &amp;lt;/os-core:space&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mirror-pu-xml-configuration&#34;&gt;Mirror pu.xml configuration&lt;/h2&gt;

&lt;p&gt;The url mirror bean property should include the mirror service id together with the mirror name as demonstrated below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;lt;os-core:mirror id=&amp;quot;mirror&amp;quot; url=&amp;quot;/./mirror-service${mirror-service_id}&amp;quot; space-sync-endpoint=&amp;quot;hibernateSpaceSynchronizationEndpoint&amp;quot; operation-grouping=&amp;quot;group-by-space-transaction&amp;quot;&amp;gt;
        &amp;lt;os-core:source-space name=&amp;quot;space&amp;quot; partitions=&amp;quot;2&amp;quot; backups=&amp;quot;1&amp;quot;/&amp;gt;
    &amp;lt;/os-core:mirror&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;limitations&#34;&gt;Limitations&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Distributed transactions are not supported. Local transactions are supported.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Examples</title>
      <link>http://docs.gigaspaces.com/sbp/examples.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/examples.html</guid>
      <description>&lt;p&gt;This section provides several examples of how to implement XAP from different architectural and business need perspectives.&lt;/p&gt;

&lt;!--
mini toc
--&gt;
</description>
    </item>
    
    <item>
      <title>Export/Import Tool</title>
      <link>http://docs.gigaspaces.com/sbp/export-import-tool.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/export-import-tool.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Skyler Severns&lt;/td&gt;
&lt;td&gt;10.2.0&lt;/td&gt;
&lt;td&gt;December 2015&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/GigaSpaces-ProfessionalServices/import-export&#34;&gt;Github link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The Export/Import tool was originally created to help our engineers quickly replicate test scenarios.
Since its creation this tool has evolved to be an easy-to-use method for migrating data to new XAP deployments, capturing data snapshots,
and bootstrapping disparate environments.&lt;/p&gt;

&lt;p&gt;The Export/Import tool leverages several XAP features that make its operations the most performant and functional for each
 use case. The fundamental feature leveraged by Export/Import is XAP&amp;rsquo;s &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/task-execution-overview.html&#34;&gt;Task Execution API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When the Export/Import tool is started it will send either an Export or Import task to each partition, and this is where
the actual operation will be performed. To put it simply each primary instance is responsible for exporting or importing their own data.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&#34;when-to-use-export-import&#34;&gt;&lt;em&gt;When to use Export/Import?&lt;/em&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Creating a snapshot of data&lt;/li&gt;
&lt;li&gt;Introducing a new environment&lt;/li&gt;
&lt;li&gt;Upgrading XAP versions&lt;/li&gt;
&lt;li&gt;Setting up integration-style test scenarios&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can download and build the &lt;a href=&#34;https://github.com/GigaSpaces-ProfessionalServices/import-export&#34;&gt;source code&lt;/a&gt; from our GitHub repository.
Directions on how to build the project can be found in the repository&amp;rsquo;s &lt;code&gt;README&lt;/code&gt; document.
 Alternatively you can contact your &lt;a href=&#34;http://www.gigaspaces.com/services-technical-account-management&#34;&gt;GigaSpaces Technical Account Manager&lt;/a&gt; for pre-built binaries.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&#34;export&#34;&gt;Export&lt;/h1&gt;

&lt;p&gt;During the export a remote task is sent to each primary space instance on the grid; or a subset
of the space instances if specified via the command line options.&lt;/p&gt;

&lt;p&gt;Once the task begins executing on the grid it will acquire a list of all space classes described in that instance,
and use this list to drive the creation of export files. It is at this time that a new thread pool will be created
 to dictate how many files can be exported in parallel.&lt;/p&gt;

&lt;p&gt;For each combination of class name and partition a query will be performed on the local space instance. If any space class
 instances match the route to the new partition it will be written to disk. If no matches were found the file will not be written.&lt;/p&gt;

&lt;p&gt;Files Name Pattern:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{class-name-with-package}.{originating-partition}.{target-partition}.ser.gz
Example: com.j_spaces.examples.benchmark.messages.MessagePOJO.ser.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;File Content Structure (Uncompressed):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;UTF: Class Name
Obj: Specialized Type Description (Portable/Serializable Class Definition)
Obj: Space Class Instance (x Row Count)
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/export-import/export.png&#34; alt=&#34;How Exporting Data Works&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&#34;usage&#34;&gt;&lt;em&gt;Usage&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;Due to the number of configuration options available we are unable to show all permutations of the tool, but the simplest and most
common usage is shown below.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Linux &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./setAppEnv.sh

$JAVA_HOME/bin/java -cp $GS_HOME/lib/required/*:./lib/* com.gigaspaces.tools.importexport.Program -o export -g $LOOKUPGROUPS -s myspace --jarless -d /tmp/export/output
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  Windows &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;call &amp;quot;%~dp0\setAppEnv.bat&amp;quot;

%JAVA_HOME%\bin\java.exe -cp %GS_HOME%\lib\required\*;.\lib\* com.gigaspaces.tools.importexport.Program -o export -g %LOOKUPGROUPS% -s myspace --jarless -d c:\tmp\output
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PS C:\var\import-export&amp;gt; .\export.ps1
2015-12-12 23:02:15,130 CONFIG [com.gigaspaces.logger] - Log file: C:\opt\gigaspaces\xap-10.2.0-ga\logs\2015-12-12~23.02
-gigaspaces-service-riomhairenua-13864.log
2015-12-12 23:02:15,125  INFO [com.gigaspaces.tools.importexport.config.SpaceConnectionFactory] - Creating connection wi
th url:
/./myspace?total_members=2,0&amp;amp;schema=default&amp;amp;cluster_schema=partitioned-sync2backup&amp;amp;id=1&amp;amp;groups=space-test-10&amp;amp;state=start
ed
2015-12-12 23:02:15,199  INFO [import-export] - Started import/export operation with the following configuration:
EXPORT [Space: myspace, Lookup Groups: [space-test-10], Lookup Locators: [], Output/Input Directory: c:\var\import-expor
t\output, Operating Partitions: &#39;[]&#39;, Export/Import Classes: &#39;[]&#39;, XAP Read Batch Size: 1000, PU Name Override: null, Se
curity level: null, New partition count: Not specified, Threads: 20, Jarless: true, Thread sleep ms: 1000]

2015-12-12 23:02:17,203  INFO [import-export] - Partition 1 Finished ---------------------

        Partition Id: 1
        Process Id: 10048
        Hostname: 127.0.0.1
        Elapsed Process Time (ms): 1610

        Files:
                com.j_spaces.examples.benchmark.messages.MessagePOJO.1.1.ser.gz | Records: 5000 | Elapsed time (ms): 742


2015-12-12 23:02:17,204  INFO [import-export] - Partition 2 Finished ---------------------

        Partition Id: 2
        Process Id: 11592
        Hostname: 127.0.0.1
        Elapsed Process Time (ms): 1595

        Files:
                com.j_spaces.examples.benchmark.messages.MessagePOJO.2.2.ser.gz | Records: 5000 | Elapsed time (ms): 737


PS C:\var\import-export&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&#34;options&#34;&gt;&lt;em&gt;Options&lt;/em&gt;&lt;/h2&gt;

&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Short Name&lt;/th&gt;
            &lt;th&gt;Long Name&lt;/th&gt;
            &lt;th&gt;Optional / Required&lt;/th&gt;
            &lt;th&gt;Default Value&lt;/th&gt;
            &lt;th&gt;Acceptable Values&lt;/th&gt;
            &lt;th&gt;Description&lt;/th&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th colspan=&#34;6&#34;&gt; Grid Connection Information&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-s&lt;/td&gt;
            &lt;td&gt;--space&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Name of the target space to perform the operation on.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-l&lt;/td&gt;
            &lt;td&gt;--locators&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of XAP lookup locators for the target grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-g&lt;/td&gt;
            &lt;td&gt;--groups&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of XAP lookup groups for the target grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-u&lt;/td&gt;
            &lt;td&gt;--username&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Specifies an XAP username with read and execute privileges. Required when connecting to a secured grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-a&lt;/td&gt;
            &lt;td&gt;--password&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Specifies an XAP password corresponding to the specified XAP username. Required when connecting to a secured grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;--security-level&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;grid, space, both&lt;/td&gt;
            &lt;td&gt;Indicates the level of security for the grid.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;thead&gt;
            &lt;tr&gt;
                &lt;th colspan=&#34;6&#34;&gt;General Configuration&lt;/th&gt;
            &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-o&lt;/td&gt;
            &lt;td&gt;--operation&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;export&lt;/td&gt;
            &lt;td&gt;export, import&lt;/td&gt;
            &lt;td&gt;A flag indicating whether an export or import will be performed.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-d&lt;/td&gt;
            &lt;td&gt;--directory&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A full path to the directory containing either previously exported files, or where the exported files should be placed.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;--pu-name&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Overrides the name of the processing unit, relevant only when the processing unit is different from space name.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;--jarless&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Indicates that the import / export will not use Java class definitions during processing.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-c&lt;/td&gt;
            &lt;td&gt;--classes&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of class names to operate on. The class names are case sensitive.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-p&lt;/td&gt;
            &lt;td&gt;--partitions&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of partitions that will be operated on.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-n&lt;/td&gt;
            &lt;td&gt;--number&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Relevant only when exporting data for use in a grid with a different partition count (i.e. Exporting data from a 6 partition grid to 2 partition grid or vice versa.)&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;thead&gt;
            &lt;tr&gt;
                &lt;th colspan=&#34;6&#34;&gt;Performance Configuration&lt;/th&gt;
            &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-b&lt;/td&gt;
            &lt;td&gt;--batch&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;1000&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Performance option to batch records retrieved from the space.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;--thread-sleep&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;1000&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Number of milliseconds to sleep between checks for task completion.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-t&lt;/td&gt;
            &lt;td&gt;--threads&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;20&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Number of threads to simultaneously process import or export files.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&#34;import&#34;&gt;Import&lt;/h1&gt;

&lt;p&gt;During the import a remote task is sent to each primary space instance. From there each primary instance will search the file system
for relevant files. Relevancy is determined by the second integer in the file name also known as the destination partition ID.&lt;/p&gt;

&lt;p&gt;All files destine for the new partition will then be queued and processed from the export/import thread pool. The number of
files that will be processed in parallel for each partition is configurable and based on the size of the export/import thread pool.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/export-import/import.png&#34; alt=&#34;How Exporting Data Works&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;usage-1&#34;&gt;&lt;em&gt;Usage&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;Due to the number of configuration options available we are unable to show all permutations of the tool, but the simplest and most
common usage is shown below.&lt;/p&gt;

&lt;div class=&#34;easyui-tabs&#34; plain=&#34;true&#34; data-options=&#34;&#34;&gt;&lt;div title=&#34;  Linux &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./setAppEnv.sh

$JAVA_HOME/bin/java -cp $GS_HOME/lib/required/*:./lib/* com.gigaspaces.tools.importexport.Program -o import -g $LOOKUPGROUPS -s myspace -d /tmp/export/output
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div title=&#34;  Windows &#34; style=&#34;padding:10px&#34;&gt;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;call &amp;quot;%~dp0\setAppEnv.bat&amp;quot;

%JAVA_HOME%\bin\java.exe -cp %GS_HOME%\lib\required\*;.\lib\* com.gigaspaces.tools.importexport.Program -o import -g %LOOKUPGROUPS% -s myspace -d c:\tmp\output
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PS C:\var\import-export&amp;gt; .\import.ps1
2015-12-13 00:58:12,624 CONFIG [com.gigaspaces.logger] - Log file: C:\opt\gigaspaces\xap-10.2.0-ga\logs\2015-12-13~00.58-gigaspaces-service-
riomhairenua-3836.log
2015-12-13 00:58:12,618  INFO [com.gigaspaces.tools.importexport.config.SpaceConnectionFactory] - Creating connection with url:
/./myspace?total_members=2,0&amp;amp;schema=default&amp;amp;cluster_schema=partitioned-sync2backup&amp;amp;id=1&amp;amp;groups=space-test-10&amp;amp;state=started
2015-12-13 00:58:12,697  INFO [import-export] - Started import/export operation with the following configuration:
IMPORT [Space: myspace, Lookup Groups: [space-test-10], Lookup Locators: [], Output/Input Directory: c:\var\import-export\output, Operating
Partitions: &#39;[]&#39;, Export/Import Classes: &#39;[]&#39;, XAP Read Batch Size: 1000, PU Name Override: null, Security level: null, New partition count:
 Not specified, Threads: 20, Jarless: false, Thread sleep ms: 1000]

2015-12-13 00:58:14,699  INFO [import-export] - Partition 1 Finished ---------------------

        Partition Id: 1
        Process Id: 10048
        Hostname: 127.0.0.1
        Elapsed Process Time (ms): 1096

        Files:
                com.j_spaces.examples.benchmark.messages.MessagePOJO.1.1.ser.gz | Records: 5000 | Elapsed time (ms): 1095

2015-12-13 00:58:14,700  INFO [import-export] - Partition 2 Finished ---------------------

        Partition Id: 2
        Process Id: 11592
        Hostname: 127.0.0.1
        Elapsed Process Time (ms): 1099

        Files:
                com.j_spaces.examples.benchmark.messages.MessagePOJO.2.2.ser.gz | Records: 5000 | Elapsed time (ms): 1092

PS C:\var\import-export&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&#34;options-1&#34;&gt;&lt;em&gt;Options&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Short Name&lt;/th&gt;
            &lt;th&gt;Long Name&lt;/th&gt;
            &lt;th&gt;Optional / Required&lt;/th&gt;
            &lt;th&gt;Default Value&lt;/th&gt;
            &lt;th&gt;Acceptable Values&lt;/th&gt;
            &lt;th&gt;Description&lt;/th&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;th colspan=&#34;6&#34;&gt; Grid Connection Information&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-s&lt;/td&gt;
            &lt;td&gt;&amp;ndash;space&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Name of the target space to perform the operation on.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-l&lt;/td&gt;
            &lt;td&gt;&amp;ndash;locators&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of XAP lookup locators for the target grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-g&lt;/td&gt;
            &lt;td&gt;&amp;ndash;groups&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A comma separated list of XAP lookup groups for the target grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-u&lt;/td&gt;
            &lt;td&gt;&amp;ndash;username&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Specifies an XAP username with read and execute privileges. Required when connecting to a secured grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-a&lt;/td&gt;
            &lt;td&gt;&amp;ndash;password&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Specifies an XAP password corresponding to the specified XAP username. Required when connecting to a secured grid.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&amp;ndash;security-level&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;grid, space, both&lt;/td&gt;
            &lt;td&gt;Indicates the level of security for the grid.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;thead&gt;
            &lt;tr&gt;
                &lt;th colspan=&#34;6&#34;&gt;General Configuration&lt;/th&gt;
            &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-o&lt;/td&gt;
            &lt;td&gt;&amp;ndash;operation&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;export&lt;/td&gt;
            &lt;td&gt;export, import&lt;/td&gt;
            &lt;td&gt;A flag indicating whether an export or import will be performed.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-d&lt;/td&gt;
            &lt;td&gt;&amp;ndash;directory&lt;/td&gt;
            &lt;td&gt;required&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;A full path to the directory containing either previously exported files, or where the exported files should be placed.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&amp;ndash;pu-name&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Overrides the name of the processing unit, relevant only when the processing unit is different from space name.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
    &lt;thead&gt;
            &lt;tr&gt;
                &lt;th colspan=&#34;6&#34;&gt;Performance Configuration&lt;/th&gt;
            &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;-b&lt;/td&gt;
            &lt;td&gt;&amp;ndash;batch&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;1000&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Performance option to batch records retrieved from the space.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;&amp;ndash;thread-sleep&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;1000&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Number of milliseconds to sleep between checks for task completion.&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;-t&lt;/td&gt;
            &lt;td&gt;&amp;ndash;threads&lt;/td&gt;
            &lt;td&gt;optional&lt;/td&gt;
            &lt;td&gt;20&lt;/td&gt;
            &lt;td&gt;n/a&lt;/td&gt;
            &lt;td&gt;Number of threads to simultaneously process import or export files.&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&#34;troubleshooting-frequently-asked-questions&#34;&gt;Troubleshooting &amp;amp; Frequently Asked Questions&lt;/h1&gt;

&lt;h3 id=&#34;can-i-use-the-export-import-tool-with-a-secured-grid&#34;&gt;&lt;em&gt;Can I use the Export/Import tool with a secured grid?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes, the Export/Import tool will work with secured infrastructure components and/or secured spaces. The username and password provided
should have sufficient privileges to &lt;em&gt;execute&lt;/em&gt; a remote task on the grid.&lt;/p&gt;

&lt;p&gt;If using a secured space the space must be authenticated with sufficient privileges to &lt;em&gt;read, write, and update all classes, as well as monitor_pu&lt;/em&gt;.
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&#34;i-m-receiving-a-filenotfoundexception-what-does-this-mean&#34;&gt;&lt;em&gt;I&amp;rsquo;m receiving a FileNotFoundException; what does this mean?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The most common reason for this exception is that your storage directory (the &lt;code&gt;-d&lt;/code&gt; command line option) may not exist on all hosts.
Double check the directory exists before re-running the Export/Import tool.
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&#34;can-i-use-this-to-upgrade-xap-versions&#34;&gt;&lt;em&gt;Can I use this to upgrade XAP versions?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes, this tool has been tested for upgrades between XAP 9.7, XAP 10, and XAP 11.
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&#34;one-or-more-of-my-files-did-not-get-imported-why-is-that&#34;&gt;&lt;em&gt;One or more of my files did not get imported, why is that?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Each partition is responsible for exporting or importing its data. Because of this the files will be stored in the directory provided
on that partition&amp;rsquo;s host machine.&lt;/p&gt;

&lt;p&gt;It is recommended that all machines mount a NFS drive that will be used during the export and import operations. This will ensure all partitions
regardless of hosts will have access to the export files.
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&#34;why-should-i-use-the-jarless-option-during-export&#34;&gt;&lt;em&gt;Why should I use the &lt;code&gt;--jarless&lt;/code&gt; option during export?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;If you do not provided the &lt;code&gt;--jarless&lt;/code&gt; option during export you will be required to include your application jars on the Export/Import tool&amp;rsquo;s classpath
as well as the classpath used by your processing unit running on XAP. The jars would be required on both import and export operations.&lt;/p&gt;

&lt;p&gt;When &lt;code&gt;--jarless&lt;/code&gt; is provided all objects will be read as an XAP &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/document-overview.html&#34;&gt;Space Document&lt;/a&gt; this
removes the requirement to include your application jars in the classpath. Documents and Space Classes can be interoperable,
and when following XAP documentation and best practices should be interoperable.
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&#34;why-am-i-receiving-a-noclassdeffounderror-and-or-a-classnotfoundexception&#34;&gt;&lt;em&gt;Why am I receiving a NoClassDefFoundError and/or a ClassNotFoundException?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;There are several reasons this could be. If you&amp;rsquo;re seeing this on one of your space classes during import it is because
the classes were exported without the &lt;code&gt;--jarless&lt;/code&gt; option and you will need to include your jars in the Export/Import tools
classpath as well as the Processing Unit&amp;rsquo;s classpath.&lt;/p&gt;

&lt;p&gt;If this is occurring during export you may be missing jars on the classpath, or the class definitions in the space may not be available
to the export thread. If it is the latter the solution would be making your jars available to the processing unit instances
by placing the required jars in your pu_common folder before the processing units are deployed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XAP Integration with Kafka</title>
      <link>http://docs.gigaspaces.com/sbp/kafka-integration.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/kafka-integration.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Oleksiy Dyagilev&lt;/td&gt;
&lt;td&gt;9.6&lt;/td&gt;
&lt;td&gt;February 2014&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://kafka.apache.org&#34;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/kafka-integration.tar&#34;&gt;Kafka integration&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org&#34;&gt;Apache Kafka&lt;/a&gt; is a distributed publish-subscribe messaging system. It is designed to support persistent messaging with a O(1) disk structures that provides constant time performance even with many TB of stored messages.
Apache Kafka provides High-throughput even with very modest hardware, Kafka can support hundreds of thousands of messages per second. Apache Kafka supports partitioning the messages over Kafka servers and distributing consumption over a cluster of consumer machines while maintaining per-partition ordering semantics. Many times Apache Kafka is used to perform parallel data load into Hadoop.&lt;/p&gt;

&lt;p&gt;This pattern integrates GigaSpaces with Apache Kafka. GigaSpaces&amp;rsquo; write-behind IMDG operations to Kafka making it available for the subscribers. Such could be Hadoop or other data warehousing systems using the data for reporting and processing.&lt;/p&gt;

&lt;h1 id=&#34;xap-kafka-integration-architecture&#34;&gt;XAP Kafka Integration Architecture&lt;/h1&gt;

&lt;p&gt;The XAP Kafka integration is done via the &lt;code&gt;SpaceSynchronizationEndpoint&lt;/code&gt; interface deployed as a Mirror service PU. It consumes a batch of IMDG operations, converts them to custom Kafka messages and sends these to the Kafka server using the Kafka Producer API.&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/xap-kafka.jpg&#34; alt=&#34;xap-kafka.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;GigaSpace-Kafka protocol is simple and represents the data and its IMDG operation. The message consists of the IMDG operation type (Write, Update , remove, etc.) and the actual data object. The Data object itself could be represented either as a single object or as a Space Document with key/values pairs (&lt;code&gt;SpaceDocument&lt;/code&gt;).
Since a Kafka message is sent over the wire, it should be serialized to bytes in some way.
The default encoder utilizes Java serialization mechanism which implies Space classes (domain model) to be &lt;code&gt;Serializable&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;By default Kafka messages are uniformly distributed across Kafka partitions. Please note, even though IMDG operations appear ordered in &lt;code&gt;SpaceSynchronizationEndpoint&lt;/code&gt;, it doesn&amp;rsquo;t imply correct ordering of data processing in Kafka consumers. See below diagram:&lt;/p&gt;

&lt;div class=&#34;tc-align-center&#34;&gt;&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/sbp/xap-kafka-ordering.jpg&#34; alt=&#34;xap-kafka-ordering.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;getting-started&#34;&gt;Getting started&lt;/h1&gt;

&lt;h2 id=&#34;download-the-kafka-example&#34;&gt;Download the Kafka Example&lt;/h2&gt;

&lt;p&gt;You can download the example code from &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/kafka-integration.tar&#34;&gt;here&lt;/a&gt;.
Unzip into an empty folder.&lt;/p&gt;

&lt;p&gt;The example located under &lt;code&gt;&amp;lt;project_root&amp;gt;/example&lt;/code&gt;. It demonstrates how to configure Kafka persistence and implements a simple Kafka consumer pulling data from Kafka and store in HsqlDB.&lt;/p&gt;

&lt;h2 id=&#34;running-the-example&#34;&gt;Running the Example&lt;/h2&gt;

&lt;p&gt;In order to run an example, please follow the instruction below:&lt;/p&gt;

&lt;p&gt;Step 1: Install Kafka&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Start Zookeeper and Kafka server&lt;br/&gt;
bin/zookeeper-server-start.sh config/zookeeper.properties&lt;br&gt;
bin/kafka-server-start.sh config/server.properties&lt;/p&gt;

&lt;p&gt;Step 3: Build project&lt;br/&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;cd &amp;lt;project_root&amp;gt;
mvn clean install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Step 4: Deploy example to GigaSpaces&lt;br/&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;cd example
mvn os:deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Step 5: Check GigaSpaces log files, there should be messages from the Feeder and Consumer.&lt;/p&gt;

&lt;h1 id=&#34;configuration&#34;&gt;Configuration&lt;/h1&gt;

&lt;h2 id=&#34;library-dependency&#34;&gt;Library Dependency&lt;/h2&gt;

&lt;p&gt;The following maven dependency needs to be included in your project in order to use Kafka persistence. This artifact is built from &lt;code&gt;&amp;lt;project_rood&amp;gt;/kafka-persistence&lt;/code&gt; source directory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.epam&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;kafka-persistence&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;processing-unit&#34;&gt;Processing Unit&lt;/h2&gt;

&lt;p&gt;Here is an example of the Kafka Processing Unit configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;beans xmlns=&amp;quot;http://www.springframework.org/schema/beans&amp;quot;
       xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
       xmlns:os-core=&amp;quot;http://www.openspaces.org/schema/core&amp;quot;
       xsi:schemaLocation=&amp;quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd&amp;quot;&amp;gt;

    &amp;lt;!--
        Spring property configurer which allows us to use system properties (such as user.name).
    --&amp;gt;
    &amp;lt;bean id=&amp;quot;propertiesConfigurer&amp;quot; class=&amp;quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&amp;quot;/&amp;gt;

    &amp;lt;!--
        Enables the usage of @GigaSpaceContext annotation based injection.
    --&amp;gt;
    &amp;lt;os-core:giga-space-context/&amp;gt;

    &amp;lt;!--
        A bean representing a space (an IJSpace implementation).
    --&amp;gt;
    &amp;lt;os-core:space id=&amp;quot;space&amp;quot; url=&amp;quot;/./space&amp;quot; schema=&amp;quot;default&amp;quot; mirror=&amp;quot;true&amp;quot;&amp;gt;
        &amp;lt;os-core:space-type type-name=&amp;quot;Product&amp;quot;&amp;gt;
            &amp;lt;os-core:id property=&amp;quot;CatalogNumber&amp;quot;/&amp;gt;
            &amp;lt;os-core:basic-index path=&amp;quot;Name&amp;quot;/&amp;gt;
            &amp;lt;os-core:extended-index path=&amp;quot;Price&amp;quot;/&amp;gt;
        &amp;lt;/os-core:space-type&amp;gt;
    &amp;lt;/os-core:space&amp;gt;

    &amp;lt;!--
        OpenSpaces simplified space API built on top of IJSpace/JavaSpace.
    --&amp;gt;
    &amp;lt;os-core:giga-space id=&amp;quot;gigaSpace&amp;quot; space=&amp;quot;space&amp;quot; /&amp;gt;
&amp;lt;/beans&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mirror-service&#34;&gt;Mirror service&lt;/h2&gt;

&lt;p&gt;Here is an example of the Kafka Space Synchronization Endpoint configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;beans xmlns=&amp;quot;http://www.springframework.org/schema/beans&amp;quot;
       xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
       xmlns:os-core=&amp;quot;http://www.openspaces.org/schema/core&amp;quot;
       xmlns:os-events=&amp;quot;http://www.openspaces.org/schema/events&amp;quot;
       xmlns:os-remoting=&amp;quot;http://www.openspaces.org/schema/remoting&amp;quot;
       xmlns:os-sla=&amp;quot;http://www.openspaces.org/schema/sla&amp;quot;
       xsi:schemaLocation=&amp;quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
       http://www.openspaces.org/schema/core http://www.openspaces.org/schema/9.1/core/openspaces-core.xsd
       http://www.openspaces.org/schema/events http://www.openspaces.org/schema/9.1/events/openspaces-events.xsd
       http://www.openspaces.org/schema/remoting http://www.openspaces.org/schema/9.1/remoting/openspaces-remoting.xsd
       http://www.openspaces.org/schema/sla http://www.openspaces.org/schema/sla/9.1/openspaces-sla.xsd&amp;quot;&amp;gt;

    &amp;lt;bean id=&amp;quot;propertiesConfigurer&amp;quot; class=&amp;quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&amp;quot;&amp;gt;
        &amp;lt;property name=&amp;quot;locations&amp;quot;&amp;gt;
            &amp;lt;list&amp;gt;
                &amp;lt;value&amp;gt;classpath:kafka.properties&amp;lt;/value&amp;gt;
            &amp;lt;/list&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;bean id=&amp;quot;kafkaSpaceSynchronizationEndpoint&amp;quot; class=&amp;quot;com.epam.openspaces.persistency.kafka.KafkaSpaceSynchronizationEndpointFactoryBean&amp;quot;&amp;gt;
        &amp;lt;property name=&amp;quot;producerProperties&amp;quot;&amp;gt;
            &amp;lt;props&amp;gt;
                &amp;lt;!-- Kafka producer properties. Consult Kafka documentation for a list of available properties --&amp;gt;
                &amp;lt;prop key=&amp;quot;metadata.broker.list&amp;quot;&amp;gt;${metadata.broker.list}&amp;lt;/prop&amp;gt;
                &amp;lt;prop key=&amp;quot;request.required.acks&amp;quot;&amp;gt;${request.required.acks}&amp;lt;/prop&amp;gt;
            &amp;lt;/props&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--
        The mirror space. Uses the Kafka external data source. Persists changes done on the Space that
        connects to this mirror space into the Kafka.
    --&amp;gt;
    &amp;lt;os-core:mirror id=&amp;quot;mirror&amp;quot; url=&amp;quot;/./mirror-service&amp;quot; space-sync-endpoint=&amp;quot;kafkaSpaceSynchronizationEndpoint&amp;quot; operation-grouping=&amp;quot;group-by-replication-bulk&amp;quot;&amp;gt;
        &amp;lt;os-core:source-space name=&amp;quot;space&amp;quot; partitions=&amp;quot;2&amp;quot; backups=&amp;quot;1&amp;quot;/&amp;gt;
    &amp;lt;/os-core:mirror&amp;gt;

&amp;lt;/beans&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;tc-admon-refer&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;For more information on the Mirror service see &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/asynchronous-persistency-with-the-mirror.html&#34;&gt;asynchronous persistence&lt;/a&gt;&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;producer-properties&#34;&gt;Producer Properties&lt;/h1&gt;

&lt;p&gt;Please consult Kafka documentation for the full list of available producer properties.
The default properties applied to Kafka producer are the following:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Property&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Default value&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;key.serializer.class&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;com.epam.openspaces.persistency.kafka.&lt;br&gt;protocol.impl.serializer.KafkaMessageKeyEncoder&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Message key serializer of default Gigaspace-Kafka protocol&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;serializer.class&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;com.epam.openspaces.persistency.kafka.&lt;br&gt;protocol.impl.serializer.KafkaMessageEncoder&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Message serializer of default Gigaspace-Kafka protocol&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can override the default properties if there is a need to customize GigaSpace-Kafka protocol. See Customization section below for details.&lt;/p&gt;

&lt;h2 id=&#34;space-class&#34;&gt;Space class&lt;/h2&gt;

&lt;p&gt;In order to associate a Kafka topic with the domain model class, the class needs to be annotated with the &lt;code&gt;@KafkaTopic&lt;/code&gt; annotation and declared as &lt;code&gt;Serializable&lt;/code&gt;. Here is an example&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@KafkaTopic(&amp;quot;user_activity&amp;quot;)
@SpaceClass
public class UserActivity implements Serializable {
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;space-documents&#34;&gt;Space Documents&lt;/h2&gt;

&lt;p&gt;To configure a Kafka topic for a SpaceDocuments or Extended SpaceDocument, the property &lt;code&gt;KafkaPersistenceConstants.SPACE_DOCUMENT_KAFKA_TOPIC_PROPERTY_NAME&lt;/code&gt; should be added to document. Here is an example&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Product extends SpaceDocument {

public Product() {
    super(&amp;quot;Product&amp;quot;);
    super.setProperty(SPACE_DOCUMENT_KAFKA_TOPIC_PROPERTY_NAME, &amp;quot;product&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s also possible to configure the name of the property which defines the Kafka topic for SpaceDocuments. Set &lt;code&gt;spaceDocumentKafkaTopicName&lt;/code&gt; to the desired value as shown below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;bean id=&amp;quot;kafkaSpaceSynchronizationEndpoint&amp;quot; class=&amp;quot;com.epam.openspaces.persistency.kafka.KafkaSpaceSynchrspaceDocumentKafkaTopicNameonizationEndpointFactoryBean&amp;quot;&amp;gt;
    ...
    &amp;lt;property name=&amp;quot;spaceDocumentKafkaTopicName&amp;quot; value=&amp;quot;topic_name&amp;quot; /&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kafka-consumers&#34;&gt;Kafka consumers&lt;/h2&gt;

&lt;p&gt;The Kafka persistence library provides a wrapper around the native Kafka Consumer API for the GigaSpace-Kafka protocol serialization. Please see &lt;code&gt;com.epam.openspaces.persistency.kafka.consumer.KafkaConsumer&lt;/code&gt;, example of how to use it under &lt;code&gt;&amp;lt;project_root&amp;gt;/example module&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;customization&#34;&gt;Customization&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Kafka persistence was designed to be extensible and customizable.&lt;/li&gt;
&lt;li&gt;If you need to create a custom protocol between GigaSpace and Kafka, provide an implementation of &lt;code&gt;AbstractKafkaMessage&lt;/code&gt;, &lt;code&gt;AbstractKafkaMessageKey&lt;/code&gt;, &lt;code&gt;AbstractKafkaMessageFactory&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you would like to customize how data grid operations are sent to Kafka or how the Kafka topic is chosen for a given entity, provide an implementation of &amp;lsquo;AbstractKafkaSpaceSynchronizationEndpoint&amp;rsquo;.&lt;/li&gt;
&lt;li&gt;If you want to create a custom serializer, look at &lt;code&gt;KafkaMessageDecoder&lt;/code&gt; and &lt;code&gt;KafkaMessageKeyDecoder&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Kafka Producer client (which is used under the hood) can be configured with a number of settings, see Kafka documentation.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>WAN Gateway CLI Tool</title>
      <link>http://docs.gigaspaces.com/sbp/wan-gateway-command-line-tool.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/wan-gateway-command-line-tool.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Skyler Severns, Pavlo Romanenko&lt;/td&gt;
&lt;td&gt;10.2.1&lt;/td&gt;
&lt;td&gt;December 2015&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/GigaSpaces-ProfessionalServices/gw-cli&#34;&gt;Github link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Often there is a need to create and deploy a WAN gateway PU. The process is repeatable
and can be easily automated. To speed it up this tool was created and it takes care
of WAN gateway configuration and deployment.
This tool can be used with master-slave, master-master or any other topology.&lt;/p&gt;

&lt;h1 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h1&gt;

&lt;h3 id=&#34;download-the-wan-gateway-cli&#34;&gt;Download the WAN Gateway CLI&lt;/h3&gt;

&lt;p&gt;You can download the example project  from &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/WAN_GW_CLI_Example.zip&#34;&gt;here&lt;/a&gt; and unzip it into an empty folder.&lt;/p&gt;

&lt;h3 id=&#34;building-and-running-the-tool&#34;&gt;Building and Running the Tool&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Deploy the Space Processing Units&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Deploy &lt;code&gt;space-de.jar&lt;/code&gt; and &lt;code&gt;space-ru.jar&lt;/code&gt; via &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/deploying-onto-the-service-grid.html&#34;&gt;command line or Gigaspaces Management Center&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Build the tool with Maven&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Modify &lt;code&gt;&amp;lt;gsVersion&amp;gt;&lt;/code&gt; within the &lt;code&gt;gw-cli/pom.xml&lt;/code&gt; to include the right XAP release -
example below has XAP 10.2.1 (10.2.1-14000-RELEASE) as the &lt;code&gt;&amp;lt;gsVersion&amp;gt;&lt;/code&gt; value.
Then execute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd &amp;lt;project_root&amp;gt;
mvn clean install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Run the tool to deploy WAN Gateways&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tool execution requires configuration file. Two configuration files (&lt;code&gt;wan-gateway-de.conf&lt;/code&gt; and &lt;code&gt;wan-gateway-us.conf&lt;/code&gt;)
for WAN Gateways for both spaces are provided.&lt;/p&gt;

&lt;p&gt;For Windows:&lt;/p&gt;

&lt;p&gt;Modify &lt;code&gt;run.ps&lt;/code&gt; to point to your XAP installation path instead of &lt;code&gt;D:\gigaspaces-xap-premium-10.2.1-ga&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd &amp;lt;project_root&amp;gt;
run.ps wan-gateway-de.conf
run.ps wan-gateway-us.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;for Linux:&lt;/p&gt;

&lt;p&gt;Modify &lt;code&gt;run.sh&lt;/code&gt; to point to your XAP installation path instead of `&lt;code&gt;/home/adminuser/gigaspaces-xap-premium-10.2.1-ga&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd &amp;lt;project_root&amp;gt;
./run.sh wan-gateway-de.conf
./run.sh wan-gateway-us.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Example output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./run.sh wan-gateway-us.sh
01:02:53.055 [main] INFO  Gateway-CLI - Waiting for operations
01:02:53.167 [main] DEBUG Gateway-CLI - CONNECT: ConnectOptions{username=&#39;null&#39;, password=&#39;null&#39;, lookupLocators=&#39;null&#39;, lookupGroup=&#39;pavlo&#39;}
01:02:54.853 [main] DEBUG Gateway-CLI - INITIALIZE: InitializeGatewayParameters{name=US}
01:02:55.901 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;null&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;null&#39;, target=&#39;null&#39;, sink=&#39;sink&#39;, localSpaceURL=&#39;jini://*/*/wanSpaceUS&#39;, source=&#39;null&#39;, requireBootstrap=false, gatewayLookup=false, hostName=&#39;null&#39;, discoveryPort=null}
01:02:55.978 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;null&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;null&#39;, target=&#39;null&#39;, sink=&#39;sink&#39;, localSpaceURL=&#39;null&#39;, source=&#39;DE&#39;, requireBootstrap=false, gatewayLookup=false, hostName=&#39;null&#39;, discoveryPort=null}
01:02:56.110 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;null&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;delegator&#39;, target=&#39;null&#39;, sink=&#39;null&#39;, localSpaceURL=&#39;null&#39;, source=&#39;null&#39;, requireBootstrap=false, gatewayLookup=false, hostName=&#39;null&#39;, discoveryPort=null}
01:02:56.222 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;null&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;delegator&#39;, target=&#39;DE&#39;, sink=&#39;null&#39;, localSpaceURL=&#39;null&#39;, source=&#39;null&#39;, requireBootstrap=false, gatewayLookup=false, hostName=&#39;null&#39;, discoveryPort=null}
01:02:56.346 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;DE&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;null&#39;, target=&#39;null&#39;, sink=&#39;null&#39;, localSpaceURL=&#39;null&#39;, source=&#39;null&#39;, requireBootstrap=false, gatewayLookup=true, hostName=&#39;127.0.0.1&#39;, discoveryPort=4174}
01:02:56.437 [main] DEBUG Gateway-CLI - CONFIGURE: ConfigureOptions{gatewayName=US, add=true, remove=false, modify=false, remoteGatewayName=&#39;US&#39;, communicationPort=null, username=&#39;null&#39;, password=&#39;null&#39;, delegator=&#39;null&#39;, target=&#39;null&#39;, sink=&#39;null&#39;, localSpaceURL=&#39;null&#39;, source=&#39;null&#39;, requireBootstrap=false, gatewayLookup=true, hostName=&#39;127.0.0.1&#39;, discoveryPort=4174}
01:02:56.511 [main] DEBUG Gateway-CLI - DEPLOY: DeployOptions{name=&#39;US&#39;, zone=&#39;null&#39;, bootStrapSource=&#39;null&#39;, timeout=3600, xap9=false}
01:02:58.063 [main] DEBUG Gateway-CLI: Deployer - Deploying gateway
01:02:59.693 [main] DEBUG Gateway-CLI: Deployer - Cleaning resources..
01:02:59.700 [main] DEBUG Gateway-CLI: Deployer - Cleaned
01:02:59.700 [main] DEBUG Gateway-CLI: Deployer - Deploy executed
01:02:59.700 [main] DEBUG Gateway-CLI - DISCONNECT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 4: Test the WAN replication&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Write the data to the first space and see how it&amp;rsquo;s replicated to second one.&lt;/p&gt;

&lt;h2 id=&#34;configuration-file-format&#34;&gt;Configuration file format&lt;/h2&gt;

&lt;p&gt;Each line of configuration file has the following format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{command} {parameters}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Allowed commands: CONFIGURE, DEPLOY, DISCONNECT, INITIALIZE, LINK, BOOTSTRAP, CONNECT.
Please see allowed parameters for each command below.&lt;/p&gt;

&lt;h3 id=&#34;connect-options&#34;&gt;connect [&lt;em&gt;options&lt;/em&gt;]&lt;/h3&gt;

&lt;p&gt;Sets the connect parameters. Required as the first command to connect to the specified grid, without it all other commands will fail.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-u&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;username&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Username to authenticate against a secured grid.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-p&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;password&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Password to authenticate against a secured grid.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-l&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;lookup-locators&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Lookup locator (null for default)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-g&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;lookup-groups&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Lookup group (if doesn&amp;rsquo;t set default is used)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;connect -u user -p password -l localhost:4174 -g mygroup
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;initialize-options&#34;&gt;initialize [&lt;em&gt;options&lt;/em&gt;]&lt;/h3&gt;

&lt;p&gt;Initializes a new gateway. Throws exception, if gateway with the same name was initialized or deployed already.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-n&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Gateway site name.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;initialize -n SITE-1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;configure-options&#34;&gt;configure [&lt;em&gt;options&lt;/em&gt;]&lt;/h3&gt;

&lt;p&gt;Configures the gateway component or throws an exception if the gateway wasn&amp;rsquo;t initialized.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use one of three options to add/remove/modify one of gateway configurations.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Name of the gateway to configure.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;add&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Add to gateway configuration&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-r&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;remove&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Remove from gateway configuration&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-m&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;modify&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Modify gateway configuration&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Delegator options:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To add/remove delegator use &lt;strong&gt;&lt;em&gt;-D&lt;/em&gt;&lt;/strong&gt; option:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;delegator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Delegator id&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;username&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Username&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;password&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Password&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-c&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;communication-port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Communication port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;configure SITE-1 -a -D delegator1 --gateway-lookups lookupsId --c 8000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To add/remove target to existing delegator.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-D&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;delegator&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Delegator id&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;target&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Target gateway name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;configure SITE-1 -a -D delegator1 --target SITE-2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Sink options:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To add/remove sink  use &lt;strong&gt;&lt;em&gt;-S&lt;/em&gt;&lt;/strong&gt; option:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-S&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;sink&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Sink id&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-c&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;communication-port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Communication port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;username&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Username&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;password&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Password&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;local-space-url&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Locasl space url&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;    configure SITE-1 -a -S sink1 --c 8000 --local-space-url jini://*/*/wanSpace
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To add/remove source to existing sink.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-S&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;sink&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Sink id&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;source&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Source gateway name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;configure SITE-1 -a -S sink1 --source SITE-2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Lookup options:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To add/remove/modify lookup use &lt;strong&gt;&lt;em&gt;-L&lt;/em&gt;&lt;/strong&gt; option.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-n&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;remote-gateway-name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Name of the remote gateway&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-c&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;communication-port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Communication port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-h&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;host&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Host name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-d&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;discovery-port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Discovery port&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;configure SITE-1 -a -L -n SITE2 -h localhost -d 4366 -c 8000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deploy-options&#34;&gt;deploy [&lt;em&gt;options&lt;/em&gt;]&lt;/h3&gt;

&lt;p&gt;Deploys gateway processing unit. If &amp;ndash;source param is specified then replication gateway bootstrapping process will be executed.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-n&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Name of the gateway to deploy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-b&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;bootstrap-source&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Name of the bootstrap source gateway&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-z&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;zone&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Name of the required zone for deployment&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-t&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;bootstrap-timeout&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;The number of seconds before a boostrap timeout occurs.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;xap9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Indicates if the resulting gateway should be XAP 9.x or 10.x&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;deploy SITE-1 --bootstrap-source SITE-2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;link-options&#34;&gt;link [&lt;em&gt;options&lt;/em&gt;]&lt;/h3&gt;

&lt;p&gt;Connects the specified space to a deployed gateway at runtime.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Short name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Long name&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Optional/Required&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;add&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Adds the gateway target.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-r&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;remove&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Removes the gateway target.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-n&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Target gateway name.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-s&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;space-name&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Target space.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-b&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;bulk-size&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Replication bulk size.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-i&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;idle-time-threshold&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Max milliseconds between replication.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-m&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;max-redo-capacity&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Max redo log count.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-o&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;on-capacity-exceeded&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Operation when redo log size exceeded.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;-c&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&amp;ndash;replicate-change-as-update&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Replicates changes as updates.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;optional&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code&gt;link --add -n gateway1 -s mySpace1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;disconnect&#34;&gt;disconnect&lt;/h3&gt;

&lt;p&gt;Exits from gateway configuration CLI.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;disconnect
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>XAP Integration WebSphere Dynamic Cache</title>
      <link>http://docs.gigaspaces.com/sbp/ibm-websphere-cache.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/ibm-websphere-cache.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;XAP Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Allen Terleto&lt;/td&gt;
&lt;td&gt;9.7&lt;/td&gt;
&lt;td&gt;September 2014&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;IBM provides an embedded cache called Dynamic Cache (DynaCache) as a feature of their WebSphere Application Server. By utilizing a caching-strategy applications can bypass the latency-costs of processing web services, business logic, data access, network &amp;amp; IO overhead, etc. DynaCache is the underlying caching strategy for many of the WebSphere-based family of products such as:&lt;/p&gt;

&lt;p&gt;   WebSphere Commerce Server &lt;br&gt;
   WebSphere Portal Server  &lt;br&gt;
   WebSphere Enterprise Service Bus &lt;br&gt;
   Business Process Manager    &lt;br&gt;
   WebSphere Application Server&lt;/p&gt;

&lt;p&gt;WebSphere allows administrators to configure the Dynamic Cache Service to use GigaSpaces XAP IMDG as its alternative Cache Provider instead of the default DynaCache. GigaSpaces XAP enhances WebSpheres caching strategy by providing:&lt;/p&gt;

&lt;p&gt;   Elastic Scalability &lt;br&gt;
   High availability &lt;br&gt;
   Transactional Support &lt;br&gt;
   Event Processing &lt;br&gt;
   Persistency &lt;br&gt;
   Filtering   &lt;br&gt;
   Big Data Integration  &lt;br&gt;
   Security       &lt;br&gt;
   Enhanced Monitoring Capabilities &lt;br&gt;
   Distributed and Centralized System of Record  &lt;br&gt;
   HTTP Session Sharing (across various Web Containers) &lt;br&gt;
   Replication across multiple Data Centers&lt;br&gt;
   Other XAP Features&lt;/p&gt;

&lt;p&gt;GigaSpaces XAP features increase the capabilities of WebSpheres DynaCache beyond the limitations of the default dynamic cache engine and data replication service. While DynaCache can only provide caching across replicated and synchronized WebSphere application servers, GigaSpaces XAP provides a truly distributed and remote caching architecture. WebSphere administrators no longer need to worry about data loss due to cluster failures, redeployments and upgrades. Additionally, scaling the Data Cache Tier will no longer be a function of adding additional WebSphere Application Server instances.&lt;/p&gt;

&lt;p&gt;If you are currently using DynaCache, you can simply use the administrative console or wsadmin commands to replace WebSpheres default cache provider with GigaSpaces XAP. You do not have to make any changes to the code interacting with the default dynamic cache or caching data model. In the Demo: Step-By-Step Walkthrough section we will show how to switch to GigaSpaces XAP IMDG in just a few configuration changes.&lt;/p&gt;

&lt;div class=&#34;tc-admon-refer&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;Please read the GigaSpaces XAP Integration with &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/DynamicCache.pdf&#34;&gt;IBM Dynamic Cache&lt;/a&gt; document for a detailed walk through and additional introduction information.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;demo-requirements&#34;&gt;Demo Requirements&lt;/h1&gt;

&lt;p&gt;The following technology is required to run this demo&lt;/p&gt;

&lt;p&gt;An Application Server from the WebSphere Family &lt;br&gt;
   WebSphere Application Server 7+    &lt;br&gt;
   WebSphere Enterprise Service Bus  &lt;br&gt;
   IBM Integration Bus  &lt;br&gt;
   IBM WebSphere Process Server&lt;/p&gt;

&lt;h4 id=&#34;an-ibm-ide-br&#34;&gt;An IBM IDE&lt;br&gt;&lt;/h4&gt;

&lt;p&gt;   Rational Application Developer&lt;br&gt;
   IBM Integration Designer&lt;/p&gt;

&lt;h4 id=&#34;gigaspaces-software-br&#34;&gt;GigaSpaces Software &lt;br&gt;&lt;/h4&gt;

&lt;p&gt;   GigaSpaces &lt;a href=&#34;http://www.gigaspaces.com/xap-download&#34;&gt;XAP Premium Edition 9+&lt;/a&gt; &lt;br&gt;
   &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/GigaSpacesDynaCacheIntegration.jar&#34;&gt;GigaSpacesDynaCacheIntegration.jar&lt;/a&gt; &lt;br&gt;
   &lt;a href=&#34;http://docs.gigaspaces.com/download_files/sbp/GigaDynaCacheTestWeb.war&#34;&gt;GigaDynaCacheTestWeb.war&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;run-demo-with-dynamic-cache-as-websphere-caching-provider&#34;&gt;Run Demo with Dynamic Cache as WebSphere Caching Provider&lt;/h1&gt;

&lt;div class=&#34;row&#34;&gt;&lt;div class=&#34;easyui-accordion&#34; data-options=&#34;selected:&#39;-1&#39;&#34; plain=&#34;true&#34;&gt;&lt;div title=&#34;Create New Dynamic Cache Resource&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Enter the name and JNDI specified below&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache3.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Add new property com.ibm.ws.cache.CacheConfig.showObjectContents=true&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache4.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Deploy Dynamic Cache Monitor &#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Expand Applications -&amp;gt; Application Types and Click on Websphere enterprise applications.
On the Enterprise Applications screen, click the Install button&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache5.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Browse into your Websphere installation /AppServer/installableApps, Click on CacheMonitor.ear&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache6.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 3: Download IBM Extended Cache Monitor from IBMs offical site.
Extract the contents of cachemonitor7_package into any temp directory or onto your desktop&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache7.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 4: In your admin console, click the checkbox near Dynamic Cache Monitor and Click Update&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache8.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 5: Choose Replace, add, or delete multiple files and browse for cachemonitor7_update.zip&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache9.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Setup Dynamic Cache Monitor Security &#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: In the Enterprise Applications screen, click on the link named Dynamic Cache Monitor. Click Search. Find your User ID in the Available List, click on it and then click on the Right arrow&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache10.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Open an Internet Browser and go to &lt;code&gt;http://localhost:9082/cachemonitor&lt;/code&gt;
Enter your User ID and Password then Click OK.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache11.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 3: Find the Object Cache you created earlier cache/demo and Click OK.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache12.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Deploy Demo Application&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Expand Applications -&amp;gt; Application Types and Click on Websphere enterprise applications.
On the Enterprise Applications screen, click the Install button&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache13.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Browse for the GigaDynaCacheTestWeb.war in your local directory and Click Next.
Continue to Click Next until the summary page. Then click Finish and Save&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache14.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Test Demo Application using Dynamic Cache&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Open an Internet Browser and go to &lt;code&gt;http://localhost:9082/GigaDynaCacheTestWeb/DynaCacheTestServlet&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache15.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Go back to the Cache Monitor Page and click Refresh Statistics
&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache16.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;run-demo-with-gigaspaces-xap-as-websphere-caching-provider&#34;&gt;Run Demo with GigaSpaces XAP as WebSphere Caching Provider&lt;/h1&gt;

&lt;div title=&#34;Add GigaSpaces Jars to IBM Extension Classloader&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Scroll down to find the Server Infrastructure Section. Expand Java and Process Management.
Then click on Process definition&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache17.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Click on Java Virtual Machine
&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache18.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 3: Add a new custom properties pointing to the directory with the XAP jars  ws.ext.dirs= C:\Gigaspaces\gigaspaces-xap-premium-9.7.0-ga\lib\required;C:\temp\custom\GigaSpacesDynaCacheIntegration.jar&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache19.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Configure GigaSpaces XAP as Alternative WebSphere Caching Provider&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Choose GigaSpaces XAP from the dropdown choices of Cache provider. Click OK and Save&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache20.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Click on custom properties and add the following:&lt;br&gt;
   com.ibm.ws.cache.CacheConfig.cacheProviderName=com.ibm.ws.objectgrid.dynacache.CacheProviderImpl  &lt;br&gt;
   xap.space.url=jini://&lt;em&gt;/&lt;/em&gt;/mySpace?groups=myGroup&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache21.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Start XAP Runtime Environment&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Run gs-agent from your XAP bin directory&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache22.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Run gs-ui from the same directory&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache23.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 3: Deploy a new Data Grid called mySpace with any SLA&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache24.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 4: Confirm that there are no entries in the cache using the Space Browser tab&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache25.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div title=&#34;Test Demo using XAP as Caching Provider&#34; style=&#34;padding:10px;&#34;&gt;&lt;p&gt;Step 1: Open an Internet Browser and go to &lt;code&gt;http://localhost:9082/GigaDynaCacheTestWeb/DynaCacheTestServlet&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache26.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Step 2: Check the gs-ui to confirm that a new entry is in the Space&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/dynacache/cache27.png&#34; alt=&#34;drools1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deploying GigaSpaces Platforms on Minishift</title>
      <link>http://docs.gigaspaces.com/sbp/kubegrid-minishift.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/kubegrid-minishift.html</guid>
      <description>

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Author&lt;/th&gt;
&lt;th&gt;Product Version&lt;/th&gt;
&lt;th&gt;Last Updated&lt;/th&gt;
&lt;th&gt;Reference&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Download&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Dharma Prakash and Dixson Huie&lt;/td&gt;
&lt;td&gt;14.0&lt;/td&gt;
&lt;td&gt;February 2019&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;Minishift is a tool that helps you run OpenShift locally by running a single-node OpenShift cluster inside a VM. This topic explains how to prepare the OpenShift environment so you can install KubeGrid (the InsightEdge and XAP Kubernetes deployment) on Minishift. The sample deployment described here deploys InsightEdge using PowerShell and Oracle VirtualBox, but KubeGrid can be installed on any Minishift cluster using your preferred tools.&lt;/p&gt;

&lt;p&gt;The desktop preparation process for deploying KubeGrid in Minishift involves the following steps, which are explained in detail below:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Set up your local machine or VM.&lt;/li&gt;
&lt;li&gt;(For Windows environments only) Disable Hyper-V (as this deployment uses Oracle VirtualBox).&lt;/li&gt;
&lt;li&gt;Configure Minishift to work with Oracle VirtualBox.&lt;/li&gt;
&lt;li&gt;Set up the OpenShift container environment.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After the desktop has been prepared, you can follow the instructions in the &lt;a href=&#34;https://docs.gigaspaces.com/xap/14.0/admin/kubernetes-data-grid.html&#34;&gt;Deploying a Data Grid in Kubernetes&lt;/a&gt; topic to deploy KubeGrid on Minishift.&lt;/p&gt;

&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;

&lt;p&gt;Before beginning the preparation and deployment process, ensure that you have the following installed on your local machine or a VM:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubectl&lt;/li&gt;
&lt;li&gt;Helm&lt;/li&gt;
&lt;li&gt;Kubernetes cluster (cloud, on-premise, or local via Minishift)&lt;/li&gt;
&lt;li&gt;Oracle VirtualBox&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;This sample deployment used the following software:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Oracle VirtualBox version 5.2.18 r124319&lt;/li&gt;
&lt;li&gt;Docker version 18.06.1-ce, build e68fc7a&lt;/li&gt;
&lt;li&gt;Helm version v2.10.0&lt;/li&gt;
&lt;li&gt;Minishift v1.27.0+707887e&lt;/li&gt;
&lt;li&gt;Kubectl: Client Version: v1.10.3, Server Version: v1.10.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h1 id=&#34;preparing-your-desktop-environment&#34;&gt;Preparing your Desktop Environment&lt;/h1&gt;

&lt;p&gt;In order to prepare the desktop environment to run OpenShift using Minishift, you need to perform the steps described below. PowerShell is the preferred tool for this process due to the amount of support information available online so that you can easily troubleshoot if you have any difficulty with the preparation and deployment process.&lt;/p&gt;

&lt;h2 id=&#34;disabling-hyper-v&#34;&gt;Disabling Hyper-V&lt;/h2&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;This step is only required if you are using a machine running Windows. If you are using a machine running Linux, skip this section and begin with Configuring Minishift to Use Oracle VirtualBox.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;This sample deployment uses Oracle VirtualBox instead of Hyper-V. Therefore you must verify that Hyper-V is disabled. If it isnt, do the following to disable it.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open PowerShell as an administrator.&lt;/li&gt;
&lt;li&gt;In Windows Settings&amp;gt;Apps&amp;gt;Apps and Features, click &lt;strong&gt;Programs and Features&lt;/strong&gt; on the right side of the window.&lt;/li&gt;
&lt;li&gt;In the Programs and Features window, from the list on the left click &lt;strong&gt;Turn Windows features on and off&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;In the Windows Features window, clear the &lt;strong&gt;Hyper-V checkbox&lt;/strong&gt; and click &lt;strong&gt;OK&lt;/strong&gt;. At this point you may have to restart the machine.&lt;/li&gt;
&lt;li&gt;If you restarted your machine, open PowerShell again as an administrator.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;tc-admon-note&#34;&gt;
  
  &lt;p&gt;&lt;p&gt;This procedure disables Hyper-V temporarily. When the next batch of automatic updates is installed, Hyper-V will be enabled.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;configuring-minishift-to-use-virtualbox&#34;&gt;Configuring Minishift to use VirtualBox&lt;/h2&gt;

&lt;p&gt;Minishift can work with a number of hypervisors, some of which require manual installation of the driver plug-in. The Oracle VirtualBox driver plug-in comes embedded in Minishift, so you only need to set the configuration in order to identify VirtualBox to Minishift.&lt;/p&gt;

&lt;p&gt;To configure Minishift to use Oracle VirtualBox:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Type the following command in PowerShell:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;minishift config set vm-driver virtualbox
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You should see the following output when the command is run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;No Minishift instance exists. New &#39;vm-driver&#39; setting will be applied on next &#39;minishift start&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;starting-minishift&#34;&gt;Starting Minishift&lt;/h2&gt;

&lt;p&gt;After completing the Minishift configuration, it needs to be initiated.&lt;/p&gt;

&lt;p&gt;To start Minishift:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Type the following command in PowerShell:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;minishift --memory 20000 --cpus 4 --v=5 start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This starts a one-node cluster on your machine with 2GB of memory, 4 CPUs, and log level 5.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setting-up-the-openshift-container-environment&#34;&gt;Setting up the Openshift Container Environment&lt;/h2&gt;

&lt;p&gt;The next step in the preparation (after the cluster is up and running) is to set up the OC (OpenShift Container) environment so that you can deploy KubeGrid.&lt;/p&gt;

&lt;p&gt;To set up the OC environment:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;To initialize the OC CLI, type the following command in PowerShell:
For Windows environments:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;minishift oc-env|Invoke-Expression
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For Linux environments:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eval $(minishift oc-env)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Log out of the OC environment by typing: oc logout&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Log into the OC environment as an administrator by typing oc login, using the following credentials:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;username: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;password: &lt;code&gt;admin&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Type the following command to enable the OpenShift addons:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;minishift addons apply admin-user
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Type the following commands to grant user permissions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oc adm policy add-cluster-role-to-user cluster-admin -z default --namespace default
oc adm policy add-cluster-role-to-user cluster-admin -z default --namespace kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you are installing the data grid only, skip this step. If you are installing InsightEdge, type the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oc create serviceaccount spark
oc create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Type the following to specify the Kubernetes default namespace:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oc project default
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Type the following command to launch Helm:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;helm init
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;deploying-kubegrid&#34;&gt;Deploying KubeGrid&lt;/h1&gt;

&lt;p&gt;Now that the desktop environment is prepared, you can install the InsightEdge demo on Minishift.&lt;/p&gt;

&lt;p&gt;To deploy KubeGrid and the InsightEdge demo:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Type the following command to access the insightedge GigaSpaces charts for the XAP data grid and InsightEdge:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;helm repo add gigaspaces https://resources.gigaspaces.com/helm-charts
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;After adding the GigaSpaces Helm repo, install the required chart(s) by referencing the chart name and product package version. For example, to install InsightEdge, use the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;helm install gigaspaces/insightedge --version=14.0.1 --name demo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For more information about InsightEdge KubeGrid deployment options, see the &lt;a href=&#34;https://docs.gigaspaces.com/xap/14.0/admin/kubernetes-data-grid.html&#34;&gt;Deploying a Data Grid in Kubernetes&lt;/a&gt; topic.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adjusting the JPA Domain Model</title>
      <link>http://docs.gigaspaces.com/sbp/first-jpa-app-step-1.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://docs.gigaspaces.com/sbp/first-jpa-app-step-1.html</guid>
      <description>

&lt;p&gt;This step explains how to adjust your JPA domain model to the XAP JPA implementation for maximum performance and scalability.&lt;/p&gt;

&lt;h1 id=&#34;working-with-jpa&#34;&gt;Working with JPA&lt;/h1&gt;

&lt;p&gt;JPA stands for Java Persistence API. This API was created in order to standardize Object - Relational Mapping APIs, saving the developer the pain of learning specific implementations APIs.
If you are not familiar with JPA, it highly recommended making yourself acquainted with it &lt;a href=&#34;http://download.oracle.com/javaee/5/tutorial/doc/bnbpz.html&#34;&gt;(This would be a good place to start)  &lt;/a&gt;.
GigaSpaces&amp;rsquo; JPA support is built on top of is actually an adapter layer between the JPA and JPQL APIs and the OpenSpaces API and XAP services.&lt;/p&gt;

&lt;h1 id=&#34;gigaspaces-xap-jpa&#34;&gt;GigaSpaces XAP JPA&lt;/h1&gt;

&lt;p&gt;While GigaSpaces JPA supports a large portion of the JPA standard, there are limitations and differences that are caused by the nature of XAP&amp;rsquo;s distributed implementation.&lt;/p&gt;

&lt;h3 id=&#34;embedded-relationships-only&#34;&gt;Embedded Relationships Only&lt;/h3&gt;

&lt;p&gt;GigaSpaces XAP only manages embedded relationships between entities. That means that the JPA API layer will not manage automatically any relationships based on keys. The application code will have to take care of maintaining such relationships. While JPA &lt;code&gt;@OneToMany&lt;/code&gt; and &lt;code&gt;@OneToOne&lt;/code&gt; annotations will be interpreted by XAP as owned (embedded) relationships, the &lt;code&gt;@ManyToMany&lt;/code&gt; cannot be mapped into an embedded model and therefore is not supported (it will simply be ignored).
Another important point to note is using JOIN queries; Since JOINs are actually done on embedded objects and obviously in the same memory partition, JOIN has no special toll on performance as long as you define the right indexes.&lt;/p&gt;

&lt;h3 id=&#34;other-limitations&#34;&gt;Other Limitations&lt;/h3&gt;

&lt;p&gt;There are some other limitations to GigaSpaces JPA, most notably:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Non-String auto generated Ids - At this point, cluster wide unique IDs of types other than &lt;code&gt;java.lang.String&lt;/code&gt; will not be automatically generated by JPA. We will later show how to generate cluster wide unique IDs for the application.&lt;/li&gt;
&lt;li&gt;Native queries - the current JPA implementation does not support native OpenSpaces queries (it will be supported in XAP 8.0.1).&lt;/li&gt;
&lt;li&gt;Lazy loading - the JPA layer can only read the entire object graph in full. It cannot read parts of the object graph. We will see how the PetClinic application deals with it by running the JPA code in the same JVM as the space using &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/space-based-remoting.html&#34;&gt;Space Based Remoting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;JPQL outer joins are also not supported. For the complete list of limitation please &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/jpa-api.html#JPASupport-GigaSpacesJPALimitations&#34;&gt;refer to this page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;the-application-modules&#34;&gt;The Application Modules&lt;/h1&gt;

&lt;p&gt;The original Pet Clinic application is packaged as a single WAR file and deployed on a single JVM. The Spring MVC front end of the application is using a DAO object (Clinic) to access the data. The DAO hides the usage of JPA from the web layer.
With XAP we want to make the application scalable at all layers, therefore we will split the application into 3 modules:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The Web module&lt;/strong&gt;, which does not change from the original PetClinic implementation. It uses the same Spring MVC architecture and implementation and will use the same DAO interface to access the data. However, this module will be deployed on to the GigaSpaces runtime environment  as a Web Processing Unit. In doing so, we ensure that no matter how large the traffic of the application will be; the application will be able to serve it by scaling out and adding more instances of the web application as the load increases. It will also be able to scale in by shutting them down when load decreases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Processor module&lt;/strong&gt;. This module is where the data tier resides. It holds the entire application data set, partitioned over several JVMs. The data is collocated with the DAO JPA implementation in order to access and manipulate the data locally. So each JVM contains an instance of the DAO implementation, which operates only on the local data set, providing in-memory speeds. Using the Space infrastructure, the web module transparently invokes some or all of those instances, depending on the use case.  This ensures the scalability of your business logic and data layers. The data layer can scale up by rebalancing the partitions over additional resources according to the load. Collocating the business logic with application&amp;rsquo;s data eliminates the use of physical I/O and significantly speeds up the application. In addition, each primary partition can be synchronized with one or more backup partitions to ensure high availability. The number of partitions and their backups is external to the application&amp;rsquo;s code, and can be changed at deployment time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The common module&lt;/strong&gt; is actually just a build unit with the classes shared between the web module and the processor module. In contains the domain model classes and the Clinic DAO interface definition. It is part of both web and processor deployments units.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another way to look at the above modules is to compare them to a database client calling stored procedures on the database. However, with XAP, the entire scenario is written in java, using JPA, and is deployed on to a single, unified platform.
In order for the web application to access the remote interface, we need to add a configuration file, exposing the Clinic DAO instances across the data grid cluster as a remote service to the web application. You can learn more about XAP Remoting services &lt;a href=&#34;http://docs.gigaspaces.com/xap/14.0/dev-java/executor-based-remoting.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-application-data-model&#34;&gt;The Application Data Model&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s review the considerations and changes in the application data model when accommodating it for partitioned deployment.
The application domain model class diagram is depicted in the following diagram:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/class_diagram.jpg&#34; alt=&#34;class_diagram.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And here&amp;rsquo;s how the entities are related to one another:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://docs.gigaspaces.com/attachment_files/data_model.jpg&#34; alt=&#34;data_model.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see the application&amp;rsquo;s data model assumes the following relationships:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each vet has one or more specialties (one to many)&lt;/li&gt;
&lt;li&gt;Each owner has one or more pets (one to many)&lt;/li&gt;
&lt;li&gt;Each pet has one pet type (one to one)&lt;/li&gt;
&lt;li&gt;Each pet has one or more visits (one to many)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;distributing-the-data&#34;&gt;Distributing the Data&lt;/h1&gt;

&lt;p&gt;TO distribute the data, the first thing we want to decide is how to partition this data. As we don&amp;rsquo;t have here any association between &lt;code&gt;Vet&lt;/code&gt; and &lt;code&gt;Visit&lt;/code&gt; or &lt;code&gt;Vet&lt;/code&gt; and &lt;code&gt;Pet&lt;/code&gt;, it is rather an easy task. We should partition the Vets independently of all other entities, and we should partition the Owners, Pets and &lt;code&gt;Visit&lt;/code&gt; in a manner that each &lt;code&gt;Owner&lt;/code&gt; will be located on the same partition with her pets and their visits.
There are 2 remaining types here, however, that can cause a problem: &lt;code&gt;PetType&lt;/code&gt; and &lt;code&gt;Specialty&lt;/code&gt;. Both of these types have one to many relationships with &lt;code&gt;Vet&lt;/code&gt; and &lt;code&gt;Pet&lt;/code&gt; respectively. So we need to duplicate them or manage the relationship in code and risk non-scalable scenarios since the same PetType can be referenced by multiple Pets, potentially residing in different partitions.
Since in this example the &lt;code&gt;PetType&lt;/code&gt; and vet&amp;rsquo;s &lt;code&gt;Specialty&lt;/code&gt; are final by nature, we overcome this problem by using embedded Enums. This enables the partitioning and also has minimal footprint, as Enums are static (following the Flightweight design pattern).
Had we needed to support an open set of PetTypes or vet Specialties, we would have needed to duplicate this information across all partitions for the sake of performance and scalability
As for the Pet and Visit entities - since each of them is only reference by a single entity type: Visit by Pet and Pet by Owner, we can use embedded relationships.&lt;/p&gt;

&lt;p&gt;#Preparing the Entities for XAP&lt;/p&gt;

&lt;p&gt;In order to use these entities with XAP we need to introduce the following changes to them:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JPA annotations should be placed on getters and not on attributes&lt;/li&gt;
&lt;li&gt;When JPA&amp;rsquo;s &lt;code&gt;@Id&lt;/code&gt; or &lt;code&gt;@EmbededId&lt;/code&gt; are used, add &lt;code&gt;@SpaceId&lt;/code&gt; annotation. Use the autoGenerate = false since the IDs will be generate by another service as explained below&lt;/li&gt;
&lt;li&gt;When a JPA&amp;rsquo;s &lt;code&gt;@Transient&lt;/code&gt; is used, you must add &lt;code&gt;@SpaceExclude&lt;/code&gt; annotation&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;@OneToOne&lt;/code&gt; and &lt;code&gt;@OneToMany&lt;/code&gt; and not &lt;code&gt;@Embeddable&lt;/code&gt; although it&amp;rsquo;s an embedded relationship&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;CascadeType.ALL&lt;/code&gt; with all relationships&lt;/li&gt;
&lt;li&gt;Add &lt;code&gt;@SpaceRouting&lt;/code&gt; to the appropriate getters to control the partitioning of your data model. In our example this annotation is placed on the &lt;code&gt;BaseEntity.getId()&lt;/code&gt; method. If we don&amp;rsquo;t put this annotation explicitly, XAP JPA will use the &lt;code&gt;@SpaceId&lt;/code&gt; member as default space routing key.&lt;/li&gt;
&lt;li&gt;It is recommended to use Java&amp;rsquo;s primitive wrappers rather than primitives for entity properties. We don&amp;rsquo;t recommend using primitives when storing classes to the spaces as a specific null value needs to be specified for them. This is more error prone.&lt;/li&gt;
&lt;li&gt;Add indexes to you data using &lt;code&gt;@SpaceIndex&lt;/code&gt;. In the &lt;code&gt;PetClinic&lt;/code&gt; application queries search for &lt;code&gt;Owner&lt;/code&gt; by last name so it makes sense to index the &lt;code&gt;getLastName()&lt;/code&gt; method in the &lt;code&gt;Person&lt;/code&gt; base type. You can also index properties of entities contained in collections; for example, we have indexed the &lt;code&gt;Owner. getPetsInternal()&lt;/code&gt; method. When indexing a property of an entity in a collection, you need to specify it name. In this example the &lt;code&gt;Pet&lt;/code&gt; collection is indexed based on the Pet&amp;rsquo;s Id property and therefore the indexing path is &amp;ldquo;[*].id&amp;rdquo;. The ability to index collection of complex objects is a new and powerful features of XAP 8.0&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; @SpaceIndex(path = &amp;quot;[*].id&amp;quot;, type = SpaceIndexType.BASIC)
 @OneToMany(cascade = CascadeType.ALL)
 protected Set&amp;lt;Pet&amp;gt; getPetsInternal() {
     if (this.pets == null) {
        this.pets = new HashSet&amp;lt;Pet&amp;gt;();
     }
     return this.pets;
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>