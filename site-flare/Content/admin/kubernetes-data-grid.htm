<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
<head></head>
<body>
<h1>Deploying a Data Grid in Kubernetes</h1>
  

<div class="tc-admon-note">
  
  <p>The topics in this section assume basic knowledge of InsightEdge and the data grid. If you aren't familiar with the data grid (at minimum), review the contents of the <a href="../xap/14.0/started/">Getting Started</a> section before performing the tasks described here.</p>
</div>

<p>This topic describes how to deploy GigaSpaces products in a Kubernetes environment. The integration is packaged as a <a href="https://docs.helm.sh/developing_charts/#charts">Helm chart</a>. You can deploy the full InsightEdge platform, which includes the data grid, using the Helm chart available in the GigaSpaces Helm repository.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>Before beginning to work with the data grid and InsightEdge, ensure that you have the following installed on your local machine or a VM:</p>

<ul>
<li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">kubectl</a></li>
<li><a href="https://docs.helm.sh/using_helm/#quickstart-guide">Helm</a></li>
<li>Kubernetes cluster (cloud, on-premise, or local via <a href="https://kubernetes.io/docs/setup/minikube/">minikube</a>)</li>
</ul>

<p>This topic describes how to do basic and intermediate-level deployment tasks for the data grid and InsightEdge using simple Helm commands. You can perform these tasks using a Kubernetes minikube, because you only need a single node.</p>

<div class="tc-admon-tip">
  
  <p>Configuring the data grid for InsightEdge involves the same tasks as configuring the data grid alone. The deployment and maintenance tasks described below use <code>insightedge</code> Helm charts commands. However, you can also perform these tasks using the <code>xap</code> Helm charts commands.</p>
</div>

<h1 id="getting-started">Getting Started</h1>

<p>In this section, you will learn how to do the following:</p>

<ul>
<li>Get the required GigaSpaces Helm charts</li>
<li>Start a data grid in Kubernetes</li>
<li>Monitor your data grid using Kubernetes tools</li>
<li>Delete your data grid</li>
</ul>

<h2 id="accessing-the-gigaspaces-helm-charts">Accessing the GigaSpaces Helm Charts</h2>

<p>The Helm package manager is used for installing InsightEdge and XAP in the Kubernetes environment. Helm makes deploying complex applications more portable, supports automatic rollbacks, and is a familiar pattern for developers that is easy to understand.
Moreover, since Helm is open source, there are many community charts available with standard configurations for common application services.</p>

<p>Helm supports installing charts in <a href="https://docs.helm.sh/helm/#helm-install">a number of ways</a>. A Helm chart can be used in a variety of formats and locations; packaged, unpackaged, accessed via a remote URL or even in a chart repository.  The <code>xap</code> and <code>insightedge</code> Helm charts are published in the GigaSpaces Helm chart repository at <code>https://resources.gigaspaces.com/helm-charts</code>.</p>

<p>There are multiple ways to access these charts in order to install a GigaSpaces product in Kubernetes:</p>

<ul>
<li>Install a chart directly from the repo</li>
<li>Add the GigaSpaces Helm chart repo to the Helm repo list</li>
<li>Unpack the required Helm chart(s) in a local folder</li>
</ul>

<h3 id="adding-a-helm-repo-to-the-repo-list">Adding a Helm Repo to the Repo List</h3>

<p>You can point to the GigaSpaces Helm repo, so that Helm can locate the <code>xap</code> and <code>insightedge</code> charts for installation:</p>

<pre><code class="language-bash">helm repo add gigaspaces https://resources.gigaspaces.com/helm-charts
</code></pre>

<p>After adding the GigaSpaces Helm repo, you can install the required chart(s) by referencing the chart name and product package version. For example, to install InsightEdge, use the following command:</p>

<pre><code class="language-bash">helm install gigaspaces/insightedge --version=[%=Versions.helm-version%] --name demo
</code></pre>

<h3 id="fetching-the-gigaspaces-helm-charts-from-the-gigaspaces-repository">Fetching the GigaSpaces Helm Charts from the GigaSpaces Repository</h3>

<p>Another option is to fetch the GigaSpaces Helm charts that you need and unpack them locally, so you donâ€™t have to repeat the repo name and package version in each command (which has the added benefit of making the commands shorter). For example, if you fetch and unpack the Helm chart using the following command:</p>

<pre><code class="language-bash">helm fetch gigaspaces/insightedge --version=[%=Versions.helm-version%] --untar
</code></pre>

<div class="tc-admon-note">
  
  <p>You must fetch every chart that you will be using (for example: xap, xap-pu and xap-manager) in your GigaSpaces application environment.</p>
</div>

<p>The chart is unpacked in a local folder called insightedge, and then you can install the demo by typing:</p>

<pre><code class="language-bash">helm install insightedge --name demo
</code></pre>

<p>All of the commands in the examples below assume that the Helm chart was fetched and stored in a local folder, but you can modify the commands to accomodate the other Helm install options (remote location, repo reference, etc.).</p>

<h2 id="starting-a-data-grid-in-kubernetes">Starting a Data Grid in Kubernetes</h2>

<p>In the directory where you unpacked the Helm chart(s), run the following Helm command in the command window to start a data grid in Kubernetes. This deploys a Kubernetes cluster called <code>hello</code>, which contains a data grid comprised of one Space in a Data Pod, and one Platform Manager called <code>hello-xap-manager</code> in a Management Pod. The Platform Manager manages the Space, the Manager service, and the headless service. There are no backup instances specified.</p>

<p>To start a data grid:</p>

<pre><code class="language-bash">helm install xap --name hello
</code></pre>

<p>To start an InsightEdge data grid:</p>

<pre><code class="language-bash">helm install insightedge --name hello
</code></pre>

<div class="tc-admon-note">
  
  <p>The rest of the data grid tasks described below use command examples from the <code>insightedge</code> Helm chart. However, you can also perform these tasks using the <code>xap</code> Helm chart.</p>
</div>

<h2 id="monitoring-the-data-grid-in-kubernetes">Monitoring the Data Grid in Kubernetes</h2>

<p>You can monitor the <code>hello</code> cluster you deployed using any of the following administration tools.</p>

<ul>
<li>Helm: Run the following command to print the status of the "hello' release in the command window.</li>
</ul>

<pre><code class="language-bash">helm status hello
</code></pre>

<ul>
<li>Kubernetes dashboard: run the following command to open a dashboard in your browser, where you can see all the Pods and services by clicking the various tabs. For example, if you're using minikube:</li>
</ul>

<pre><code class="language-bash">minikube dashboard
</code></pre>

<ul>
<li>Kubectl: run the following command to print the name, description, and status of the Pods in the command window. A list of events is also printed, which can be used for troubleshooting purposes. For example, if you detected a problem in one of the Pods, you can see the Pod termination reason and exit code.</li>
</ul>

<pre><code class="language-bash">kubectl describe pod
</code></pre>

<h2 id="deleting-a-data-grid-from-the-kubernetes-environment">Deleting a Data Grid from the Kubernetes Environment</h2>

<p>To delete the <code>hello</code> Space cluster, use the following Helm command. It removes the release, but leaves the logs and data so you can inspect them at a future time. This command will remove both the Platform Manager and the Space.</p>

<pre><code class="language-bash">helm del hello
</code></pre>

<p>If you want to remove the release and delete all the <code>hello</code> release data from the server, add the <code>--purge</code> option.</p>

<pre><code class="language-bash">helm del --purge hello
</code></pre>

<h1 id="applying-a-product-license">Applying a Product License</h1>

<p>The Kubernetes installation comes with a 24-hour trial <code>tryme</code> license, to enable users to perform one-click installation and explore the InsightEdge Platform and XAP functionality. However, if you want a longer trial license, you can apply the evaluation license key that you received in the email that was sent to you after you downloaded your InsightEdge or XAP commercial edition from the Download Center. These instructions are also applicable for applying a your official product license after you purchase a GigaSpaces product.</p>

<p>When the data grid starts, it checks for a valid license. You can apply the license by setting the <code>pu.license</code> property. For example, to apply the license for InsightEdge, use the following Helm command:</p>

<pre><code class="language-bash">helm install insightedge --name hello --set pu.license="&lt;your license key&gt;"
</code></pre>

<div class="tc-admon-note">
  
  <ul>
<li>You must enclose the license key in quotation marks ("...").</li>
<li>If you install a Processing Unit using the <code>insightedge-pu</code> or <code>xap-pu</code> chart, use the syntax <code>--set license="&lt;your license key&gt;"</code>.</li>
</ul>
</div>

<h1 id="deploying-a-space-cluster">Deploying a Space Cluster</h1>

<p>The demo above created a data grid that contained a single Space instance. Real-life environments generally have to store large volumes of data, and therefore need more than a single Space instance (a cluster).</p>

<p>Type the following Helm command to deploy a Space cluster with n Data Pods, with a partition count from 1 to n:</p>

<pre><code>helm install insightedge --name test --set pu.partitions=n
</code></pre>

<h1 id="defining-high-availability-ha">Defining High Availability (HA)</h1>

<p>There are several aspects to configuring a data grid for high availability. Each primary Data Pod needs a minimum of one backup Data Pod, and three Management Pods are deployed instead of one so that a quorum of Platform Managers is always available to manage the Spaces. Both the Data Pods and the Management Pods should have the Pod anti-affinity property set to true, so that the primary/backup sets and the managers are deployed on different nodes. This enables successful failover if a node gets disrupted.</p>

<div class="tc-admon-note">
  
  <p>The Kubernetes minikube runs on a single node and therefore doesn't provide anti-affinity, so you may want to evaluate XAP and InsightEdge high-availability behavior on a Kubernetes cluster that contains multiple nodes.</p>
</div>

<h2 id="configuring-high-availability-for-the-platform-manager">Configuring High Availability for the Platform Manager</h2>

<p>When the manager high availability property (<code>ha</code>) is set to true, Kubernetes deploys three Management Pods. You should enable the manager high availability property so these Management Pods are deployed on different nodes.</p>

<p>The following Helm command deploys three Management Pods (instead of one) with high availability enabled:</p>

<pre><code class="language-bash">helm install insightedge-manager --name test --set manager.ha=true,manager.antiAffinity.enabled=true
</code></pre>

<h2 id="defining-the-space-topology">Defining the Space Topology</h2>

<p>When you set the Space high availability property to true, Kubernetes deploys a backup Data Pod for each primary Data Pod. You must also enable the Space anti-affinity (<code>antiAffinity</code>) property so that the backup Data Pods are deployed on different nodes than the primary Data Pods.</p>

<div class="tc-admon-note">
  
  <p>If you apply Pod anti-affinity on a minikube, not all of the Pods will be deployed, because the environment contains only a single node.</p>
</div>

<p>The following Helm command deploys a Space cluster called <code>test</code> in a high availability topology, with anti-affinity enabled:</p>

<pre><code class="language-bash">helm install insightedge --name test --set pu.ha=true,pu.antiAffinity.enabled=true
</code></pre>

<h1 id="deploying-multiple-spaces-on-kubernetes">Deploying Multiple Spaces on Kubernetes</h1>

<p>If you want to deploy multiple data grids in the same Kubernetes environment, to better utilize resources it is best to deploy one Platform Manager cluster and then configure the Spaces to use this cluster, instead of deploying each data grid with its own Platform Manager.</p>

<p>To enable users to customize the installation, we provide several additional Helm charts that can be used to define specific constellations in more advanced scenarios:</p>

<ul>
<li>Manager (<code>insightedge-manager</code> or <code>xap-manager</code>)</li>
<li>Processing Unit (<code>insightedge-pu</code> or <code>xap-pu</code>)</li>
<li>Apache Zeppelin (<code>insightedge-zeppelin</code>)</li>
</ul>

<p>Before using these charts for the first time, you must fetch the charts as described in Getting Started section.</p>

<h2 id="deploying-the-platform-manager">Deploying the Platform Manager</h2>

<p>The helm command by default creates a Management Pod and a Data Pod together. When deploying a Platform Manager that will connect to multiple Spaces, you have to disable the part of the command that creates the Data Pod. Type the following Helm command to create a Management Pod called <code>testmanager</code> without the accompanying Space:</p>

<pre><code class="language-bash">helm install insightedge-manager --name testmanager
</code></pre>

<h2 id="deploying-the-spaces">Deploying the Spaces</h2>

<p>After the Management Pod has been deployed and the Platform Manager is available, you can deploy the Space instances and connect them to the Platform Manager. Use the following Helm command to deploy a cluster of Data Pods called <code>testspace</code>, and to specify that the cluster should connect to the <code>testmanager</code> Management Pod:</p>

<pre><code class="language-bash">helm install insightedge-pu --name testspace --set manager.name=testmanager
</code></pre>

<h1 id="deploying-a-processing-unit-in-kubernetes">Deploying a Processing Unit in Kubernetes</h1>

<p>A Processing Unit is a container that can hold any of the following:</p>

<ul>
<li>Data only (a Space)</li>
<li>Function only (business logic)</li>
<li>Both data and a function</li>
</ul>

<p>You can use the event-processing example available with the XAP and InsightEdge software packages to see how data is fed to the function and processed in Processing Units. The example creates the following modules:</p>

<ul>
<li>Processor - a Processing Unit with the main task of processing unprocessed data objects. The processing of data objects is accomplished  using both an event container and remoting.</li>
<li>Feeder - a Processing Unit that contains two feeders, a standard Space feeder and a JMS feeder, to feed unprocessed data objects that are in turn processed by the processor module. The standard Space feeder feeds unprocessed data objects  by both directly writing them to the Space and using OpenSpaces Remoting. The JMS feeder uses the JMS API to feed unprocessed data objects using a MessageConverter, which converts JMS ObjectMessages into data objects.</li>
</ul>

<div class="tc-admon-note">
  
  <p>As a prerequisite for running this example, you must install Maven on the machine where you unpacked the GigaSpaces software package.</p>
</div>

<p>To build and deploy the event-processing example in Kubernetes, the following steps are required:</p>

<ol>
<li>Build the sample Processing Units from the GigaSpaces software package.</li>
<li>Provide a URL for deploying the Processing Unit JAR file to Kubernetes.</li>
<li>Deploy a Platform Manager (Management Pod).</li>
<li>Deploy the Processing Units that were created when you built the example to Data Pods in Kubernetes, connecting them to the Management Pod.</li>
<li>View the processor logs to see the data processing results.</li>
</ol>

<h2 id="building-the-processing-unit-example">Building the Processing Unit Example</h2>

<p>The first step in deploying the sample Processing Units to Kubernetes is to build them from the examples directory. The example uses Maven as its build tool, and comes with a build script that runs Maven automatically.</p>

<p>Open a command window and navigate to the following folder in the XAP or InsightEdge package:</p>

<pre><code class="language-bash">cd &lt;product home&gt;/examples/data-app/event-processing/
</code></pre>

<p>Type the following command (for Unix environments) to build the processor and feeder Processing Units:</p>

<pre><code class="language-bash">./build.sh package
</code></pre>

<p>This build script finalizes the Processing Unit structure of both the processor and the feeder, and copies the processor JAR file to /examples/data-app/event-processing/processor/target/data-processor/lib, making the /examples/data-app/event-processing/processor/target/data-processor/ a ready-to-use Processing Unit. The final result is two Processing Unit JAR files, one under processor/target and another under feeder/target.</p>

<h2 id="providing-a-url-for-kubernetes">Providing a URL for Kubernetes</h2>

<p>In order to deploy the Processing Units on Kubernetes, a URL must be provided. You can use an existing HTTP server, or you can create a local HTTP server using Helm. Ensure that your Kubernetes environment has access to the URL that you provide. If you opt for a local server, we recommend creating it from the examples directory so that it can easily access the Processing Unit JARs that were created.</p>

<p>Type the following Helm command in the command window to create a local HTTP server:</p>

<pre><code class="language-bash">helm serve --repo-path . --address &lt;your machine IP&gt;:&lt;port&gt;
</code></pre>

<p>Leave this command window open so the server remains available and Kubernetes can connect to it.</p>

<h2 id="deploying-the-gigaspaces-components">Deploying the GigaSpaces Components</h2>

<p>Similar to deploying a Space cluster, it is best practice to first deploy the Management Pod (with the Platform Manager), and then deploy the Data Pods (first the processor, then the feeder).</p>

<p>Open a new command window and navigate to the charts directory (where you fetched the charts from our repo).</p>

<p>As was done for the Space demo, type the following Helm command to deploy a Management Pod called <code>testmanager</code>:</p>

<pre><code class="language-bash">helm install insightedge-manager --name testmanager 
</code></pre>

<p>Next, type the following Helm command to deploy a Data Pod with the processor Processing Unit from the location where it was built in the examples directory:</p>

<pre><code class="language-bash">helm install insightedge-pu --name processor --set manager.name=testmanager,resourceUrl=http://192.168.33.16:8877/examples/data-app/event-processing/processor/target/data-processor.jar
</code></pre>

<p>Lastly, type the following Helm command to deploy a Data Pod with the feeder Processing Unit from the same directory:</p>

<pre><code class="language-bash">helm install insightedge-pu --name feeder --set manager.name=testmanager,resourceUrl=http://192.168.33.16:8877/examples/data-app/event-processing/feeder/target/data-feeder.jar
</code></pre>

<h2 id="monitoring-the-processing-units">Monitoring the Processing Units</h2>

<p>You can use one of the Kubernetes tools to view the logs for the processor Data Pod, where you can see that the sample data has been processed.</p>

<h1 id="managing-the-application-environment">Managing the Application Environment</h1>

<h2 id="configuring-the-container-memory-allocation">Configuring the Container Memory Allocation</h2>

<p>The Docker container is always allocated an absolute amount of memory. If this is undefined in the Helm chart, the container will use as much as is necessary to accomodate the data and processes it contains. You can limit the memory allocation for the contents of the Docker container (Data Pod, Manager Pod, processes, etc.) and the heap memory.</p>

<p>The on-heap memory allocation can be defined as any of the following:</p>

<ul>
<li>A positive absolute value for the heap memory.</li>
<li>A negative absolute value for the heap memory, calculating the heap size as (<span class="tc-italic">[total allocated container resources] - [XMib]</span>).</li>
<li>A percentage of the Docker container.</li>
</ul>

<p>The following Helm command allocates the amount of memory for both the Docker container and for the on-heap memory as an absolute value:</p>

<pre><code class="language-bash">helm install insightedge --name test --set pu.resources.limits.memory=512Mi,pu.java.heap=256m
</code></pre>

<p>The following Helm commands allocates the amount of memory for the Docker container, and sets aside a specific amount of memory for the container to use. The rest of the memory is available to the Java heap.</p>

<pre><code class="language-bash">helm install insightedge --name test --set pu.resources.limits.memory=512Mi,pu.java.heap=limit-150m
</code></pre>

<p>You can define the maximum size of the Docker container as an absolute value, and the maximum on-heap memory allocation for the Java running inside the Docker container as a percentage. If you use this approach, make sure you leave enough memory for the Java.</p>

<p>The following Helm command sets an absolute value for the Docker container, and defines the maximum Java on-heap memory as a percentage of the container memory:</p>

<pre><code class="language-bash">helm install insightedge --name test --set pu.resources.limits.memory=256Mi,pu.java.heap=75%
</code></pre>

<h2 id="configuring-the-data-grid-using-the-helm-chart">Configuring the Data Grid Using the Helm Chart</h2>

<h3 id="default-helm-chart">Default Helm Chart</h3>

<p>The InsightEdge Helm chart has a list of supported values that can be configured. To view this list, use the following Helm command:</p>

<pre><code class="language-bash">helm inspect insightedge
</code></pre>

<p>The values.yaml file is printed in the command window, and each configurable value has a short explanation above it. The indentation in this printout indicates a use of a ".' (dot) in the value name. For example, the high availability property for the Platform Manager is listed as follows in the file:</p>

<p><code>manager:</code><br/>
     <code>ha: false</code></p>

<p>The value you will set will look like this in the command window: <code>manager.ha=true</code></p>

<h3 id="customizing-a-helm-chart">Customizing a Helm Chart</h3>

<p>You can create additional values.yaml files with customized values.</p>

<p>The following Helm command shows how a custom YAML file can be used to override the values in the original GigaSpaces Helm chart:</p>

<pre><code class="language-bash">helm install insightedge -f customValues.yaml --name hello
</code></pre>

<h3 id="overriding-the-processing-unit-properties">Overriding the Processing Unit Properties</h3>

<p>It is recommended to define the Processing Unit properties in the pu.xml as placeholders (as described in the Processing Unit <a href="https://docs.gigaspaces.com/xap/14.0/dev-java/deployment-properties.htm/#defining-property-place-holders-in-your-processing-unit">Deployment Properties</a> topic), so you can override these properties using the Helm chart.</p>

<p>After defining the properties as placeholders, use the <code>key1=value1;key2=value2</code> format to pass the override values to the Helm chart using either the <code>--set insightedge-pu.properties=&lt;your key-value pairs&gt;</code> command, or using a custom YAML file.</p>

<h2 id="monitoring-the-data-grid">Monitoring the Data Grid</h2>

<p>While Kubernetes provides a number of ways to monitor the Pods and services, you can use the GigaSpaces administration tools to monitor the data grid (Spaces and Processing Units).</p>

<h3 id="rest-manager-api">REST Manager API</h3>

<p>You can open the GigaSpaces REST Manager API and verify that your data grid was set up properly. You can access it from the minikube on your local machine or VM.</p>

<p>To get the IP address of your minikube, type the <code>minikube ip</code> command in the command window. Then type the following URL (using the minikube IP address) in your browser to access the REST Manager API:</p>

<p><code>http://&lt;minikube ip&gt;:8090</code></p>

<p>For information on how to use the REST Manager API, see the <a href="../xap/14.0/admin/admin-tools.htm/">Administration Tools</a> section of the documentation.</p>

<h3 id="gigaspaces-command-line-interface">GigaSpaces Command Line Interface</h3>

<p>You can use the GigaSpaces CLI to monitor and administer the data grid.</p>

<p>To access the CLI, click the <span class="tc-bold">EXEC</span> button in the Kubernetes dashboard to open a shell into the Management Pod. Next, navigate to the <code>/opt/gigaspaces/bin</code> directory and start the GigaSpaces CLI (insightedge or xap).</p>

<p>At this point, you can use the CLI commands to monitor the data grid, making sure to set the â€“server with the Manager Headless Service name.</p>

<p>To view a list of Spaces, type the following command:</p>

<pre><code class="language-bash">./insightedge --server=test-space-xap-manager-hs space list
</code></pre>

<p>To view the Data Type statistics, type the following command:</p>

<pre><code class="language-bash">./insightedge --server=test-space-xap-manager-hs space info --type-stats test-space
</code></pre>

<p>For more information about the GigaSpaces CLI and available commands, see the <a href="../xap/14.0/admin/admin-tools.htm/">Administration Tools</a> section of the documentation.</p>

<h2 id="advanced-monitoring-using-kubernetes-tools">Advanced Monitoring Using Kubernetes Tools</h2>

<p>You can monitor the status of the various Kubernetes components using the Kubernetes dashboard or kubectl, as described in the <a href="#monitoring-the-kubernetes-cluster">Monitoring the Kubernetes Cluster</a> section.</p>

<p>The test-space-xap-manager-hs is one of the Kubernetes services. To list all of the Kubernetes services and exposed ports, type the following command:</p>

<pre><code class="language-bash">kubectl get services
</code></pre>

<p>For more information on using the Kubernetes monitoring tools, refer to the <a href="https://kubernetes.io/docs/home/?path=users&amp;persona=app-developer&amp;level=foundational">Kubernetes documentation</a>.</p>

<h2 id="troubleshooting">Troubleshooting</h2>

<p>If the Kubernetes environment doesn't launch properly, you can investigate by checking the Init Container logs. An init container is always run before a GigaSpaces Pod is started. After the init container runs to completion, Kubernetes deploys the actual Pod (such as a Management Pod, Data Pod, etc.). So when you deploy a Space, for example, an init container runs first to verify that the Platform Manager is available, and then the Data Pod with the Space is created.</p>

<p>You can access this log in the Kubernetes dashboard, or run the following kubectl command to print the init container log in the command window:</p>

<pre><code class="language-bash">kubectl logs test-xap-space-1-0 -c check-manager-ready
</code></pre>

</body>
</html>